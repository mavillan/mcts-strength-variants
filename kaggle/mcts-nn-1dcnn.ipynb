{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70089,"databundleVersionId":9515283,"sourceType":"competition"},{"sourceId":10020545,"sourceType":"datasetVersion","datasetId":6170268},{"sourceId":10044648,"sourceType":"datasetVersion","datasetId":5909723}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -qq /kaggle/input/wheels/lightning-2.4.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T04:11:15.827273Z","iopub.execute_input":"2024-11-29T04:11:15.827709Z","iopub.status.idle":"2024-11-29T04:12:00.277461Z","shell.execute_reply.started":"2024-11-29T04:11:15.827657Z","shell.execute_reply":"2024-11-29T04:12:00.275957Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom typing import Optional, List\nimport polars\nimport os\n\nimport torch \nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader,TensorDataset\nfrom torch.optim.lr_scheduler import OneCycleLR\n\nimport lightning.pytorch as pl\nfrom lightning.pytorch.callbacks import EarlyStopping\nfrom lightning.pytorch.callbacks import ModelCheckpoint\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"PyTorch Lightning version: {pl.__version__}\")\n\nimport sys\nsys.path.append(\"/kaggle/input/mcts-artifacts\")\nfrom preproc import process_test_data\nimport kaggle_evaluation.mcts_inference_server","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-29T04:12:00.280325Z","iopub.execute_input":"2024-11-29T04:12:00.280860Z","iopub.status.idle":"2024-11-29T04:12:08.702453Z","shell.execute_reply.started":"2024-11-29T04:12:00.280809Z","shell.execute_reply":"2024-11-29T04:12:08.701488Z"},"trusted":true},"outputs":[{"name":"stdout","text":"PyTorch version: 2.4.0+cpu\nPyTorch Lightning version: 2.4.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"***\n### load artifacts\n","metadata":{}},{"cell_type":"code","source":"# Specify the path where you want to save the serialized function\nnn_1dcnn_artifacts_path = '/kaggle/input/mcts-artifacts/nn-1dcnn_predict_uni95.pt'\n\n# Load the function from the file\nnn_1dcnn_artifacts = torch.load(nn_1dcnn_artifacts_path, weights_only=False)\n\nlen(nn_1dcnn_artifacts['models'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T04:12:08.703853Z","iopub.execute_input":"2024-11-29T04:12:08.704394Z","iopub.status.idle":"2024-11-29T04:12:12.355201Z","shell.execute_reply.started":"2024-11-29T04:12:08.704314Z","shell.execute_reply":"2024-11-29T04:12:12.354125Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OrdinalEncoder from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"15"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"class SoftOrdering1DCNN(pl.LightningModule):\n\n    def __init__(self, \n            num_input_dim: int,\n            cat_input_dims: list[int],\n            output_dim: int,\n            sign_size: int = 32,\n            cha_input: int = 16, \n            cha_hidden: int = 32,\n            K: int = 2,\n            dropout_input: float = 0.2,\n            dropout_hidden: float = 0.2, \n            dropout_output: float = 0.2,\n            embedding_dropout: float = 0.2,\n            learning_rate: float = 1e-3,\n            weight_decay: float = 1e-5,\n            embedding_dim: Optional[List[int]] = None,\n            pct_start: float = 0.2,\n            div_factor: float = 10.0,\n            final_div_factor: float = 1e4):\n        super().__init__()\n        self.save_hyperparameters()\n\n        # Initialize embedding dimensions if not provided\n        if embedding_dim is None:\n            embedding_dim = [min(50, int(1 + np.ceil(np.sqrt(dim)))) for dim in cat_input_dims]\n        elif len(embedding_dim) != len(cat_input_dims):\n            raise ValueError(\"Length of embedding_dim must match number of categorical features.\")\n        \n        self.embedding_dim = embedding_dim\n        self.embedding_dropout = embedding_dropout\n        \n        # Create embedding layers\n        self.embeddings = nn.ModuleList(\n            [nn.Embedding(dim, emb_dim) for dim, emb_dim in zip(cat_input_dims, embedding_dim)]\n        )\n        self.embedding_dropout_layer = nn.Dropout(self.embedding_dropout)\n\n        # Calculate total input dimension after embeddings\n        total_embedding_dim = sum(self.embedding_dim)\n        total_input_dim = num_input_dim + total_embedding_dim\n\n        # CNN architecture parameters\n        hidden_size = sign_size * cha_input\n        self.sign_size1 = sign_size\n        self.sign_size2 = sign_size//2\n        self.output_size = (sign_size//4) * cha_hidden\n        self.cha_input = cha_input\n        self.cha_hidden = cha_hidden\n        self.K = K\n\n        # Input projection\n        self.batch_norm1 = nn.BatchNorm1d(total_input_dim)\n        self.dropout1 = nn.Dropout(dropout_input)\n        dense1 = nn.Linear(total_input_dim, hidden_size, bias=False)\n        self.dense1 = nn.utils.weight_norm(dense1)\n\n        # 1st conv layer\n        self.batch_norm_c1 = nn.BatchNorm1d(cha_input)\n        conv1 = nn.Conv1d(\n            cha_input, \n            cha_input*K, \n            kernel_size=5, \n            stride=1, \n            padding=2,  \n            groups=cha_input, \n            bias=False)\n        self.conv1 = nn.utils.weight_norm(conv1, dim=None)\n        self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size=self.sign_size2)\n\n        # 2nd conv layer\n        self.batch_norm_c2 = nn.BatchNorm1d(cha_input*K)\n        self.dropout_c2 = nn.Dropout(dropout_hidden)\n        conv2 = nn.Conv1d(\n            cha_input*K, \n            cha_hidden, \n            kernel_size=3, \n            stride=1, \n            padding=1, \n            bias=False)\n        self.conv2 = nn.utils.weight_norm(conv2, dim=None)\n\n        # 3rd conv layer\n        self.batch_norm_c3 = nn.BatchNorm1d(cha_hidden)\n        self.dropout_c3 = nn.Dropout(dropout_hidden)\n        conv3 = nn.Conv1d(\n            cha_hidden, \n            cha_hidden, \n            kernel_size=3, \n            stride=1, \n            padding=1, \n            bias=False)\n        self.conv3 = nn.utils.weight_norm(conv3, dim=None)\n\n        # 4th conv layer\n        self.batch_norm_c4 = nn.BatchNorm1d(cha_hidden)\n        conv4 = nn.Conv1d(\n            cha_hidden, \n            cha_hidden, \n            kernel_size=5, \n            stride=1, \n            padding=2, \n            groups=cha_hidden, \n            bias=False)\n        self.conv4 = nn.utils.weight_norm(conv4, dim=None)\n\n        self.avg_po_c4 = nn.AvgPool1d(kernel_size=4, stride=2, padding=1)\n        self.flt = nn.Flatten()\n\n        # Output head\n        self.batch_norm2 = nn.BatchNorm1d(self.output_size)\n        self.dropout2 = nn.Dropout(dropout_output)\n        dense2 = nn.Linear(self.output_size, output_dim, bias=False)\n        self.dense2 = nn.utils.weight_norm(dense2)\n\n        # Training parameters\n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        self.pct_start = pct_start\n        self.div_factor = div_factor\n        self.final_div_factor = final_div_factor\n\n        # Initialize lists to store validation outputs\n        self.validation_targets = []\n        self.validation_predictions = []\n\n    def forward(self, x_num, x_cat):\n        # Process categorical variables\n        embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n        embedded = torch.cat(embedded, dim=1)\n        embedded = self.embedding_dropout_layer(embedded)\n        \n        # Concatenate numerical and embedded categorical features\n        x = torch.cat([x_num, embedded], dim=1)\n\n        # Input projection\n        x = self.batch_norm1(x)\n        x = self.dropout1(x)\n        x = nn.functional.celu(self.dense1(x))\n\n        # Reshape for CNN\n        x = x.reshape(x.shape[0], self.cha_input, self.sign_size1)\n\n        # CNN backbone\n        x = self.batch_norm_c1(x)\n        x = nn.functional.leaky_relu(self.conv1(x))\n        x = self.ave_po_c1(x)\n\n        x = self.batch_norm_c2(x)\n        x = self.dropout_c2(x)\n        x = nn.functional.leaky_relu(self.conv2(x))\n        x_s = x\n\n        x = self.batch_norm_c3(x)\n        x = self.dropout_c3(x)\n        x = nn.functional.leaky_relu(self.conv3(x))\n\n        x = self.batch_norm_c4(x)\n        x = self.conv4(x)\n        x = x + x_s\n        x = nn.functional.leaky_relu(x)\n\n        x = self.avg_po_c4(x)\n        x = self.flt(x)\n\n        # Output head\n        x = self.batch_norm2(x)\n        x = self.dropout2(x)\n        x = self.dense2(x)\n        x = nn.functional.hardtanh(x)\n\n        return x.squeeze(-1)\n\n    def training_step(self, batch, batch_idx):\n        x_num, x_cat, y = batch\n        y_hat = self(x_num, x_cat)\n        loss = F.mse_loss(y_hat, y)\n        self.log('train_loss', loss, prog_bar=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x_num, x_cat, y = batch\n        y_hat = self(x_num, x_cat)\n        loss = F.mse_loss(y_hat, y)\n        self.log('valid_loss', loss, prog_bar=True)\n        # Store targets and predictions for later use\n        self.validation_targets.append(y)\n        self.validation_predictions.append(y_hat)\n        return loss\n    \n    def predict_step(self, batch, batch_idx):\n        if len(batch) == 2:\n            x_num, x_cat = batch\n        elif len(batch) == 3:\n            x_num, x_cat, _ = batch\n        y_hat = self(x_num, x_cat)\n        return y_hat\n\n    def on_validation_epoch_end(self):\n        # Concatenate all targets and predictions\n        y = torch.cat(self.validation_targets)\n        y_hat = torch.cat(self.validation_predictions)\n        rmse = torch.sqrt(F.mse_loss(y_hat, y))\n        self.log('val_rmse', rmse, prog_bar=True)\n        # Clear the lists for next epoch\n        self.validation_targets.clear()\n        self.validation_predictions.clear()\n                \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(\n            self.parameters(), \n            lr=self.learning_rate, \n            weight_decay=self.weight_decay,\n        )\n        scheduler = OneCycleLR(\n            optimizer,\n            max_lr=self.learning_rate,\n            total_steps=self.trainer.estimated_stepping_batches,\n            pct_start=self.pct_start,\n            div_factor=self.div_factor,\n            final_div_factor=self.final_div_factor,\n            anneal_strategy='cos',\n            cycle_momentum=True,\n            base_momentum=0.85,\n            max_momentum=0.95,\n        )\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler,\n                \"interval\": \"step\",\n            },\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T04:12:12.358038Z","iopub.execute_input":"2024-11-29T04:12:12.358855Z","iopub.status.idle":"2024-11-29T04:12:12.386889Z","shell.execute_reply.started":"2024-11-29T04:12:12.358818Z","shell.execute_reply":"2024-11-29T04:12:12.385616Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class SoftOrdering1DCNNInference:\n    def __init__(\n        self,\n        models_state_dicts,\n        models_hparams,\n        numerical_cols,\n        categorical_cols,\n        encoder,\n        scaler,\n        lgbm_encoders,\n    ):\n        \"\"\"Initialize inference class with trained artifacts\n        \n        Args:\n            models_state_dicts: List of model state dictionaries\n            models_hparams: List of model hyperparameters\n            numerical_cols: List of numerical column names\n            categorical_cols: List of categorical column names\n            encoder: Fitted OrdinalEncoder for categorical features\n            scaler: Fitted StandardScaler for numerical features\n            lgbm_encoders: List of LightGBM encoders for feature engineering\n        \"\"\"\n        self.numerical_cols = numerical_cols\n        self.categorical_cols = categorical_cols\n        self.encoder = encoder\n        self.scaler = scaler\n        self.lgbm_encoders = lgbm_encoders\n\n        # Load models\n        self.models = []\n        for state_dict, hparams in zip(models_state_dicts, models_hparams):\n            model = SoftOrdering1DCNN(**hparams)\n            model.load_state_dict(state_dict)\n            model.eval()  # Set to evaluation mode\n            self.models.append(model)\n\n        print(\"len(numerical_cols):\", len(numerical_cols))\n        print(\"len(categorical_cols):\", len(categorical_cols))\n\n    def predict_array(self, df_test, batch_size=512):\n        \"\"\"Make predictions on test data using DataLoader\n        \n        Args:\n            df_test: pandas DataFrame containing test features\n            batch_size: size of batches for inference\n            \n        Returns:\n            numpy array of predictions\n        \"\"\"\n        # Preprocess test data\n        test_processed = process_test_data(\n            df_test,\n            self.numerical_cols,\n            self.categorical_cols,\n            self.encoder,\n            self.scaler,\n            include_position_features=False,\n            include_text_features=False,\n        )\n\n        # Initialize predictions array\n        predictions = np.zeros(len(df_test))\n\n        # Get predictions from all models\n        for lgbm_encoder, model in zip(self.lgbm_encoders, self.models):\n            # Prepare numerical and categorical features\n            X_test_num = test_processed[self.numerical_cols].copy()\n            X_test_cat = test_processed[self.categorical_cols].copy()\n\n            # Add LGBM encoder leaves features\n            lgbm_features = lgbm_encoder.transform(\n                test_processed[self.numerical_cols + self.categorical_cols]\n            )\n            X_test_cat = pd.concat([X_test_cat, lgbm_features], axis=1)\n            _categorical_cols = self.categorical_cols + lgbm_encoder.new_columns\n\n            # Create tensors\n            X_num_tensor = torch.tensor(\n                X_test_num[self.numerical_cols].values, \n                dtype=torch.float32\n            )\n            X_cat_tensor = torch.tensor(\n                X_test_cat[_categorical_cols].values, \n                dtype=torch.int32\n            )\n            \n            # Create TensorDataset and DataLoader\n            dataset = torch.utils.data.TensorDataset(\n                X_num_tensor, \n                X_cat_tensor\n            )\n            dataloader = torch.utils.data.DataLoader(\n                dataset, \n                batch_size=batch_size,\n                shuffle=False\n            )\n            \n            # Process batches using DataLoader\n            batch_predictions = []\n            with torch.no_grad():\n                for X_num_batch, X_cat_batch in dataloader:\n                    pred_batch = model(X_num_batch, X_cat_batch).cpu()\n                    batch_predictions.append(pred_batch)\n\n            # Concatenate all batch predictions\n            model_predictions = torch.cat(batch_predictions).numpy().flatten()\n            predictions += model_predictions\n\n        # Average predictions across models\n        predictions /= len(self.models)\n        return predictions\n\n    def predict(self, test: polars.DataFrame, sample_sub: polars.DataFrame):\n        test_pd = test.to_pandas()\n        predictions = self.predict_array(test_pd)\n        submission = sample_sub.with_columns(polars.Series(\"utility_agent1\", predictions))\n        return submission\n\n\n# Create inference class\nmodel_1dcnn = SoftOrdering1DCNNInference(\n    models_state_dicts=nn_1dcnn_artifacts['models'],\n    models_hparams=nn_1dcnn_artifacts['models_hparams'],\n    numerical_cols=nn_1dcnn_artifacts['numerical_cols'],\n    categorical_cols=nn_1dcnn_artifacts['categorical_cols'],\n    encoder=nn_1dcnn_artifacts['encoder'],\n    scaler=nn_1dcnn_artifacts['scaler'],\n    lgbm_encoders=nn_1dcnn_artifacts['lgbm_encoders'],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T04:12:12.388883Z","iopub.execute_input":"2024-11-29T04:12:12.389410Z","iopub.status.idle":"2024-11-29T04:12:13.068087Z","shell.execute_reply.started":"2024-11-29T04:12:12.389363Z","shell.execute_reply":"2024-11-29T04:12:13.066964Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n  WeightNorm.apply(module, name, dim)\n","output_type":"stream"},{"name":"stdout","text":"len(numerical_cols): 396\nlen(categorical_cols): 10\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# sanity check #1\ntest = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\nsample_sub = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\")\nmodel_1dcnn.predict(test, sample_sub)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T04:12:13.069639Z","iopub.execute_input":"2024-11-29T04:12:13.070085Z","iopub.status.idle":"2024-11-29T04:12:15.185582Z","shell.execute_reply.started":"2024-11-29T04:12:13.070038Z","shell.execute_reply":"2024-11-29T04:12:15.184085Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"shape: (3, 2)\n┌────────┬────────────────┐\n│ Id     ┆ utility_agent1 │\n│ ---    ┆ ---            │\n│ i64    ┆ f64            │\n╞════════╪════════════════╡\n│ 233234 ┆ 0.166511       │\n│ 233235 ┆ -0.197469      │\n│ 233236 ┆ 0.025468       │\n└────────┴────────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Id</th><th>utility_agent1</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>233234</td><td>0.166511</td></tr><tr><td>233235</td><td>-0.197469</td></tr><tr><td>233236</td><td>0.025468</td></tr></tbody></table></div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# sanity check #2\ntrain = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\")\n\ntest = train.drop(['num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1', 'utility_agent1'])\nsample_sub = train.select(['Id', 'utility_agent1'])\n\nmodel_1dcnn.predict(test, sample_sub)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-29T04:12:45.874422Z","iopub.execute_input":"2024-11-29T04:12:45.874844Z","iopub.status.idle":"2024-11-29T04:13:50.804539Z","shell.execute_reply.started":"2024-11-29T04:12:45.874810Z","shell.execute_reply":"2024-11-29T04:13:50.802648Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m test \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_wins_agent1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_draws_agent1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_losses_agent1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutility_agent1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m sample_sub \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mselect([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutility_agent1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel_1dcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sub\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[5], line 115\u001b[0m, in \u001b[0;36mSoftOrdering1DCNNInference.predict\u001b[0;34m(self, test, sample_sub)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, test: polars\u001b[38;5;241m.\u001b[39mDataFrame, sample_sub: polars\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    114\u001b[0m     test_pd \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[0;32m--> 115\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_pd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     submission \u001b[38;5;241m=\u001b[39m sample_sub\u001b[38;5;241m.\u001b[39mwith_columns(polars\u001b[38;5;241m.\u001b[39mSeries(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutility_agent1\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictions))\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m submission\n","Cell \u001b[0;32mIn[5], line 102\u001b[0m, in \u001b[0;36mSoftOrdering1DCNNInference.predict_array\u001b[0;34m(self, df_test, batch_size)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X_num_batch, X_cat_batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m--> 102\u001b[0m         pred_batch \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_num_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_cat_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    103\u001b[0m         batch_predictions\u001b[38;5;241m.\u001b[39mappend(pred_batch)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Concatenate all batch predictions\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[4], line 129\u001b[0m, in \u001b[0;36mSoftOrdering1DCNN.forward\u001b[0;34m(self, x_num, x_cat)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_num, x_cat):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Process categorical variables\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m [emb(x_cat[:, i]) \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings)]\n\u001b[1;32m    130\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(embedded, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    131\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dropout_layer(embedded)\n","Cell \u001b[0;32mIn[4], line 129\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_num, x_cat):\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Process categorical variables\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m [\u001b[43memb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cat\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings)]\n\u001b[1;32m    130\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(embedded, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    131\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_dropout_layer(embedded)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mIndexError\u001b[0m: index out of range in self"],"ename":"IndexError","evalue":"index out of range in self","output_type":"error"}],"execution_count":7},{"cell_type":"markdown","source":"***\n### inference","metadata":{}},{"cell_type":"code","source":"inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(model_1dcnn.predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2024-11-29T04:14:19.437796Z","iopub.execute_input":"2024-11-29T04:14:19.438235Z","iopub.status.idle":"2024-11-29T04:14:21.520500Z","shell.execute_reply.started":"2024-11-29T04:14:19.438198Z","shell.execute_reply":"2024-11-29T04:14:21.519401Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"***","metadata":{}}]}