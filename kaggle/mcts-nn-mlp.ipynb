{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":70089,"databundleVersionId":9515283,"sourceType":"competition"},{"sourceId":10020397,"sourceType":"datasetVersion","datasetId":5909723},{"sourceId":10020545,"sourceType":"datasetVersion","datasetId":6170268}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -qq /kaggle/input/wheels/lightning-2.4.0-py3-none-any.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T14:47:12.528964Z","iopub.execute_input":"2024-11-26T14:47:12.529415Z","iopub.status.idle":"2024-11-26T14:47:58.193015Z","shell.execute_reply.started":"2024-11-26T14:47:12.529347Z","shell.execute_reply":"2024-11-26T14:47:58.191501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom typing import Optional, List\nimport polars\nimport os\n\nimport torch \nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader,TensorDataset\nfrom torch.optim.lr_scheduler import OneCycleLR\n\nimport lightning.pytorch as pl\nfrom lightning.pytorch.callbacks import EarlyStopping\nfrom lightning.pytorch.callbacks import ModelCheckpoint\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"PyTorch Lightning version: {pl.__version__}\")\n\nimport sys\nsys.path.append(\"/kaggle/input/mcts-artifacts\")\nfrom preproc import process_test_data\nimport kaggle_evaluation.mcts_inference_server","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-26T14:53:05.608133Z","iopub.execute_input":"2024-11-26T14:53:05.608550Z","iopub.status.idle":"2024-11-26T14:53:05.617021Z","shell.execute_reply.started":"2024-11-26T14:53:05.608513Z","shell.execute_reply":"2024-11-26T14:53:05.615757Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"***\n### load artifacts\n","metadata":{}},{"cell_type":"code","source":"# Specify the path where you want to save the serialized function\nnn_mlp_artifacts_path = '/kaggle/input/mcts-artifacts/nn-mlp_predict.pt'\n\n# Load the function from the file\nnn_mlp_artifacts = torch.load(nn_mlp_artifacts_path, weights_only=False)\n\nlen(nn_mlp_artifacts['models'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T14:56:26.674694Z","iopub.execute_input":"2024-11-26T14:56:26.675106Z","iopub.status.idle":"2024-11-26T14:56:26.791949Z","shell.execute_reply.started":"2024-11-26T14:56:26.675073Z","shell.execute_reply":"2024-11-26T14:56:26.790771Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MLP(pl.LightningModule):\n\n    def __init__(self, \n            num_input_dim: int,\n            cat_input_dims: list[int],\n            output_dim: int,\n            layers: str,\n            dropout: float,\n            embedding_dropout: float,\n            learning_rate: float = 1e-3,\n            weight_decay: float = 1e-5,\n            initialization: str = 'kaiming_uniform',\n            embedding_dim: Optional[List[int]] = None,\n            pct_start: float = 0.2,\n            div_factor: float = 10.0,\n            final_div_factor: float = 1e4,\n        ):\n        super().__init__()\n        self.save_hyperparameters()\n        self.dropout = dropout\n        self.embedding_dropout = embedding_dropout\n        self.pct_start = pct_start\n        self.div_factor = div_factor\n        self.final_div_factor = final_div_factor\n\n        # Initialize embedding dimensions if not provided\n        if embedding_dim is None:\n            # Rule of thumb: min(50, num_unique // 2 + 1) for each categorical feature\n            embedding_dim = [min(50, int(1 + np.ceil(np.sqrt(dim)))) for dim in cat_input_dims]\n\n        elif len(embedding_dim) != len(cat_input_dims):\n            raise ValueError(\"Length of embedding_dim must match number of categorical features.\")\n\n        self.embedding_dim = embedding_dim\n\n        # Create embedding layers\n        self.create_embeddings(cat_input_dims, embedding_dim)\n\n        # Create backbone layers\n        self.create_backbone(num_input_dim, layers)\n\n        # Create head layers\n        self.create_head(output_dim)\n\n        self.learning_rate = learning_rate\n        self.weight_decay = weight_decay\n        self.initialization = initialization\n\n        self._init_weights()\n\n        # Initialize lists to store validation outputs\n        self.validation_targets = []\n        self.validation_predictions = []\n\n    def create_embeddings(self, cat_input_dims: list[int], embedding_dim: list[int]):\n        self.embeddings = nn.ModuleList(\n            [nn.Embedding(dim, emb_dim) for dim, emb_dim in zip(cat_input_dims, embedding_dim)]\n        )\n        self.embedding_dropout_layer = nn.Dropout(self.embedding_dropout)\n\n    def create_backbone(self, num_input_dim: int, layers: str):\n        # Calculate total input dimension after embeddings\n        total_embedding_dim = sum(self.embedding_dim)\n        total_input_dim = num_input_dim + total_embedding_dim\n\n        # Parse layers string\n        layer_sizes = [int(size) for size in layers.split('-')]\n\n        # Create backbone network layers\n        backbone_layers = []\n        prev_size = total_input_dim\n        for size in layer_sizes:\n            backbone_layers.extend([\n                nn.BatchNorm1d(prev_size),\n                nn.Linear(prev_size, size),\n                nn.ReLU(),\n                nn.Dropout(self.hparams.dropout),\n            ])\n            prev_size = size\n        self.backbone = nn.Sequential(*backbone_layers)\n        self.backbone_output_size = prev_size\n\n    def create_head(self, output_dim: int):\n        # Output layer\n        self.head = nn.Sequential(\n            nn.BatchNorm1d(self.backbone_output_size),\n            nn.Linear(self.backbone_output_size, output_dim)\n        )\n\n    def _init_weights(self):\n        for module in self.modules():\n            if isinstance(module, nn.Linear):\n                if any(module is m for m in self.head.modules()):\n                    nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('tanh'))\n                else:\n                    if self.initialization == 'kaiming_uniform':\n                        nn.init.kaiming_uniform_(module.weight, nonlinearity='relu')\n                    elif self.initialization == 'kaiming_normal':\n                        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n                    elif self.initialization == 'xavier_uniform':\n                        nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('relu'))\n                    elif self.initialization == 'xavier_normal':\n                        nn.init.xavier_normal_(module.weight, gain=nn.init.calculate_gain('relu'))\n                    else:\n                        raise ValueError(f\"Unsupported initialization method: {self.initialization}\")\n                \n                # Initialize bias to small values\n                if module.bias is not None:\n                    nn.init.uniform_(module.bias, -0.1, 0.1)\n\n    def forward(self, x_num, x_cat):\n        # Process categorical variables\n        embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n        embedded = torch.cat(embedded, dim=1)\n        embedded = self.embedding_dropout_layer(embedded)\n        \n        # Concatenate numerical and embedded categorical features\n        x = torch.cat([x_num, embedded], dim=1)\n        \n        # Pass through backbone\n        x = self.backbone(x)\n        \n        # Pass through head\n        x = self.head(x)\n        x = nn.functional.hardtanh(x)\n\n        return x.squeeze(-1)\n\n    def training_step(self, batch, batch_idx):\n        x_num, x_cat, y = batch\n        y_hat = self(x_num, x_cat)\n        loss = F.mse_loss(y_hat, y)\n        self.log('train_loss', loss, prog_bar=True)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x_num, x_cat, y = batch\n        y_hat = self(x_num, x_cat)\n        loss = F.mse_loss(y_hat, y)\n        self.log('valid_loss', loss, prog_bar=True)\n        # Store targets and predictions for later use\n        self.validation_targets.append(y)\n        self.validation_predictions.append(y_hat)\n        return loss\n    \n    def predict_step(self, batch, batch_idx):\n        if len(batch) == 2:\n            x_num, x_cat = batch\n        elif len(batch) == 3:\n            x_num, x_cat, _ = batch\n        y_hat = self(x_num, x_cat)\n        return y_hat\n\n    def on_validation_epoch_end(self):\n        # Concatenate all targets and predictions\n        y = torch.cat(self.validation_targets)\n        y_hat = torch.cat(self.validation_predictions)\n        rmse = torch.sqrt(F.mse_loss(y_hat, y))\n        self.log('val_rmse', rmse, prog_bar=True)\n        # Clear the lists for next epoch\n        self.validation_targets.clear()\n        self.validation_predictions.clear()\n                \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(\n            self.parameters(), \n            lr=self.learning_rate, \n            weight_decay=self.weight_decay,\n        )\n        scheduler = OneCycleLR(\n            optimizer,\n            max_lr=self.learning_rate,\n            total_steps=self.trainer.estimated_stepping_batches,\n            pct_start=self.pct_start,\n            div_factor=self.div_factor,\n            final_div_factor=self.final_div_factor,\n            anneal_strategy='cos',\n            cycle_momentum=True,\n            base_momentum=0.85,\n            max_momentum=0.95,\n        )\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler,\n                \"interval\": \"step\",\n            },\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T14:56:29.444588Z","iopub.execute_input":"2024-11-26T14:56:29.445026Z","iopub.status.idle":"2024-11-26T14:56:29.472854Z","shell.execute_reply.started":"2024-11-26T14:56:29.444991Z","shell.execute_reply":"2024-11-26T14:56:29.471730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MLPInference:\n    def __init__(\n        self,\n        models_state_dicts,\n        models_hparams,\n        numerical_cols,\n        categorical_cols,\n        encoder,\n        scaler,\n        lgbm_encoders,\n    ):\n        \"\"\"Initialize inference class with trained artifacts\n        \n        Args:\n            models_state_dicts: List of model state dictionaries\n            models_hparams: List of model hyperparameters\n            numerical_cols: List of numerical column names\n            categorical_cols: List of categorical column names\n            encoder: Fitted OrdinalEncoder for categorical features\n            scaler: Fitted StandardScaler for numerical features\n            lgbm_encoders: List of LightGBM encoders for feature engineering\n        \"\"\"\n        self.numerical_cols = numerical_cols\n        self.categorical_cols = categorical_cols\n        self.encoder = encoder\n        self.scaler = scaler\n        self.lgbm_encoders = lgbm_encoders\n\n        # Load models\n        self.models = []\n        for state_dict, hparams in zip(models_state_dicts, models_hparams):\n            model = MLP(**hparams)\n            model.load_state_dict(state_dict)\n            model.eval()  # Set to evaluation mode\n            self.models.append(model)\n\n        print(\"len(numerical_cols):\", len(numerical_cols))\n        print(\"len(categorical_cols):\", len(categorical_cols))\n\n    def predict_array(self, df_test, batch_size=512):\n        \"\"\"Make predictions on test data using DataLoader\n        \n        Args:\n            df_test: pandas DataFrame containing test features\n            batch_size: size of batches for inference\n            \n        Returns:\n            numpy array of predictions\n        \"\"\"\n        # Preprocess test data\n        test_processed = process_test_data(\n            df_test,\n            self.numerical_cols,\n            self.categorical_cols,\n            self.encoder,\n            self.scaler,\n            include_position_features=False,\n            include_text_features=False,\n        )\n\n        # Initialize predictions array\n        predictions = np.zeros(len(df_test))\n\n        # Get predictions from all models\n        for lgbm_encoder, model in zip(self.lgbm_encoders, self.models):\n            # Prepare numerical and categorical features\n            X_test_num = test_processed[self.numerical_cols].copy()\n            X_test_cat = test_processed[self.categorical_cols].copy()\n\n            # Add LGBM encoder leaves features\n            lgbm_features = lgbm_encoder.transform(\n                test_processed[self.numerical_cols + self.categorical_cols]\n            )\n            X_test_cat = pd.concat([X_test_cat, lgbm_features], axis=1)\n            _categorical_cols = self.categorical_cols + lgbm_encoder.new_columns\n\n            # Create tensors\n            X_num_tensor = torch.tensor(\n                X_test_num[self.numerical_cols].values, \n                dtype=torch.float32\n            )\n            X_cat_tensor = torch.tensor(\n                X_test_cat[_categorical_cols].values, \n                dtype=torch.int32\n            )\n            \n            # Create TensorDataset and DataLoader\n            dataset = torch.utils.data.TensorDataset(\n                X_num_tensor, \n                X_cat_tensor\n            )\n            dataloader = torch.utils.data.DataLoader(\n                dataset, \n                batch_size=batch_size,\n                shuffle=False\n            )\n            \n            # Process batches using DataLoader\n            batch_predictions = []\n            with torch.no_grad():\n                for X_num_batch, X_cat_batch in dataloader:\n                    pred_batch = model(X_num_batch, X_cat_batch).cpu()\n                    batch_predictions.append(pred_batch)\n\n            # Concatenate all batch predictions\n            model_predictions = torch.cat(batch_predictions).numpy().flatten()\n            predictions += model_predictions\n\n        # Average predictions across models\n        predictions /= len(self.models)\n        return predictions\n\n    def predict(self, test: polars.DataFrame, sample_sub: polars.DataFrame):\n        test_pd = test.to_pandas()\n        predictions = self.predict_array(test_pd)\n        submission = sample_sub.with_columns(polars.Series(\"utility_agent1\", predictions))\n        return submission\n\n\n# Create inference class\nmodel_mlp = MLPInference(\n    models_state_dicts=nn_mlp_artifacts['models'],\n    models_hparams=nn_mlp_artifacts['models_hparams'],\n    numerical_cols=nn_mlp_artifacts['numerical_cols'],\n    categorical_cols=nn_mlp_artifacts['categorical_cols'],\n    encoder=nn_mlp_artifacts['encoder'],\n    scaler=nn_mlp_artifacts['scaler'],\n    lgbm_encoders=nn_mlp_artifacts['lgbm_encoders'],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T14:56:55.977786Z","iopub.execute_input":"2024-11-26T14:56:55.978198Z","iopub.status.idle":"2024-11-26T14:56:56.226237Z","shell.execute_reply.started":"2024-11-26T14:56:55.978164Z","shell.execute_reply":"2024-11-26T14:56:56.224909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# sanity check #1\ntest = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\nsample_sub = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\")\nmodel_mlp.predict(test, sample_sub)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# sanity check #2\ntrain = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\")\n\ntest = train.drop(['num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1', 'utility_agent1'])\nsample_sub = train.select(['Id', 'utility_agent1'])\n\nmodel_mlp.predict(test, sample_sub)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"***\n### inference","metadata":{}},{"cell_type":"code","source":"inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(model_mlp.predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n        )\n    )","metadata":{"execution":{"iopub.status.busy":"2024-11-26T15:04:32.352389Z","iopub.execute_input":"2024-11-26T15:04:32.352839Z","iopub.status.idle":"2024-11-26T15:04:33.055800Z","shell.execute_reply.started":"2024-11-26T15:04:32.352804Z","shell.execute_reply":"2024-11-26T15:04:33.054740Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"***","metadata":{}}]}