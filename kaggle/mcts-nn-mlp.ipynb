{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c0048d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:11:40.286149Z",
     "iopub.status.busy": "2024-11-26T15:11:40.285646Z",
     "iopub.status.idle": "2024-11-26T15:12:24.790182Z",
     "shell.execute_reply": "2024-11-26T15:12:24.788699Z"
    },
    "papermill": {
     "duration": 44.516259,
     "end_time": "2024-11-26T15:12:24.796148",
     "exception": false,
     "start_time": "2024-11-26T15:11:40.279889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qq /kaggle/input/wheels/lightning-2.4.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e54c432",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-26T15:12:24.806010Z",
     "iopub.status.busy": "2024-11-26T15:12:24.805036Z",
     "iopub.status.idle": "2024-11-26T15:12:36.274434Z",
     "shell.execute_reply": "2024-11-26T15:12:36.273016Z"
    },
    "papermill": {
     "duration": 11.477205,
     "end_time": "2024-11-26T15:12:36.277294",
     "exception": false,
     "start_time": "2024-11-26T15:12:24.800089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0+cpu\n",
      "PyTorch Lightning version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from typing import Optional, List\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pl.__version__}\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/mcts-artifacts\")\n",
    "from preproc import process_test_data\n",
    "from transformer import LGBMLeavesEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4bf21",
   "metadata": {
    "papermill": {
     "duration": 0.003676,
     "end_time": "2024-11-26T15:12:36.285135",
     "exception": false,
     "start_time": "2024-11-26T15:12:36.281459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### load artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f34f657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:12:36.295045Z",
     "iopub.status.busy": "2024-11-26T15:12:36.294330Z",
     "iopub.status.idle": "2024-11-26T15:12:37.274360Z",
     "shell.execute_reply": "2024-11-26T15:12:37.273264Z"
    },
    "papermill": {
     "duration": 0.987802,
     "end_time": "2024-11-26T15:12:37.276718",
     "exception": false,
     "start_time": "2024-11-26T15:12:36.288916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OrdinalEncoder from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Specify the path where you want to save the serialized function\n",
    "nn_artifacts_path = '/kaggle/input/mcts-artifacts/nn-mlp_predict.pt'\n",
    "\n",
    "# Load the function from the file\n",
    "nn_artifacts = torch.load(nn_artifacts_path, weights_only=False)\n",
    "\n",
    "numerical_cols = nn_artifacts[\"numerical_cols\"]\n",
    "categorical_cols = nn_artifacts[\"categorical_cols\"]\n",
    "_categorical_cols = nn_artifacts[\"_categorical_cols\"]\n",
    "encoder = nn_artifacts[\"encoder\"]\n",
    "scaler = nn_artifacts[\"scaler\"]\n",
    "lgbm_encoders = nn_artifacts[\"lgbm_encoders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024aae18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:12:37.286470Z",
     "iopub.status.busy": "2024-11-26T15:12:37.286042Z",
     "iopub.status.idle": "2024-11-26T15:12:37.312686Z",
     "shell.execute_reply": "2024-11-26T15:12:37.311555Z"
    },
    "papermill": {
     "duration": 0.034588,
     "end_time": "2024-11-26T15:12:37.314923",
     "exception": false,
     "start_time": "2024-11-26T15:12:37.280335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "            num_input_dim: int,\n",
    "            cat_input_dims: list[int],\n",
    "            output_dim: int,\n",
    "            layers: str,\n",
    "            dropout: float,\n",
    "            embedding_dropout: float,\n",
    "            learning_rate: float = 1e-3,\n",
    "            weight_decay: float = 1e-5,\n",
    "            initialization: str = 'kaiming_uniform',\n",
    "            embedding_dim: Optional[List[int]] = None,\n",
    "            pct_start: float = 0.2,\n",
    "            div_factor: float = 10.0,\n",
    "            final_div_factor: float = 1e4,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.dropout = dropout\n",
    "        self.embedding_dropout = embedding_dropout\n",
    "        self.pct_start = pct_start\n",
    "        self.div_factor = div_factor\n",
    "        self.final_div_factor = final_div_factor\n",
    "\n",
    "        # Initialize embedding dimensions if not provided\n",
    "        if embedding_dim is None:\n",
    "            # Rule of thumb: min(50, num_unique // 2 + 1) for each categorical feature\n",
    "            embedding_dim = [min(50, int(1 + np.ceil(np.sqrt(dim)))) for dim in cat_input_dims]\n",
    "\n",
    "        elif len(embedding_dim) != len(cat_input_dims):\n",
    "            raise ValueError(\"Length of embedding_dim must match number of categorical features.\")\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Create embedding layers\n",
    "        self.create_embeddings(cat_input_dims, embedding_dim)\n",
    "\n",
    "        # Create backbone layers\n",
    "        self.create_backbone(num_input_dim, layers)\n",
    "\n",
    "        # Create head layers\n",
    "        self.create_head(output_dim)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.initialization = initialization\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "        # Initialize lists to store validation outputs\n",
    "        self.validation_targets = []\n",
    "        self.validation_predictions = []\n",
    "\n",
    "    def create_embeddings(self, cat_input_dims: list[int], embedding_dim: list[int]):\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(dim, emb_dim) for dim, emb_dim in zip(cat_input_dims, embedding_dim)]\n",
    "        )\n",
    "        self.embedding_dropout_layer = nn.Dropout(self.embedding_dropout)\n",
    "\n",
    "    def create_backbone(self, num_input_dim: int, layers: str):\n",
    "        # Calculate total input dimension after embeddings\n",
    "        total_embedding_dim = sum(self.embedding_dim)\n",
    "        total_input_dim = num_input_dim + total_embedding_dim\n",
    "\n",
    "        # Parse layers string\n",
    "        layer_sizes = [int(size) for size in layers.split('-')]\n",
    "\n",
    "        # Create backbone network layers\n",
    "        backbone_layers = []\n",
    "        prev_size = total_input_dim\n",
    "        for size in layer_sizes:\n",
    "            backbone_layers.extend([\n",
    "                nn.BatchNorm1d(prev_size),\n",
    "                nn.Linear(prev_size, size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.hparams.dropout),\n",
    "            ])\n",
    "            prev_size = size\n",
    "        self.backbone = nn.Sequential(*backbone_layers)\n",
    "        self.backbone_output_size = prev_size\n",
    "\n",
    "    def create_head(self, output_dim: int):\n",
    "        # Output layer\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.backbone_output_size),\n",
    "            nn.Linear(self.backbone_output_size, output_dim)\n",
    "        )\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if any(module is m for m in self.head.modules()):\n",
    "                    nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "                else:\n",
    "                    if self.initialization == 'kaiming_uniform':\n",
    "                        nn.init.kaiming_uniform_(module.weight, nonlinearity='relu')\n",
    "                    elif self.initialization == 'kaiming_normal':\n",
    "                        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "                    elif self.initialization == 'xavier_uniform':\n",
    "                        nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                    elif self.initialization == 'xavier_normal':\n",
    "                        nn.init.xavier_normal_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unsupported initialization method: {self.initialization}\")\n",
    "                \n",
    "                # Initialize bias to small values\n",
    "                if module.bias is not None:\n",
    "                    nn.init.uniform_(module.bias, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        # Process categorical variables\n",
    "        embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        embedded = torch.cat(embedded, dim=1)\n",
    "        embedded = self.embedding_dropout_layer(embedded)\n",
    "        \n",
    "        # Concatenate numerical and embedded categorical features\n",
    "        x = torch.cat([x_num, embedded], dim=1)\n",
    "        \n",
    "        # Pass through backbone\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # Pass through head\n",
    "        x = self.head(x)\n",
    "        x = nn.functional.hardtanh(x)\n",
    "\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('valid_loss', loss, prog_bar=True)\n",
    "        # Store targets and predictions for later use\n",
    "        self.validation_targets.append(y)\n",
    "        self.validation_predictions.append(y_hat)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        if len(batch) == 2:\n",
    "            x_num, x_cat = batch\n",
    "        elif len(batch) == 3:\n",
    "            x_num, x_cat, _ = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        return y_hat\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Concatenate all targets and predictions\n",
    "        y = torch.cat(self.validation_targets)\n",
    "        y_hat = torch.cat(self.validation_predictions)\n",
    "        rmse = torch.sqrt(F.mse_loss(y_hat, y))\n",
    "        self.log('val_rmse', rmse, prog_bar=True)\n",
    "        # Clear the lists for next epoch\n",
    "        self.validation_targets.clear()\n",
    "        self.validation_predictions.clear()\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=self.learning_rate, \n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.learning_rate,\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "            pct_start=self.pct_start,\n",
    "            div_factor=self.div_factor,\n",
    "            final_div_factor=self.final_div_factor,\n",
    "            anneal_strategy='cos',\n",
    "            cycle_momentum=True,\n",
    "            base_momentum=0.85,\n",
    "            max_momentum=0.95,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7da48f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:12:37.324034Z",
     "iopub.status.busy": "2024-11-26T15:12:37.323601Z",
     "iopub.status.idle": "2024-11-26T15:12:37.605937Z",
     "shell.execute_reply": "2024-11-26T15:12:37.605004Z"
    },
    "papermill": {
     "duration": 0.289806,
     "end_time": "2024-11-26T15:12:37.608432",
     "exception": false,
     "start_time": "2024-11-26T15:12:37.318626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reconstruct each model\n",
    "trained_models = []\n",
    "\n",
    "for state_dict, hparams in zip(nn_artifacts['models'], nn_artifacts['models_hparams']):\n",
    "    # Create model instance with saved hyperparameters\n",
    "    model = MLP(**hparams)\n",
    "    # Load the saved weights\n",
    "    model.load_state_dict(state_dict)\n",
    "    # Set to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    trained_models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb7561",
   "metadata": {
    "papermill": {
     "duration": 0.003338,
     "end_time": "2024-11-26T15:12:37.615419",
     "exception": false,
     "start_time": "2024-11-26T15:12:37.612081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433bce95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:12:37.624762Z",
     "iopub.status.busy": "2024-11-26T15:12:37.624341Z",
     "iopub.status.idle": "2024-11-26T15:12:38.102581Z",
     "shell.execute_reply": "2024-11-26T15:12:38.101258Z"
    },
    "papermill": {
     "duration": 0.486106,
     "end_time": "2024-11-26T15:12:38.105458",
     "exception": false,
     "start_time": "2024-11-26T15:12:37.619352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import polars\n",
    "import kaggle_evaluation.mcts_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eec16da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:12:38.115416Z",
     "iopub.status.busy": "2024-11-26T15:12:38.114310Z",
     "iopub.status.idle": "2024-11-26T15:12:38.123955Z",
     "shell.execute_reply": "2024-11-26T15:12:38.122845Z"
    },
    "papermill": {
     "duration": 0.016951,
     "end_time": "2024-11-26T15:12:38.126177",
     "exception": false,
     "start_time": "2024-11-26T15:12:38.109226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test: polars.DataFrame, sample_sub: polars.DataFrame):\n",
    "    # Convert Polars DataFrame to Pandas DataFrame\n",
    "    test_pd = test.to_pandas()\n",
    "    \n",
    "    # Process the test data\n",
    "    test_processed = process_test_data(\n",
    "        test_pd,\n",
    "        numerical_cols,\n",
    "        categorical_cols,\n",
    "        encoder,\n",
    "        scaler,\n",
    "        include_position_features = False,\n",
    "        include_text_features = False,\n",
    "    )\n",
    "        \n",
    "    # Initialize an array to store predictions\n",
    "    predictions = np.zeros(len(test_pd))\n",
    "    \n",
    "    # Make predictions using each trained model\n",
    "    for lgbm_encoder,model in zip(lgbm_encoders, trained_models):\n",
    "\n",
    "        # Select relevant features\n",
    "        X_test_num = test_processed[numerical_cols].copy()\n",
    "        X_test_cat = test_processed[categorical_cols].copy()\n",
    "\n",
    "        # Add LGBM encoder leaves features\n",
    "        lgbm_features = lgbm_encoder.transform(\n",
    "            test_processed[numerical_cols+categorical_cols]\n",
    "        )\n",
    "        X_test_cat = pd.concat([X_test_cat, lgbm_features], axis=1)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_test_num_tensor = torch.tensor(\n",
    "                X_test_num[numerical_cols].values, dtype=torch.float32\n",
    "            )\n",
    "            X_test_cat_tensor = torch.tensor(\n",
    "                X_test_cat[_categorical_cols].values, dtype=torch.int32\n",
    "            )\n",
    "            batch_predictions = model(\n",
    "                X_test_num_tensor, X_test_cat_tensor\n",
    "            ).cpu().numpy().flatten()\n",
    "\n",
    "        predictions += batch_predictions\n",
    "    \n",
    "    # Average the predictions\n",
    "    predictions /= len(trained_models)\n",
    "    \n",
    "    # Create the submission DataFrame\n",
    "    submission = sample_sub.with_columns(polars.Series(\"utility_agent1\", predictions))\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aa5ae59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:12:38.135156Z",
     "iopub.status.busy": "2024-11-26T15:12:38.134739Z",
     "iopub.status.idle": "2024-11-26T15:12:38.839070Z",
     "shell.execute_reply": "2024-11-26T15:12:38.837946Z"
    },
    "papermill": {
     "duration": 0.711429,
     "end_time": "2024-11-26T15:12:38.841301",
     "exception": false,
     "start_time": "2024-11-26T15:12:38.129872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Id</th><th>utility_agent1</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>233234</td><td>0.065173</td></tr><tr><td>233235</td><td>-0.044703</td></tr><tr><td>233236</td><td>-0.012284</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬────────────────┐\n",
       "│ Id     ┆ utility_agent1 │\n",
       "│ ---    ┆ ---            │\n",
       "│ i64    ┆ f64            │\n",
       "╞════════╪════════════════╡\n",
       "│ 233234 ┆ 0.065173       │\n",
       "│ 233235 ┆ -0.044703      │\n",
       "│ 233236 ┆ -0.012284      │\n",
       "└────────┴────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "test = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\n",
    "sample_sub = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\")\n",
    "predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a375e8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T15:12:38.851835Z",
     "iopub.status.busy": "2024-11-26T15:12:38.850925Z",
     "iopub.status.idle": "2024-11-26T15:12:39.507045Z",
     "shell.execute_reply": "2024-11-26T15:12:39.505958Z"
    },
    "papermill": {
     "duration": 0.663629,
     "end_time": "2024-11-26T15:12:39.509717",
     "exception": false,
     "start_time": "2024-11-26T15:12:38.846088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e8eed7",
   "metadata": {
    "papermill": {
     "duration": 0.003641,
     "end_time": "2024-11-26T15:12:39.517434",
     "exception": false,
     "start_time": "2024-11-26T15:12:39.513793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9515283,
     "sourceId": 70089,
     "sourceType": "competition"
    },
    {
     "datasetId": 5909723,
     "sourceId": 10020397,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6170268,
     "sourceId": 10020545,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 64.509801,
   "end_time": "2024-11-26T15:12:42.008163",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-26T15:11:37.498362",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
