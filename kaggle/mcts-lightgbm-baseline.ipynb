{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a76e3a15",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-01T15:52:11.722999Z",
     "iopub.status.busy": "2024-11-01T15:52:11.721843Z",
     "iopub.status.idle": "2024-11-01T15:52:15.449938Z",
     "shell.execute_reply": "2024-11-01T15:52:15.448516Z"
    },
    "papermill": {
     "duration": 3.737527,
     "end_time": "2024-11-01T15:52:15.452711",
     "exception": false,
     "start_time": "2024-11-01T15:52:11.715184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightgbm version: 4.2.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/mcts-artifacts\")\n",
    "from preproc import process_test_data\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "\n",
    "print(\"Lightgbm version:\", lgb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7f1fb4",
   "metadata": {
    "papermill": {
     "duration": 0.002985,
     "end_time": "2024-11-01T15:52:15.459315",
     "exception": false,
     "start_time": "2024-11-01T15:52:15.456330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### load artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf28ff50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T15:52:15.467901Z",
     "iopub.status.busy": "2024-11-01T15:52:15.467343Z",
     "iopub.status.idle": "2024-11-01T15:52:15.965613Z",
     "shell.execute_reply": "2024-11-01T15:52:15.964400Z"
    },
    "papermill": {
     "duration": 0.505679,
     "end_time": "2024-11-01T15:52:15.968215",
     "exception": false,
     "start_time": "2024-11-01T15:52:15.462536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OrdinalEncoder from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Specify the path where you want to save the serialized function\n",
    "lightgbm_artifacts_path = '/kaggle/input/mcts-artifacts/lightgbm_predict.pkl'\n",
    "\n",
    "# Load the function from the file\n",
    "with open(lightgbm_artifacts_path, 'rb') as f:\n",
    "    lightgbm_artifacts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbac1698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T15:52:15.976814Z",
     "iopub.status.busy": "2024-11-01T15:52:15.976369Z",
     "iopub.status.idle": "2024-11-01T15:52:15.985660Z",
     "shell.execute_reply": "2024-11-01T15:52:15.984507Z"
    },
    "papermill": {
     "duration": 0.016211,
     "end_time": "2024-11-01T15:52:15.987904",
     "exception": false,
     "start_time": "2024-11-01T15:52:15.971693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelInference:\n",
    "    def __init__(self, models, numerical_cols, categorical_cols, encoder, scaler):\n",
    "        \"\"\"Initialize inference class with trained artifacts\n",
    "        \n",
    "        Args:\n",
    "            models: List of trained LightGBM models\n",
    "            numerical_cols: List of numerical column names\n",
    "            categorical_cols: List of categorical column names\n",
    "            encoder: Fitted OrdinalEncoder for categorical features\n",
    "            scaler: Fitted StandardScaler for numerical features (optional)\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.encoder = encoder\n",
    "        self.scaler = scaler\n",
    "        \n",
    "    def predict(self, df_test):\n",
    "        \"\"\"Make predictions on test data\n",
    "        \n",
    "        Args:\n",
    "            df_test: pandas DataFrame containing test features\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of predictions\n",
    "        \"\"\"\n",
    "        # Preprocess test data\n",
    "        test_processed = process_test_data(\n",
    "            df_test,\n",
    "            self.numerical_cols,\n",
    "            self.categorical_cols,\n",
    "            self.encoder,\n",
    "            self.scaler\n",
    "        )\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        predictions = [\n",
    "            model.predict(test_processed[self.numerical_cols + self.categorical_cols])\n",
    "            for model in self.models\n",
    "        ]\n",
    "        \n",
    "        # Average and clip predictions\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "        predictions = np.clip(predictions, -1, 1)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "model_lgbm = ModelInference(**lightgbm_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5677962c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T15:52:15.996944Z",
     "iopub.status.busy": "2024-11-01T15:52:15.995988Z",
     "iopub.status.idle": "2024-11-01T15:52:16.170640Z",
     "shell.execute_reply": "2024-11-01T15:52:16.169596Z"
    },
    "papermill": {
     "duration": 0.181871,
     "end_time": "2024-11-01T15:52:16.173230",
     "exception": false,
     "start_time": "2024-11-01T15:52:15.991359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12646345, -0.17040403, -0.06733033])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "test = pd.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\n",
    "model_lgbm.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae83397",
   "metadata": {
    "papermill": {
     "duration": 0.003401,
     "end_time": "2024-11-01T15:52:16.180256",
     "exception": false,
     "start_time": "2024-11-01T15:52:16.176855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abaa722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T15:52:16.188845Z",
     "iopub.status.busy": "2024-11-01T15:52:16.188446Z",
     "iopub.status.idle": "2024-11-01T15:52:16.857751Z",
     "shell.execute_reply": "2024-11-01T15:52:16.856622Z"
    },
    "papermill": {
     "duration": 0.676585,
     "end_time": "2024-11-01T15:52:16.860424",
     "exception": false,
     "start_time": "2024-11-01T15:52:16.183839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import kaggle_evaluation.mcts_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16fbbeb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T15:52:16.870140Z",
     "iopub.status.busy": "2024-11-01T15:52:16.869481Z",
     "iopub.status.idle": "2024-11-01T15:52:16.875821Z",
     "shell.execute_reply": "2024-11-01T15:52:16.874674Z"
    },
    "papermill": {
     "duration": 0.014065,
     "end_time": "2024-11-01T15:52:16.878421",
     "exception": false,
     "start_time": "2024-11-01T15:52:16.864356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame, sample_sub: pl.DataFrame):\n",
    "    test_pd = test.to_pandas()\n",
    "    predictions = model_lgbm.predict(test_pd)\n",
    "    submission = sample_sub.with_columns(pl.Series(\"utility_agent1\", predictions))\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0861a1da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-01T15:52:16.887139Z",
     "iopub.status.busy": "2024-11-01T15:52:16.886721Z",
     "iopub.status.idle": "2024-11-01T15:52:17.398646Z",
     "shell.execute_reply": "2024-11-01T15:52:17.397387Z"
    },
    "papermill": {
     "duration": 0.519396,
     "end_time": "2024-11-01T15:52:17.401461",
     "exception": false,
     "start_time": "2024-11-01T15:52:16.882065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef678e",
   "metadata": {
    "papermill": {
     "duration": 0.003264,
     "end_time": "2024-11-01T15:52:17.408596",
     "exception": false,
     "start_time": "2024-11-01T15:52:17.405332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9515283,
     "sourceId": 70089,
     "sourceType": "competition"
    },
    {
     "datasetId": 5909723,
     "sourceId": 9775671,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.282392,
   "end_time": "2024-11-01T15:52:18.134848",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-01T15:52:08.852456",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
