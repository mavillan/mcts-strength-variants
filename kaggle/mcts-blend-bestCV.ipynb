{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19131e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:15:54.345804Z",
     "iopub.status.busy": "2024-12-02T22:15:54.344895Z",
     "iopub.status.idle": "2024-12-02T22:19:28.829973Z",
     "shell.execute_reply": "2024-12-02T22:19:28.829070Z"
    },
    "papermill": {
     "duration": 214.496719,
     "end_time": "2024-12-02T22:19:28.832240",
     "exception": false,
     "start_time": "2024-12-02T22:15:54.335521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/working/antlr4-python3-runtime-4.9.3\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=2e31b5c01074854c278d637e859705c9af57cd8b1f43363cf27854bd8f634122\n",
      "  Stored in directory: /root/.cache/pip/wheels/08/67/2a/c8a92440bcfa6a48a4e0b84bd0f5ffbf135907bacb6ee4ae0e\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime\n",
      "Successfully installed antlr4-python3-runtime-4.9.3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install -qq /kaggle/input/wheels/lightning-2.4.0-py3-none-any.whl;\n",
    "\n",
    "pip install --no-deps -qq /kaggle/input/wheels/omegaconf-2.3.0-py3-none-any.whl;\n",
    "pip install --no-deps -qq /kaggle/input/wheels/einops-0.7.0-py3-none-any.whl;\n",
    "\n",
    "cp -r /kaggle/input/wheels/antlr4-python3-runtime-4.9.3/antlr4-python3-runtime-4.9.3 /kaggle/working/;\n",
    "cd /kaggle/working/antlr4-python3-runtime-4.9.3;\n",
    "pip install . --user;\n",
    "\n",
    "pip install --no-deps -qq /kaggle/input/wheels/pytorch_tabnet-4.1.0-py3-none-any.whl;\n",
    "pip install --no-deps -qq /kaggle/input/wheels/pytorch_tabular-1.1.1-py2.py3-none-any.whl;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c651ce",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:28.848405Z",
     "iopub.status.busy": "2024-12-02T22:19:28.848112Z",
     "iopub.status.idle": "2024-12-02T22:19:41.357966Z",
     "shell.execute_reply": "2024-12-02T22:19:41.356991Z"
    },
    "papermill": {
     "duration": 12.519574,
     "end_time": "2024-12-02T22:19:41.359784",
     "exception": false,
     "start_time": "2024-12-02T22:19:28.840210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cb.__version__: 1.2.7\n",
      "Lightgbm version: 4.2.0\n",
      "xgb.__version__: 2.0.3\n",
      "PyTorch version: 2.4.0\n",
      "PyTorch Lightning version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Callable\n",
    "import polars\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import catboost as cb\n",
    "print(\"cb.__version__:\", cb.__version__)\n",
    "\n",
    "import lightgbm as lgb\n",
    "print(\"Lightgbm version:\", lgb.__version__)\n",
    "\n",
    "import xgboost as xgb\n",
    "print(\"xgb.__version__:\", xgb.__version__)\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from pytorch_tabular.models.common.layers import GatedFeatureLearningUnit\n",
    "from pytorch_tabular.models.common.layers.activations import t_softmax\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pl.__version__}\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/input/mcts-artifacts\")\n",
    "from preproc import process_test_data\n",
    "import kaggle_evaluation.mcts_inference_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9220d4d",
   "metadata": {
    "papermill": {
     "duration": 0.006909,
     "end_time": "2024-12-02T22:19:41.374147",
     "exception": false,
     "start_time": "2024-12-02T22:19:41.367238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### 1dcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810e4e8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:41.389365Z",
     "iopub.status.busy": "2024-12-02T22:19:41.389085Z",
     "iopub.status.idle": "2024-12-02T22:19:43.813003Z",
     "shell.execute_reply": "2024-12-02T22:19:43.811871Z"
    },
    "papermill": {
     "duration": 2.434123,
     "end_time": "2024-12-02T22:19:43.815243",
     "exception": false,
     "start_time": "2024-12-02T22:19:41.381120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OrdinalEncoder from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the path where you want to save the serialized function\n",
    "\n",
    "nn_1dcnn_artifacts_path = '/kaggle/input/mcts-artifacts/nn-1dcnn_predict_uni80.pt'\n",
    "# nn_1dcnn_artifacts_path = '/kaggle/input/mcts-artifacts/nn-1dcnn_predict_uni95.pt'\n",
    "# nn_1dcnn_artifacts_path = '/kaggle/input/mcts-artifacts/nn-1dcnn_predict_full.pt'\n",
    "\n",
    "# Load the function from the file\n",
    "nn_1dcnn_artifacts = torch.load(nn_1dcnn_artifacts_path, weights_only=False)\n",
    "\n",
    "len(nn_1dcnn_artifacts['models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46d3fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:43.831744Z",
     "iopub.status.busy": "2024-12-02T22:19:43.831469Z",
     "iopub.status.idle": "2024-12-02T22:19:43.854095Z",
     "shell.execute_reply": "2024-12-02T22:19:43.853351Z"
    },
    "papermill": {
     "duration": 0.033034,
     "end_time": "2024-12-02T22:19:43.855781",
     "exception": false,
     "start_time": "2024-12-02T22:19:43.822747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SoftOrdering1DCNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "            num_input_dim: int,\n",
    "            cat_input_dims: list[int],\n",
    "            output_dim: int,\n",
    "            sign_size: int = 32,\n",
    "            cha_input: int = 16, \n",
    "            cha_hidden: int = 32,\n",
    "            K: int = 2,\n",
    "            dropout_input: float = 0.2,\n",
    "            dropout_hidden: float = 0.2, \n",
    "            dropout_output: float = 0.2,\n",
    "            embedding_dropout: float = 0.2,\n",
    "            learning_rate: float = 1e-3,\n",
    "            weight_decay: float = 1e-5,\n",
    "            embedding_dim: Optional[List[int]] = None,\n",
    "            pct_start: float = 0.2,\n",
    "            div_factor: float = 10.0,\n",
    "            final_div_factor: float = 1e4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Initialize embedding dimensions if not provided\n",
    "        if embedding_dim is None:\n",
    "            embedding_dim = [min(50, int(1 + np.ceil(np.sqrt(dim)))) for dim in cat_input_dims]\n",
    "        elif len(embedding_dim) != len(cat_input_dims):\n",
    "            raise ValueError(\"Length of embedding_dim must match number of categorical features.\")\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_dropout = embedding_dropout\n",
    "        \n",
    "        # Create embedding layers\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(dim, emb_dim) for dim, emb_dim in zip(cat_input_dims, embedding_dim)]\n",
    "        )\n",
    "        self.embedding_dropout_layer = nn.Dropout(self.embedding_dropout)\n",
    "\n",
    "        # Calculate total input dimension after embeddings\n",
    "        total_embedding_dim = sum(self.embedding_dim)\n",
    "        total_input_dim = num_input_dim + total_embedding_dim\n",
    "\n",
    "        # CNN architecture parameters\n",
    "        hidden_size = sign_size * cha_input\n",
    "        self.sign_size1 = sign_size\n",
    "        self.sign_size2 = sign_size//2\n",
    "        self.output_size = (sign_size//4) * cha_hidden\n",
    "        self.cha_input = cha_input\n",
    "        self.cha_hidden = cha_hidden\n",
    "        self.K = K\n",
    "\n",
    "        # Input projection\n",
    "        self.batch_norm1 = nn.BatchNorm1d(total_input_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_input)\n",
    "        dense1 = nn.Linear(total_input_dim, hidden_size, bias=False)\n",
    "        self.dense1 = nn.utils.weight_norm(dense1)\n",
    "\n",
    "        # 1st conv layer\n",
    "        self.batch_norm_c1 = nn.BatchNorm1d(cha_input)\n",
    "        conv1 = nn.Conv1d(\n",
    "            cha_input, \n",
    "            cha_input*K, \n",
    "            kernel_size=5, \n",
    "            stride=1, \n",
    "            padding=2,  \n",
    "            groups=cha_input, \n",
    "            bias=False)\n",
    "        self.conv1 = nn.utils.weight_norm(conv1, dim=None)\n",
    "        self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size=self.sign_size2)\n",
    "\n",
    "        # 2nd conv layer\n",
    "        self.batch_norm_c2 = nn.BatchNorm1d(cha_input*K)\n",
    "        self.dropout_c2 = nn.Dropout(dropout_hidden)\n",
    "        conv2 = nn.Conv1d(\n",
    "            cha_input*K, \n",
    "            cha_hidden, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1, \n",
    "            bias=False)\n",
    "        self.conv2 = nn.utils.weight_norm(conv2, dim=None)\n",
    "\n",
    "        # 3rd conv layer\n",
    "        self.batch_norm_c3 = nn.BatchNorm1d(cha_hidden)\n",
    "        self.dropout_c3 = nn.Dropout(dropout_hidden)\n",
    "        conv3 = nn.Conv1d(\n",
    "            cha_hidden, \n",
    "            cha_hidden, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1, \n",
    "            bias=False)\n",
    "        self.conv3 = nn.utils.weight_norm(conv3, dim=None)\n",
    "\n",
    "        # 4th conv layer\n",
    "        self.batch_norm_c4 = nn.BatchNorm1d(cha_hidden)\n",
    "        conv4 = nn.Conv1d(\n",
    "            cha_hidden, \n",
    "            cha_hidden, \n",
    "            kernel_size=5, \n",
    "            stride=1, \n",
    "            padding=2, \n",
    "            groups=cha_hidden, \n",
    "            bias=False)\n",
    "        self.conv4 = nn.utils.weight_norm(conv4, dim=None)\n",
    "\n",
    "        self.avg_po_c4 = nn.AvgPool1d(kernel_size=4, stride=2, padding=1)\n",
    "        self.flt = nn.Flatten()\n",
    "\n",
    "        # Output head\n",
    "        self.batch_norm2 = nn.BatchNorm1d(self.output_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_output)\n",
    "        dense2 = nn.Linear(self.output_size, output_dim, bias=False)\n",
    "        self.dense2 = nn.utils.weight_norm(dense2)\n",
    "\n",
    "        # Training parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.pct_start = pct_start\n",
    "        self.div_factor = div_factor\n",
    "        self.final_div_factor = final_div_factor\n",
    "\n",
    "        # Initialize lists to store validation outputs\n",
    "        self.validation_targets = []\n",
    "        self.validation_predictions = []\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        # Process categorical variables\n",
    "        embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        embedded = torch.cat(embedded, dim=1)\n",
    "        embedded = self.embedding_dropout_layer(embedded)\n",
    "        \n",
    "        # Concatenate numerical and embedded categorical features\n",
    "        x = torch.cat([x_num, embedded], dim=1)\n",
    "\n",
    "        # Input projection\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = nn.functional.celu(self.dense1(x))\n",
    "\n",
    "        # Reshape for CNN\n",
    "        x = x.reshape(x.shape[0], self.cha_input, self.sign_size1)\n",
    "\n",
    "        # CNN backbone\n",
    "        x = self.batch_norm_c1(x)\n",
    "        x = nn.functional.leaky_relu(self.conv1(x))\n",
    "        x = self.ave_po_c1(x)\n",
    "\n",
    "        x = self.batch_norm_c2(x)\n",
    "        x = self.dropout_c2(x)\n",
    "        x = nn.functional.leaky_relu(self.conv2(x))\n",
    "        x_s = x\n",
    "\n",
    "        x = self.batch_norm_c3(x)\n",
    "        x = self.dropout_c3(x)\n",
    "        x = nn.functional.leaky_relu(self.conv3(x))\n",
    "\n",
    "        x = self.batch_norm_c4(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x + x_s\n",
    "        x = nn.functional.leaky_relu(x)\n",
    "\n",
    "        x = self.avg_po_c4(x)\n",
    "        x = self.flt(x)\n",
    "\n",
    "        # Output head\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.dense2(x)\n",
    "        x = nn.functional.hardtanh(x)\n",
    "\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('valid_loss', loss, prog_bar=True)\n",
    "        # Store targets and predictions for later use\n",
    "        self.validation_targets.append(y)\n",
    "        self.validation_predictions.append(y_hat)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        if len(batch) == 2:\n",
    "            x_num, x_cat = batch\n",
    "        elif len(batch) == 3:\n",
    "            x_num, x_cat, _ = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        return y_hat\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Concatenate all targets and predictions\n",
    "        y = torch.cat(self.validation_targets)\n",
    "        y_hat = torch.cat(self.validation_predictions)\n",
    "        rmse = torch.sqrt(F.mse_loss(y_hat, y))\n",
    "        self.log('val_rmse', rmse, prog_bar=True)\n",
    "        # Clear the lists for next epoch\n",
    "        self.validation_targets.clear()\n",
    "        self.validation_predictions.clear()\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=self.learning_rate, \n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.learning_rate,\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "            pct_start=self.pct_start,\n",
    "            div_factor=self.div_factor,\n",
    "            final_div_factor=self.final_div_factor,\n",
    "            anneal_strategy='cos',\n",
    "            cycle_momentum=True,\n",
    "            base_momentum=0.85,\n",
    "            max_momentum=0.95,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54876b84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:43.872074Z",
     "iopub.status.busy": "2024-12-02T22:19:43.871796Z",
     "iopub.status.idle": "2024-12-02T22:19:44.557178Z",
     "shell.execute_reply": "2024-12-02T22:19:44.556263Z"
    },
    "papermill": {
     "duration": 0.695761,
     "end_time": "2024-12-02T22:19:44.559088",
     "exception": false,
     "start_time": "2024-12-02T22:19:43.863327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(numerical_cols): 215\n",
      "len(categorical_cols): 8\n"
     ]
    }
   ],
   "source": [
    "class SoftOrdering1DCNNInference:\n",
    "    def __init__(\n",
    "        self,\n",
    "        models_state_dicts,\n",
    "        models_hparams,\n",
    "        numerical_cols,\n",
    "        categorical_cols,\n",
    "        encoder,\n",
    "        scaler,\n",
    "        lgbm_encoders,\n",
    "    ):\n",
    "        \"\"\"Initialize inference class with trained artifacts\n",
    "        \n",
    "        Args:\n",
    "            models_state_dicts: List of model state dictionaries\n",
    "            models_hparams: List of model hyperparameters\n",
    "            numerical_cols: List of numerical column names\n",
    "            categorical_cols: List of categorical column names\n",
    "            encoder: Fitted OrdinalEncoder for categorical features\n",
    "            scaler: Fitted StandardScaler for numerical features\n",
    "            lgbm_encoders: List of LightGBM encoders for feature engineering\n",
    "        \"\"\"\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.encoder = encoder\n",
    "        self.scaler = scaler\n",
    "        self.lgbm_encoders = lgbm_encoders\n",
    "\n",
    "        # Load models\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.models = []\n",
    "        for state_dict, hparams in zip(models_state_dicts, models_hparams):\n",
    "            model = SoftOrdering1DCNN(**hparams)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(self.device)  # Move model to GPU\n",
    "            model.eval()  # Set to evaluation mode\n",
    "            self.models.append(model)\n",
    "\n",
    "        print(\"len(numerical_cols):\", len(numerical_cols))\n",
    "        print(\"len(categorical_cols):\", len(categorical_cols))\n",
    "\n",
    "    def predict_array(self, df_test, batch_size=4096):\n",
    "        \"\"\"Make predictions on test data using DataLoader\n",
    "        \n",
    "        Args:\n",
    "            df_test: pandas DataFrame containing test features\n",
    "            batch_size: size of batches for inference\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of predictions\n",
    "        \"\"\"\n",
    "        # Preprocess test data\n",
    "        test_processed = process_test_data(\n",
    "            df_test,\n",
    "            self.numerical_cols,\n",
    "            self.categorical_cols,\n",
    "            self.encoder,\n",
    "            self.scaler,\n",
    "            include_position_features=False,\n",
    "            include_text_features=False,\n",
    "        )\n",
    "\n",
    "        # Initialize predictions array\n",
    "        predictions = np.zeros(len(df_test))\n",
    "\n",
    "        # Get predictions from all models\n",
    "        for lgbm_encoder, model in zip(self.lgbm_encoders, self.models):\n",
    "            # Prepare numerical and categorical features\n",
    "            X_test_num = test_processed[self.numerical_cols].copy()\n",
    "            X_test_cat = test_processed[self.categorical_cols].copy()\n",
    "\n",
    "            # Add LGBM encoder leaves features\n",
    "            lgbm_features = lgbm_encoder.transform(\n",
    "                test_processed[self.numerical_cols + self.categorical_cols]\n",
    "            )\n",
    "            X_test_cat = pd.concat([X_test_cat, lgbm_features], axis=1)\n",
    "            _categorical_cols = self.categorical_cols + lgbm_encoder.new_columns\n",
    "\n",
    "            # Create tensors\n",
    "            X_num_tensor = torch.tensor(\n",
    "                X_test_num[self.numerical_cols].values, \n",
    "                dtype=torch.float32,\n",
    "                device=self.device\n",
    "            )\n",
    "            X_cat_tensor = torch.tensor(\n",
    "                X_test_cat[_categorical_cols].values, \n",
    "                dtype=torch.int32,\n",
    "                device=self.device\n",
    "            )\n",
    "            \n",
    "            # Create TensorDataset and DataLoader\n",
    "            dataset = torch.utils.data.TensorDataset(\n",
    "                X_num_tensor, \n",
    "                X_cat_tensor\n",
    "            )\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                dataset, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=False\n",
    "            )\n",
    "            \n",
    "            # Process batches using DataLoader\n",
    "            batch_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for X_num_batch, X_cat_batch in dataloader:\n",
    "                    pred_batch = model(X_num_batch, X_cat_batch).cpu()\n",
    "                    batch_predictions.append(pred_batch)\n",
    "\n",
    "            # Concatenate all batch predictions\n",
    "            model_predictions = torch.cat(batch_predictions).numpy().flatten()\n",
    "            predictions += model_predictions\n",
    "\n",
    "        # Average predictions across models\n",
    "        predictions /= len(self.models)\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, test: polars.DataFrame, sample_sub: polars.DataFrame):\n",
    "        test_pd = test.to_pandas().fillna(0)\n",
    "        predictions = self.predict_array(test_pd)\n",
    "        submission = sample_sub.with_columns(polars.Series(\"utility_agent1\", predictions))\n",
    "        return submission\n",
    "\n",
    "\n",
    "# Create inference class\n",
    "model_1dcnn = SoftOrdering1DCNNInference(\n",
    "    models_state_dicts=nn_1dcnn_artifacts['models'],\n",
    "    models_hparams=nn_1dcnn_artifacts['models_hparams'],\n",
    "    numerical_cols=nn_1dcnn_artifacts['numerical_cols'],\n",
    "    categorical_cols=nn_1dcnn_artifacts['categorical_cols'],\n",
    "    encoder=nn_1dcnn_artifacts['encoder'],\n",
    "    scaler=nn_1dcnn_artifacts['scaler'],\n",
    "    lgbm_encoders=nn_1dcnn_artifacts['lgbm_encoders'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81defd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:44.575478Z",
     "iopub.status.busy": "2024-12-02T22:19:44.575137Z",
     "iopub.status.idle": "2024-12-02T22:19:46.212146Z",
     "shell.execute_reply": "2024-12-02T22:19:46.211385Z"
    },
    "papermill": {
     "duration": 1.647197,
     "end_time": "2024-12-02T22:19:46.214040",
     "exception": false,
     "start_time": "2024-12-02T22:19:44.566843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2413545367.py:118: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_pd = test.to_pandas().fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Id</th><th>utility_agent1</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>233234</td><td>0.136913</td></tr><tr><td>233235</td><td>-0.139139</td></tr><tr><td>233236</td><td>-0.040731</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬────────────────┐\n",
       "│ Id     ┆ utility_agent1 │\n",
       "│ ---    ┆ ---            │\n",
       "│ i64    ┆ f64            │\n",
       "╞════════╪════════════════╡\n",
       "│ 233234 ┆ 0.136913       │\n",
       "│ 233235 ┆ -0.139139      │\n",
       "│ 233236 ┆ -0.040731      │\n",
       "└────────┴────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check #1\n",
    "test = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\n",
    "sample_sub = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\")\n",
    "model_1dcnn.predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5887d061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:46.230692Z",
     "iopub.status.busy": "2024-12-02T22:19:46.230395Z",
     "iopub.status.idle": "2024-12-02T22:19:46.234098Z",
     "shell.execute_reply": "2024-12-02T22:19:46.233285Z"
    },
    "papermill": {
     "duration": 0.014123,
     "end_time": "2024-12-02T22:19:46.236112",
     "exception": false,
     "start_time": "2024-12-02T22:19:46.221989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sanity check #2\n",
    "# train = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\")\n",
    "# test = train.drop(['num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1', 'utility_agent1'])\n",
    "# sample_sub = train.select(['Id', 'utility_agent1'])\n",
    "# model_1dcnn.predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6cad4",
   "metadata": {
    "papermill": {
     "duration": 0.007598,
     "end_time": "2024-12-02T22:19:46.254540",
     "exception": false,
     "start_time": "2024-12-02T22:19:46.246942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c527c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:46.271242Z",
     "iopub.status.busy": "2024-12-02T22:19:46.270639Z",
     "iopub.status.idle": "2024-12-02T22:19:47.649900Z",
     "shell.execute_reply": "2024-12-02T22:19:47.648730Z"
    },
    "papermill": {
     "duration": 1.389548,
     "end_time": "2024-12-02T22:19:47.651721",
     "exception": false,
     "start_time": "2024-12-02T22:19:46.262173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OrdinalEncoder from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the path where you want to save the serialized function\n",
    "\n",
    "nn_mlp_artifacts_path = '/kaggle/input/mcts-artifacts/nn-mlp_predict_uni80.pt'\n",
    "# nn_mlp_artifacts_path = '/kaggle/input/mcts-artifacts/nn-mlp_predict_uni95.pt'\n",
    "# nn_mlp_artifacts_path = '/kaggle/input/mcts-artifacts/nn-mlp_predict_full.pt'\n",
    "\n",
    "# Load the function from the file\n",
    "nn_mlp_artifacts = torch.load(nn_mlp_artifacts_path, weights_only=False)\n",
    "\n",
    "len(nn_mlp_artifacts['models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2021b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:47.669445Z",
     "iopub.status.busy": "2024-12-02T22:19:47.669114Z",
     "iopub.status.idle": "2024-12-02T22:19:47.693404Z",
     "shell.execute_reply": "2024-12-02T22:19:47.692726Z"
    },
    "papermill": {
     "duration": 0.035152,
     "end_time": "2024-12-02T22:19:47.695084",
     "exception": false,
     "start_time": "2024-12-02T22:19:47.659932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "            num_input_dim: int,\n",
    "            cat_input_dims: list[int],\n",
    "            output_dim: int,\n",
    "            layers: str,\n",
    "            dropout: float,\n",
    "            embedding_dropout: float,\n",
    "            learning_rate: float = 1e-3,\n",
    "            weight_decay: float = 1e-5,\n",
    "            initialization: str = 'kaiming_uniform',\n",
    "            embedding_dim: Optional[List[int]] = None,\n",
    "            pct_start: float = 0.2,\n",
    "            div_factor: float = 10.0,\n",
    "            final_div_factor: float = 1e4,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.dropout = dropout\n",
    "        self.embedding_dropout = embedding_dropout\n",
    "        self.pct_start = pct_start\n",
    "        self.div_factor = div_factor\n",
    "        self.final_div_factor = final_div_factor\n",
    "\n",
    "        # Initialize embedding dimensions if not provided\n",
    "        if embedding_dim is None:\n",
    "            # Rule of thumb: min(50, num_unique // 2 + 1) for each categorical feature\n",
    "            embedding_dim = [min(50, int(1 + np.ceil(np.sqrt(dim)))) for dim in cat_input_dims]\n",
    "\n",
    "        elif len(embedding_dim) != len(cat_input_dims):\n",
    "            raise ValueError(\"Length of embedding_dim must match number of categorical features.\")\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Create embedding layers\n",
    "        self.create_embeddings(cat_input_dims, embedding_dim)\n",
    "\n",
    "        # Create backbone layers\n",
    "        self.create_backbone(num_input_dim, layers)\n",
    "\n",
    "        # Create head layers\n",
    "        self.create_head(output_dim)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.initialization = initialization\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "        # Initialize lists to store validation outputs\n",
    "        self.validation_targets = []\n",
    "        self.validation_predictions = []\n",
    "\n",
    "    def create_embeddings(self, cat_input_dims: list[int], embedding_dim: list[int]):\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(dim, emb_dim) for dim, emb_dim in zip(cat_input_dims, embedding_dim)]\n",
    "        )\n",
    "        self.embedding_dropout_layer = nn.Dropout(self.embedding_dropout)\n",
    "\n",
    "    def create_backbone(self, num_input_dim: int, layers: str):\n",
    "        # Calculate total input dimension after embeddings\n",
    "        total_embedding_dim = sum(self.embedding_dim)\n",
    "        total_input_dim = num_input_dim + total_embedding_dim\n",
    "\n",
    "        # Parse layers string\n",
    "        layer_sizes = [int(size) for size in layers.split('-')]\n",
    "\n",
    "        # Create backbone network layers\n",
    "        backbone_layers = []\n",
    "        prev_size = total_input_dim\n",
    "        for size in layer_sizes:\n",
    "            backbone_layers.extend([\n",
    "                nn.BatchNorm1d(prev_size),\n",
    "                nn.Linear(prev_size, size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.hparams.dropout),\n",
    "            ])\n",
    "            prev_size = size\n",
    "        self.backbone = nn.Sequential(*backbone_layers)\n",
    "        self.backbone_output_size = prev_size\n",
    "\n",
    "    def create_head(self, output_dim: int):\n",
    "        # Output layer\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.backbone_output_size),\n",
    "            nn.Linear(self.backbone_output_size, output_dim)\n",
    "        )\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if any(module is m for m in self.head.modules()):\n",
    "                    nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "                else:\n",
    "                    if self.initialization == 'kaiming_uniform':\n",
    "                        nn.init.kaiming_uniform_(module.weight, nonlinearity='relu')\n",
    "                    elif self.initialization == 'kaiming_normal':\n",
    "                        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "                    elif self.initialization == 'xavier_uniform':\n",
    "                        nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                    elif self.initialization == 'xavier_normal':\n",
    "                        nn.init.xavier_normal_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unsupported initialization method: {self.initialization}\")\n",
    "                \n",
    "                # Initialize bias to small values\n",
    "                if module.bias is not None:\n",
    "                    nn.init.uniform_(module.bias, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        # Process categorical variables\n",
    "        embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        embedded = torch.cat(embedded, dim=1)\n",
    "        embedded = self.embedding_dropout_layer(embedded)\n",
    "        \n",
    "        # Concatenate numerical and embedded categorical features\n",
    "        x = torch.cat([x_num, embedded], dim=1)\n",
    "        \n",
    "        # Pass through backbone\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # Pass through head\n",
    "        x = self.head(x)\n",
    "        x = nn.functional.hardtanh(x)\n",
    "\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('valid_loss', loss, prog_bar=True)\n",
    "        # Store targets and predictions for later use\n",
    "        self.validation_targets.append(y)\n",
    "        self.validation_predictions.append(y_hat)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        if len(batch) == 2:\n",
    "            x_num, x_cat = batch\n",
    "        elif len(batch) == 3:\n",
    "            x_num, x_cat, _ = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        return y_hat\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Concatenate all targets and predictions\n",
    "        y = torch.cat(self.validation_targets)\n",
    "        y_hat = torch.cat(self.validation_predictions)\n",
    "        rmse = torch.sqrt(F.mse_loss(y_hat, y))\n",
    "        self.log('val_rmse', rmse, prog_bar=True)\n",
    "        # Clear the lists for next epoch\n",
    "        self.validation_targets.clear()\n",
    "        self.validation_predictions.clear()\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=self.learning_rate, \n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.learning_rate,\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "            pct_start=self.pct_start,\n",
    "            div_factor=self.div_factor,\n",
    "            final_div_factor=self.final_div_factor,\n",
    "            anneal_strategy='cos',\n",
    "            cycle_momentum=True,\n",
    "            base_momentum=0.85,\n",
    "            max_momentum=0.95,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f192022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:47.717559Z",
     "iopub.status.busy": "2024-12-02T22:19:47.717233Z",
     "iopub.status.idle": "2024-12-02T22:19:48.333125Z",
     "shell.execute_reply": "2024-12-02T22:19:48.331984Z"
    },
    "papermill": {
     "duration": 0.628806,
     "end_time": "2024-12-02T22:19:48.335011",
     "exception": false,
     "start_time": "2024-12-02T22:19:47.706205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(numerical_cols): 215\n",
      "len(categorical_cols): 8\n"
     ]
    }
   ],
   "source": [
    "class MLPInference:\n",
    "    def __init__(\n",
    "        self,\n",
    "        models_state_dicts,\n",
    "        models_hparams,\n",
    "        numerical_cols,\n",
    "        categorical_cols,\n",
    "        encoder,\n",
    "        scaler,\n",
    "        lgbm_encoders,\n",
    "    ):\n",
    "        \"\"\"Initialize inference class with trained artifacts\n",
    "        \n",
    "        Args:\n",
    "            models_state_dicts: List of model state dictionaries\n",
    "            models_hparams: List of model hyperparameters\n",
    "            numerical_cols: List of numerical column names\n",
    "            categorical_cols: List of categorical column names\n",
    "            encoder: Fitted OrdinalEncoder for categorical features\n",
    "            scaler: Fitted StandardScaler for numerical features\n",
    "            lgbm_encoders: List of LightGBM encoders for feature engineering\n",
    "        \"\"\"\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.encoder = encoder\n",
    "        self.scaler = scaler\n",
    "        self.lgbm_encoders = lgbm_encoders\n",
    "\n",
    "        # Load models\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.models = []\n",
    "        for state_dict, hparams in zip(models_state_dicts, models_hparams):\n",
    "            model = MLP(**hparams)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(self.device)  # Move model to GPU\n",
    "            model.eval()  # Set to evaluation mode\n",
    "            self.models.append(model)\n",
    "\n",
    "        print(\"len(numerical_cols):\", len(numerical_cols))\n",
    "        print(\"len(categorical_cols):\", len(categorical_cols))\n",
    "\n",
    "    def predict_array(self, df_test, batch_size=4096):\n",
    "        \"\"\"Make predictions on test data using DataLoader\n",
    "        \n",
    "        Args:\n",
    "            df_test: pandas DataFrame containing test features\n",
    "            batch_size: size of batches for inference\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of predictions\n",
    "        \"\"\"\n",
    "        # Preprocess test data\n",
    "        test_processed = process_test_data(\n",
    "            df_test,\n",
    "            self.numerical_cols,\n",
    "            self.categorical_cols,\n",
    "            self.encoder,\n",
    "            self.scaler,\n",
    "            include_position_features=False,\n",
    "            include_text_features=False,\n",
    "        )\n",
    "\n",
    "        # Initialize predictions array\n",
    "        predictions = np.zeros(len(df_test))\n",
    "\n",
    "        # Get predictions from all models\n",
    "        for lgbm_encoder, model in zip(self.lgbm_encoders, self.models):\n",
    "            # Prepare numerical and categorical features\n",
    "            X_test_num = test_processed[self.numerical_cols].copy()\n",
    "            X_test_cat = test_processed[self.categorical_cols].copy()\n",
    "\n",
    "            # Add LGBM encoder leaves features\n",
    "            lgbm_features = lgbm_encoder.transform(\n",
    "                test_processed[self.numerical_cols + self.categorical_cols]\n",
    "            )\n",
    "            X_test_cat = pd.concat([X_test_cat, lgbm_features], axis=1)\n",
    "            _categorical_cols = self.categorical_cols + lgbm_encoder.new_columns\n",
    "\n",
    "            # Create tensors\n",
    "            X_num_tensor = torch.tensor(\n",
    "                X_test_num[self.numerical_cols].values, \n",
    "                dtype=torch.float32,\n",
    "                device=self.device\n",
    "            )\n",
    "            X_cat_tensor = torch.tensor(\n",
    "                X_test_cat[_categorical_cols].values, \n",
    "                dtype=torch.int32,\n",
    "                device=self.device,\n",
    "            )\n",
    "            \n",
    "            # Create TensorDataset and DataLoader\n",
    "            dataset = torch.utils.data.TensorDataset(\n",
    "                X_num_tensor, \n",
    "                X_cat_tensor\n",
    "            )\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                dataset, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=False\n",
    "            )\n",
    "            \n",
    "            # Process batches using DataLoader\n",
    "            batch_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for X_num_batch, X_cat_batch in dataloader:\n",
    "                    pred_batch = model(X_num_batch, X_cat_batch).cpu()\n",
    "                    batch_predictions.append(pred_batch)\n",
    "\n",
    "            # Concatenate all batch predictions\n",
    "            model_predictions = torch.cat(batch_predictions).numpy().flatten()\n",
    "            predictions += model_predictions\n",
    "\n",
    "        # Average predictions across models\n",
    "        predictions /= len(self.models)\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, test: polars.DataFrame, sample_sub: polars.DataFrame):\n",
    "        test_pd = test.to_pandas().fillna(0)\n",
    "        predictions = self.predict_array(test_pd)\n",
    "        submission = sample_sub.with_columns(polars.Series(\"utility_agent1\", predictions))\n",
    "        return submission\n",
    "\n",
    "\n",
    "# Create inference class\n",
    "model_mlp = MLPInference(\n",
    "    models_state_dicts=nn_mlp_artifacts['models'],\n",
    "    models_hparams=nn_mlp_artifacts['models_hparams'],\n",
    "    numerical_cols=nn_mlp_artifacts['numerical_cols'],\n",
    "    categorical_cols=nn_mlp_artifacts['categorical_cols'],\n",
    "    encoder=nn_mlp_artifacts['encoder'],\n",
    "    scaler=nn_mlp_artifacts['scaler'],\n",
    "    lgbm_encoders=nn_mlp_artifacts['lgbm_encoders'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c9ecf8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:48.352580Z",
     "iopub.status.busy": "2024-12-02T22:19:48.352227Z",
     "iopub.status.idle": "2024-12-02T22:19:49.388366Z",
     "shell.execute_reply": "2024-12-02T22:19:49.387476Z"
    },
    "papermill": {
     "duration": 1.047228,
     "end_time": "2024-12-02T22:19:49.390530",
     "exception": false,
     "start_time": "2024-12-02T22:19:48.343302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1309123747.py:118: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_pd = test.to_pandas().fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Id</th><th>utility_agent1</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>233234</td><td>0.109035</td></tr><tr><td>233235</td><td>-0.138016</td></tr><tr><td>233236</td><td>-0.013962</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬────────────────┐\n",
       "│ Id     ┆ utility_agent1 │\n",
       "│ ---    ┆ ---            │\n",
       "│ i64    ┆ f64            │\n",
       "╞════════╪════════════════╡\n",
       "│ 233234 ┆ 0.109035       │\n",
       "│ 233235 ┆ -0.138016      │\n",
       "│ 233236 ┆ -0.013962      │\n",
       "└────────┴────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check #1\n",
    "test = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\n",
    "sample_sub = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\")\n",
    "model_mlp.predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be370530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:49.409279Z",
     "iopub.status.busy": "2024-12-02T22:19:49.408526Z",
     "iopub.status.idle": "2024-12-02T22:19:49.412527Z",
     "shell.execute_reply": "2024-12-02T22:19:49.411771Z"
    },
    "papermill": {
     "duration": 0.014678,
     "end_time": "2024-12-02T22:19:49.414117",
     "exception": false,
     "start_time": "2024-12-02T22:19:49.399439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sanity check #2\n",
    "# train = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\")\n",
    "# test = train.drop(['num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1', 'utility_agent1'])\n",
    "# sample_sub = train.select(['Id', 'utility_agent1'])\n",
    "# model_mlp.predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e7c448",
   "metadata": {
    "papermill": {
     "duration": 0.007689,
     "end_time": "2024-12-02T22:19:49.429745",
     "exception": false,
     "start_time": "2024-12-02T22:19:49.422056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### gandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e05b636a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:49.446666Z",
     "iopub.status.busy": "2024-12-02T22:19:49.446098Z",
     "iopub.status.idle": "2024-12-02T22:19:54.024868Z",
     "shell.execute_reply": "2024-12-02T22:19:54.023986Z"
    },
    "papermill": {
     "duration": 4.589391,
     "end_time": "2024-12-02T22:19:54.026904",
     "exception": false,
     "start_time": "2024-12-02T22:19:49.437513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OrdinalEncoder from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator MinMaxScaler from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the path where you want to save the serialized function\n",
    "nn_gandalf_artifacts_path = '/kaggle/input/mcts-artifacts/nn-gandalf_predict_uni80.pt'\n",
    "# nn_gandalf_artifacts_path = '/kaggle/input/mcts-artifacts/nn-gandalf_predict_uni95.pt'\n",
    "# nn_gandalf_artifacts_path = '/kaggle/input/mcts-artifacts/nn-gandalf_predict_full.pt'\n",
    "\n",
    "# Load the function from the file\n",
    "nn_gandalf_artifacts = torch.load(nn_gandalf_artifacts_path, weights_only=False)\n",
    "\n",
    "len(nn_gandalf_artifacts['models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bfd43d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:54.049105Z",
     "iopub.status.busy": "2024-12-02T22:19:54.048717Z",
     "iopub.status.idle": "2024-12-02T22:19:54.072062Z",
     "shell.execute_reply": "2024-12-02T22:19:54.071359Z"
    },
    "papermill": {
     "duration": 0.034961,
     "end_time": "2024-12-02T22:19:54.073762",
     "exception": false,
     "start_time": "2024-12-02T22:19:54.038801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GANDALF(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "            num_input_dim: int,\n",
    "            cat_input_dims: list[int],\n",
    "            output_dim: int,\n",
    "            dropout: float,\n",
    "            embedding_dropout: float,\n",
    "            learning_rate: float = 1e-3,\n",
    "            weight_decay: float = 1e-5,\n",
    "            initialization: str = 'kaiming_uniform',\n",
    "            embedding_dim: Optional[List[int]] = None,\n",
    "            pct_start: float = 0.2,\n",
    "            div_factor: float = 10.0,\n",
    "            final_div_factor: float = 1e4,\n",
    "            n_stages: int = 6,\n",
    "            feature_mask_function: Callable = t_softmax,\n",
    "            feature_sparsity: float = 0.3,\n",
    "            learnable_sparsity: bool = True\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.dropout = dropout\n",
    "        self.embedding_dropout = embedding_dropout\n",
    "        self.pct_start = pct_start\n",
    "        self.div_factor = div_factor\n",
    "        self.final_div_factor = final_div_factor\n",
    "\n",
    "        # Initialize embedding dimensions if not provided\n",
    "        if embedding_dim is None:\n",
    "            # Rule of thumb: min(50, num_unique // 2 + 1) for each categorical feature\n",
    "            embedding_dim = [min(50, int(1 + np.ceil(np.sqrt(dim)))) for dim in cat_input_dims]\n",
    "\n",
    "        elif len(embedding_dim) != len(cat_input_dims):\n",
    "            raise ValueError(\"Length of embedding_dim must match number of categorical features.\")\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Create embedding layers\n",
    "        self.create_embeddings(cat_input_dims, embedding_dim)\n",
    "\n",
    "        # Create backbone layers\n",
    "        self.create_backbone(\n",
    "            num_input_dim,\n",
    "            n_stages,\n",
    "            feature_mask_function,\n",
    "            dropout,\n",
    "            feature_sparsity,\n",
    "            learnable_sparsity\n",
    "        )\n",
    "\n",
    "        # Create head layers\n",
    "        self.create_head(output_dim)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.initialization = initialization\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "        # Initialize lists to store validation outputs\n",
    "        self.validation_targets = []\n",
    "        self.validation_predictions = []\n",
    "\n",
    "    def create_embeddings(self, cat_input_dims: list[int], embedding_dim: list[int]):\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(dim, emb_dim) for dim, emb_dim in zip(cat_input_dims, embedding_dim)]\n",
    "        )\n",
    "        self.embedding_dropout_layer = nn.Dropout(self.embedding_dropout)\n",
    "\n",
    "    def create_backbone(\n",
    "            self, \n",
    "            num_input_dim: int,\n",
    "            n_stages: int,\n",
    "            feature_mask_function: Callable,\n",
    "            dropout: float,\n",
    "            feature_sparsity: float,\n",
    "            learnable_sparsity: bool\n",
    "        ):\n",
    "        # Calculate total input dimension after embeddings\n",
    "        total_embedding_dim = sum(self.embedding_dim)\n",
    "        total_input_dim = num_input_dim + total_embedding_dim\n",
    "\n",
    "        self.backbone = GatedFeatureLearningUnit(\n",
    "            n_features_in=total_input_dim,\n",
    "            n_stages=n_stages,\n",
    "            feature_mask_function=feature_mask_function,\n",
    "            dropout=dropout,\n",
    "            feature_sparsity=feature_sparsity,\n",
    "            learnable_sparsity=learnable_sparsity,\n",
    "        )\n",
    "        self.backbone_output_size = total_input_dim\n",
    "\n",
    "    def create_head(self, output_dim: int):\n",
    "        # Output layer\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.backbone_output_size),\n",
    "            nn.Linear(self.backbone_output_size, output_dim)\n",
    "        )\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if any(module is m for m in self.head.modules()):\n",
    "                    nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "                else:\n",
    "                    if self.initialization == 'kaiming_uniform':\n",
    "                        nn.init.kaiming_uniform_(module.weight, nonlinearity='relu')\n",
    "                    elif self.initialization == 'kaiming_normal':\n",
    "                        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "                    elif self.initialization == 'xavier_uniform':\n",
    "                        nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                    elif self.initialization == 'xavier_normal':\n",
    "                        nn.init.xavier_normal_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unsupported initialization method: {self.initialization}\")\n",
    "                \n",
    "                # Initialize bias to small values\n",
    "                if module.bias is not None:\n",
    "                    nn.init.uniform_(module.bias, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        # Process categorical variables\n",
    "        embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        embedded = torch.cat(embedded, dim=1)\n",
    "        embedded = self.embedding_dropout_layer(embedded)\n",
    "        \n",
    "        # Concatenate numerical and embedded categorical features\n",
    "        x = torch.cat([x_num, embedded], dim=1)\n",
    "        \n",
    "        # Pass through backbone\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # Pass through head\n",
    "        x = self.head(x)\n",
    "        x = nn.functional.hardtanh(x)\n",
    "\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('valid_loss', loss, prog_bar=True)\n",
    "        # Store targets and predictions for later use\n",
    "        self.validation_targets.append(y)\n",
    "        self.validation_predictions.append(y_hat)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        if len(batch) == 2:\n",
    "            x_num, x_cat = batch\n",
    "        elif len(batch) == 3:\n",
    "            x_num, x_cat, _ = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        return y_hat\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Concatenate all targets and predictions\n",
    "        y = torch.cat(self.validation_targets)\n",
    "        y_hat = torch.cat(self.validation_predictions)\n",
    "        rmse = torch.sqrt(F.mse_loss(y_hat, y))\n",
    "        self.log('val_rmse', rmse, prog_bar=True)\n",
    "        # Clear the lists for next epoch\n",
    "        self.validation_targets.clear()\n",
    "        self.validation_predictions.clear()\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=self.learning_rate, \n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.learning_rate,\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "            pct_start=self.pct_start,\n",
    "            div_factor=self.div_factor,\n",
    "            final_div_factor=self.final_div_factor,\n",
    "            anneal_strategy='cos',\n",
    "            cycle_momentum=True,\n",
    "            base_momentum=0.85,\n",
    "            max_momentum=0.95,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e37d99c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:54.091289Z",
     "iopub.status.busy": "2024-12-02T22:19:54.091056Z",
     "iopub.status.idle": "2024-12-02T22:19:57.881371Z",
     "shell.execute_reply": "2024-12-02T22:19:57.880332Z"
    },
    "papermill": {
     "duration": 3.801259,
     "end_time": "2024-12-02T22:19:57.883242",
     "exception": false,
     "start_time": "2024-12-02T22:19:54.081983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "len(numerical_cols): 215\n",
      "len(categorical_cols): 8\n"
     ]
    }
   ],
   "source": [
    "class GandalfInference:\n",
    "    def __init__(\n",
    "        self,\n",
    "        models_state_dicts,\n",
    "        models_hparams,\n",
    "        numerical_cols,\n",
    "        categorical_cols,\n",
    "        encoder,\n",
    "        scaler,\n",
    "        lgbm_encoders,\n",
    "    ):\n",
    "        \"\"\"Initialize inference class with trained artifacts\n",
    "        \n",
    "        Args:\n",
    "            models_state_dicts: List of model state dictionaries\n",
    "            models_hparams: List of model hyperparameters\n",
    "            numerical_cols: List of numerical column names\n",
    "            categorical_cols: List of categorical column names\n",
    "            encoder: Fitted OrdinalEncoder for categorical features\n",
    "            scaler: Fitted StandardScaler for numerical features\n",
    "            lgbm_encoders: List of LightGBM encoders for feature engineering\n",
    "        \"\"\"\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.encoder = encoder\n",
    "        self.scaler = scaler\n",
    "        self.lgbm_encoders = lgbm_encoders\n",
    "\n",
    "        # Load models\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.models = []\n",
    "        for state_dict, hparams in zip(models_state_dicts, models_hparams):\n",
    "            model = GANDALF(**hparams)\n",
    "            model.load_state_dict(state_dict)\n",
    "            model.to(self.device)  # Move model to GPU\n",
    "            model.eval()  # Set to evaluation mode\n",
    "            self.models.append(model)\n",
    "\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        print(\"len(numerical_cols):\", len(numerical_cols))\n",
    "        print(\"len(categorical_cols):\", len(categorical_cols))\n",
    "\n",
    "    def predict_array(self, df_test, batch_size=4096):\n",
    "        \"\"\"Make predictions on test data using DataLoader\n",
    "        \n",
    "        Args:\n",
    "            df_test: pandas DataFrame containing test features\n",
    "            batch_size: size of batches for inference\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of predictions\n",
    "        \"\"\"\n",
    "        # Preprocess test data\n",
    "        test_processed = process_test_data(\n",
    "            df_test,\n",
    "            self.numerical_cols,\n",
    "            self.categorical_cols,\n",
    "            self.encoder,\n",
    "            self.scaler,\n",
    "            include_position_features=False,\n",
    "            include_text_features=False,\n",
    "        )\n",
    "\n",
    "        # Initialize predictions array\n",
    "        predictions = np.zeros(len(df_test))\n",
    "\n",
    "        # Get predictions from all models\n",
    "        for lgbm_encoder, model in zip(self.lgbm_encoders, self.models):\n",
    "            # Prepare numerical and categorical features\n",
    "            X_test_num = test_processed[self.numerical_cols].copy()\n",
    "            X_test_cat = test_processed[self.categorical_cols].copy()\n",
    "\n",
    "            # Add LGBM encoder leaves features\n",
    "            lgbm_features = lgbm_encoder.transform(\n",
    "                test_processed[self.numerical_cols + self.categorical_cols]\n",
    "            )\n",
    "            X_test_cat = pd.concat([X_test_cat, lgbm_features], axis=1)\n",
    "            _categorical_cols = self.categorical_cols + lgbm_encoder.new_columns\n",
    "\n",
    "            # Create tensors\n",
    "            X_num_tensor = torch.tensor(\n",
    "                X_test_num[self.numerical_cols].values, \n",
    "                dtype=torch.float32,\n",
    "                device=self.device\n",
    "            )\n",
    "            X_cat_tensor = torch.tensor(\n",
    "                X_test_cat[_categorical_cols].values, \n",
    "                dtype=torch.int32,\n",
    "                device=self.device\n",
    "            )\n",
    "            \n",
    "            # Create TensorDataset and DataLoader\n",
    "            dataset = torch.utils.data.TensorDataset(\n",
    "                X_num_tensor, \n",
    "                X_cat_tensor\n",
    "            )\n",
    "            dataloader = torch.utils.data.DataLoader(\n",
    "                dataset, \n",
    "                batch_size=batch_size,\n",
    "                shuffle=False\n",
    "            )\n",
    "            \n",
    "            # Process batches using DataLoader\n",
    "            batch_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for X_num_batch, X_cat_batch in dataloader:\n",
    "                    pred_batch = model(X_num_batch, X_cat_batch).cpu()\n",
    "                    batch_predictions.append(pred_batch)\n",
    "\n",
    "            # Concatenate all batch predictions\n",
    "            model_predictions = torch.cat(batch_predictions).numpy().flatten()\n",
    "            predictions += model_predictions\n",
    "\n",
    "        # Average predictions across models\n",
    "        predictions /= len(self.models)\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, test: polars.DataFrame, sample_sub: polars.DataFrame):\n",
    "        test_pd = test.to_pandas().fillna(0)\n",
    "        predictions = self.predict_array(test_pd)\n",
    "        submission = sample_sub.with_columns(polars.Series(\"utility_agent1\", predictions))\n",
    "        return submission\n",
    "\n",
    "\n",
    "# Create inference class\n",
    "model_gandalf = GandalfInference(\n",
    "    models_state_dicts=nn_gandalf_artifacts['models'],\n",
    "    models_hparams=nn_gandalf_artifacts['models_hparams'],\n",
    "    numerical_cols=nn_gandalf_artifacts['numerical_cols'],\n",
    "    categorical_cols=nn_gandalf_artifacts['categorical_cols'],\n",
    "    encoder=nn_gandalf_artifacts['encoder'],\n",
    "    scaler=nn_gandalf_artifacts['scaler'],\n",
    "    lgbm_encoders=nn_gandalf_artifacts['lgbm_encoders'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d189816",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:57.901401Z",
     "iopub.status.busy": "2024-12-02T22:19:57.901067Z",
     "iopub.status.idle": "2024-12-02T22:19:58.742987Z",
     "shell.execute_reply": "2024-12-02T22:19:58.742101Z"
    },
    "papermill": {
     "duration": 0.853036,
     "end_time": "2024-12-02T22:19:58.744888",
     "exception": false,
     "start_time": "2024-12-02T22:19:57.891852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/1597166422.py:119: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_pd = test.to_pandas().fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Id</th><th>utility_agent1</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>233234</td><td>0.16078</td></tr><tr><td>233235</td><td>-0.166201</td></tr><tr><td>233236</td><td>-0.03351</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬────────────────┐\n",
       "│ Id     ┆ utility_agent1 │\n",
       "│ ---    ┆ ---            │\n",
       "│ i64    ┆ f64            │\n",
       "╞════════╪════════════════╡\n",
       "│ 233234 ┆ 0.16078        │\n",
       "│ 233235 ┆ -0.166201      │\n",
       "│ 233236 ┆ -0.03351       │\n",
       "└────────┴────────────────┘"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check #1\n",
    "test = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\n",
    "sample_sub = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\")\n",
    "model_gandalf.predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbe30217",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:58.763720Z",
     "iopub.status.busy": "2024-12-02T22:19:58.763414Z",
     "iopub.status.idle": "2024-12-02T22:19:58.766995Z",
     "shell.execute_reply": "2024-12-02T22:19:58.766297Z"
    },
    "papermill": {
     "duration": 0.014438,
     "end_time": "2024-12-02T22:19:58.768583",
     "exception": false,
     "start_time": "2024-12-02T22:19:58.754145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sanity check #2\n",
    "# train = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\")\n",
    "# test = train.drop(['num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1', 'utility_agent1'])\n",
    "# sample_sub = train.select(['Id', 'utility_agent1'])\n",
    "# model_gandalf.predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf866cb",
   "metadata": {
    "papermill": {
     "duration": 0.008013,
     "end_time": "2024-12-02T22:19:58.784818",
     "exception": false,
     "start_time": "2024-12-02T22:19:58.776805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "096dfc35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:19:58.802107Z",
     "iopub.status.busy": "2024-12-02T22:19:58.801833Z",
     "iopub.status.idle": "2024-12-02T22:20:02.627065Z",
     "shell.execute_reply": "2024-12-02T22:20:02.626076Z"
    },
    "papermill": {
     "duration": 3.835989,
     "end_time": "2024-12-02T22:20:02.628984",
     "exception": false,
     "start_time": "2024-12-02T22:19:58.792995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator OrdinalEncoder from version 1.5.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the path where you want to save the serialized function\n",
    "\n",
    "catboost_artifacts_path = '/kaggle/input/mcts-artifacts/catboost_text_predict_int99.pkl'\n",
    "# catboost_artifacts_path = '/kaggle/input/mcts-artifacts/catboost_predict_int99.pkl'\n",
    "\n",
    "\n",
    "# Load the function from the file\n",
    "with open(catboost_artifacts_path, 'rb') as f:\n",
    "    catboost_artifacts = pickle.load(f)\n",
    "\n",
    "len(catboost_artifacts[\"models\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40fc0211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:02.648456Z",
     "iopub.status.busy": "2024-12-02T22:20:02.647833Z",
     "iopub.status.idle": "2024-12-02T22:20:02.658075Z",
     "shell.execute_reply": "2024-12-02T22:20:02.657196Z"
    },
    "papermill": {
     "duration": 0.0217,
     "end_time": "2024-12-02T22:20:02.659844",
     "exception": false,
     "start_time": "2024-12-02T22:20:02.638144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(numerical_cols): 362\n",
      "len(categorical_cols): 8\n"
     ]
    }
   ],
   "source": [
    "class CATBoostInference:\n",
    "    def __init__(\n",
    "        self,\n",
    "        models,\n",
    "        numerical_cols,\n",
    "        categorical_cols,\n",
    "        encoder,\n",
    "        scaler,\n",
    "        text_cols=None,\n",
    "    ):\n",
    "        \"\"\"Initialize inference class with trained artifacts\n",
    "        \n",
    "        Args:\n",
    "            models: List of trained CatBoost models\n",
    "            numerical_cols: List of numerical column names\n",
    "            categorical_cols: List of categorical column names\n",
    "            encoder: Fitted OrdinalEncoder for categorical features\n",
    "            scaler: Fitted StandardScaler for numerical features (optional)\n",
    "            text_cols: List of text columns (optional)\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.text_cols = text_cols\n",
    "        self.encoder = encoder\n",
    "        self.scaler = scaler\n",
    "\n",
    "        print(\"len(numerical_cols):\", len(numerical_cols))\n",
    "        print(\"len(categorical_cols):\", len(categorical_cols))\n",
    "        \n",
    "    def predict_array(self, df_test):\n",
    "        \"\"\"Make predictions on test data\n",
    "        \n",
    "        Args:\n",
    "            df_test: pandas DataFrame containing test features\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of predictions\n",
    "        \"\"\"\n",
    "        # Preprocess test data\n",
    "        test_processed = process_test_data(\n",
    "            df_test,\n",
    "            self.numerical_cols,\n",
    "            self.categorical_cols,\n",
    "            self.encoder,\n",
    "            self.scaler,\n",
    "            include_position_features=True,\n",
    "            include_text_features=True,\n",
    "        )\n",
    "        \n",
    "        # Create CatBoost Pool for test data\n",
    "        features = self.numerical_cols + self.categorical_cols\n",
    "        pool_kwargs = {\n",
    "            'data': test_processed[features],\n",
    "            'cat_features': self.categorical_cols,\n",
    "        }\n",
    "        \n",
    "        if self.text_cols is not None:\n",
    "            features += self.text_cols\n",
    "            pool_kwargs['data'] = test_processed[features]\n",
    "            pool_kwargs['text_features'] = self.text_cols\n",
    "            \n",
    "        test_pool = cb.Pool(**pool_kwargs)\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        predictions = np.mean([\n",
    "            model.predict(test_pool)\n",
    "            for model in self.models\n",
    "        ], axis=0)\n",
    "        # predictions = np.clip(predictions, -1, 1)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "\n",
    "    def predict(self, test: polars.DataFrame, sample_sub: polars.DataFrame):\n",
    "        test_pd = test.to_pandas()\n",
    "        predictions = self.predict_array(test_pd)\n",
    "        submission = sample_sub.with_columns(polars.Series(\"utility_agent1\", predictions))\n",
    "        return submission\n",
    "\n",
    "\n",
    "model_catboost = CATBoostInference(\n",
    "    # models=catboost_artifacts[\"models\"][:5],\n",
    "    # models=catboost_artifacts[\"models\"][5:10],\n",
    "    # models=catboost_artifacts[\"models\"][10:],\n",
    "    models=catboost_artifacts[\"models\"],\n",
    "    numerical_cols=catboost_artifacts[\"numerical_cols\"],\n",
    "    categorical_cols=catboost_artifacts[\"categorical_cols\"],\n",
    "    text_cols=catboost_artifacts[\"text_cols\"],\n",
    "    encoder=catboost_artifacts[\"encoder\"],\n",
    "    scaler=catboost_artifacts[\"scaler\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53694ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:02.678539Z",
     "iopub.status.busy": "2024-12-02T22:20:02.678187Z",
     "iopub.status.idle": "2024-12-02T22:20:02.865905Z",
     "shell.execute_reply": "2024-12-02T22:20:02.865089Z"
    },
    "papermill": {
     "duration": 0.198927,
     "end_time": "2024-12-02T22:20:02.867788",
     "exception": false,
     "start_time": "2024-12-02T22:20:02.668861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Id</th><th>utility_agent1</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>233234</td><td>0.154499</td></tr><tr><td>233235</td><td>-0.18696</td></tr><tr><td>233236</td><td>0.015267</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬────────────────┐\n",
       "│ Id     ┆ utility_agent1 │\n",
       "│ ---    ┆ ---            │\n",
       "│ i64    ┆ f64            │\n",
       "╞════════╪════════════════╡\n",
       "│ 233234 ┆ 0.154499       │\n",
       "│ 233235 ┆ -0.18696       │\n",
       "│ 233236 ┆ 0.015267       │\n",
       "└────────┴────────────────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "test = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\n",
    "sample_sub = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\")\n",
    "model_catboost.predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57fbcb1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:02.886839Z",
     "iopub.status.busy": "2024-12-02T22:20:02.886251Z",
     "iopub.status.idle": "2024-12-02T22:20:02.890169Z",
     "shell.execute_reply": "2024-12-02T22:20:02.889311Z"
    },
    "papermill": {
     "duration": 0.015227,
     "end_time": "2024-12-02T22:20:02.891849",
     "exception": false,
     "start_time": "2024-12-02T22:20:02.876622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sanity check #2\n",
    "# train = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/train.csv\")\n",
    "# test = train.drop(['num_wins_agent1', 'num_draws_agent1', 'num_losses_agent1', 'utility_agent1'])\n",
    "# sample_sub = train.select(['Id', 'utility_agent1'])\n",
    "# model_catboost.predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbdd4ca",
   "metadata": {
    "papermill": {
     "duration": 0.008451,
     "end_time": "2024-12-02T22:20:02.909749",
     "exception": false,
     "start_time": "2024-12-02T22:20:02.901298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d21d5db8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:02.928736Z",
     "iopub.status.busy": "2024-12-02T22:20:02.928083Z",
     "iopub.status.idle": "2024-12-02T22:20:02.932187Z",
     "shell.execute_reply": "2024-12-02T22:20:02.931326Z"
    },
    "papermill": {
     "duration": 0.015549,
     "end_time": "2024-12-02T22:20:02.933946",
     "exception": false,
     "start_time": "2024-12-02T22:20:02.918397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the serialized function\n",
    "# lightgbm_artifacts_path = '/kaggle/input/mcts-artifacts/lightgbm_predict_uni80.pkl'\n",
    "# lightgbm_artifacts_path = '/kaggle/input/mcts-artifacts/lightgbm_linear_predict_uni95.pkl'\n",
    "# lightgbm_artifacts_path = '/kaggle/input/mcts-artifacts/lightgbm_predict_fsv24.pkl'\n",
    "\n",
    "# Load the function from the file\n",
    "# with open(lightgbm_artifacts_path, 'rb') as f:\n",
    "#     lightgbm_artifacts = pickle.load(f)\n",
    "# len(lightgbm_artifacts[\"models\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faadaf58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:02.953103Z",
     "iopub.status.busy": "2024-12-02T22:20:02.952369Z",
     "iopub.status.idle": "2024-12-02T22:20:02.959641Z",
     "shell.execute_reply": "2024-12-02T22:20:02.958766Z"
    },
    "papermill": {
     "duration": 0.018425,
     "end_time": "2024-12-02T22:20:02.961215",
     "exception": false,
     "start_time": "2024-12-02T22:20:02.942790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LightGBMInference:\n",
    "    def __init__(\n",
    "        self,\n",
    "        models,\n",
    "        numerical_cols,\n",
    "        categorical_cols,\n",
    "        encoder,\n",
    "        scaler,\n",
    "    ):\n",
    "        \"\"\"Initialize inference class with trained artifacts\n",
    "        \n",
    "        Args:\n",
    "            models: List of trained LightGBM models\n",
    "            numerical_cols: List of numerical column names\n",
    "            categorical_cols: List of categorical column names\n",
    "            encoder: Fitted OrdinalEncoder for categorical features\n",
    "            scaler: Fitted StandardScaler for numerical features (optional)\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.encoder = encoder\n",
    "        self.scaler = scaler\n",
    "\n",
    "        print(\"len(numerical_cols):\", len(numerical_cols))\n",
    "        print(\"len(categorical_cols):\", len(categorical_cols))\n",
    "        \n",
    "    def predict_array(self, df_test):\n",
    "        \"\"\"Make predictions on test data\n",
    "        \n",
    "        Args:\n",
    "            df_test: pandas DataFrame containing test features\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of predictions\n",
    "        \"\"\"\n",
    "        # Preprocess test data\n",
    "        test_processed = process_test_data(\n",
    "            df_test,\n",
    "            self.numerical_cols,\n",
    "            self.categorical_cols,\n",
    "            self.encoder,\n",
    "            self.scaler,\n",
    "            include_position_features=True,\n",
    "            include_text_features=True,\n",
    "        )\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        predictions = np.mean([\n",
    "            model.predict(test_processed[self.numerical_cols + self.categorical_cols])\n",
    "            for model in self.models\n",
    "        ], axis=0)\n",
    "        # predictions = np.clip(predictions, -1, 1)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def predict(self, test: polars.DataFrame, sample_sub: polars.DataFrame):\n",
    "        test_pd = test.to_pandas()\n",
    "        predictions = self.predict_array(test_pd)\n",
    "        submission = sample_sub.with_columns(polars.Series(\"utility_agent1\", predictions))\n",
    "        return submission\n",
    "\n",
    "# model_lgbm = LightGBMInference(**lightgbm_artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0870310c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:02.980221Z",
     "iopub.status.busy": "2024-12-02T22:20:02.979516Z",
     "iopub.status.idle": "2024-12-02T22:20:02.983212Z",
     "shell.execute_reply": "2024-12-02T22:20:02.982488Z"
    },
    "papermill": {
     "duration": 0.014896,
     "end_time": "2024-12-02T22:20:02.984856",
     "exception": false,
     "start_time": "2024-12-02T22:20:02.969960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "# test = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\n",
    "# sample_sub = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\")\n",
    "# model_lgbm.predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b0d6a4",
   "metadata": {
    "papermill": {
     "duration": 0.008868,
     "end_time": "2024-12-02T22:20:03.002277",
     "exception": false,
     "start_time": "2024-12-02T22:20:02.993409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f706a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:03.020832Z",
     "iopub.status.busy": "2024-12-02T22:20:03.020156Z",
     "iopub.status.idle": "2024-12-02T22:20:03.024057Z",
     "shell.execute_reply": "2024-12-02T22:20:03.023225Z"
    },
    "papermill": {
     "duration": 0.01491,
     "end_time": "2024-12-02T22:20:03.025709",
     "exception": false,
     "start_time": "2024-12-02T22:20:03.010799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the serialized function\n",
    "# xgboost_artifacts_path = '/kaggle/input/mcts-artifacts/xgboost_predict_uni90.pkl'\n",
    "# xgboost_artifacts_path = '/kaggle/input/mcts-artifacts/xgboost_predict_fsv24.pkl'\n",
    "\n",
    "# Load the function from the file\n",
    "# with open(xgboost_artifacts_path, 'rb') as f:\n",
    "#     xgboost_artifacts = pickle.load(f)\n",
    "# len(xgboost_artifacts[\"models\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d7b8a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:03.043791Z",
     "iopub.status.busy": "2024-12-02T22:20:03.043515Z",
     "iopub.status.idle": "2024-12-02T22:20:03.051125Z",
     "shell.execute_reply": "2024-12-02T22:20:03.050468Z"
    },
    "papermill": {
     "duration": 0.018521,
     "end_time": "2024-12-02T22:20:03.052749",
     "exception": false,
     "start_time": "2024-12-02T22:20:03.034228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XGBoostInference:\n",
    "    def __init__(\n",
    "        self,\n",
    "        models,\n",
    "        numerical_cols,\n",
    "        categorical_cols,\n",
    "        encoder,\n",
    "        scaler,\n",
    "    ):\n",
    "        \"\"\"Initialize inference class with trained artifacts\n",
    "        \n",
    "        Args:\n",
    "            models: List of trained XGBoost models\n",
    "            numerical_cols: List of numerical column names\n",
    "            categorical_cols: List of categorical column names\n",
    "            encoder: Fitted OrdinalEncoder for categorical features\n",
    "            scaler: Fitted StandardScaler for numerical features\n",
    "        \"\"\"\n",
    "        self.models = models\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.encoder = encoder\n",
    "        self.scaler = scaler\n",
    "\n",
    "        print(\"len(numerical_cols):\", len(numerical_cols))\n",
    "        print(\"len(categorical_cols):\", len(categorical_cols))\n",
    "        \n",
    "    def predict_array(self, df_test):\n",
    "        \"\"\"Make predictions on test data\n",
    "        \n",
    "        Args:\n",
    "            df_test: pandas DataFrame containing test features\n",
    "            \n",
    "        Returns:\n",
    "            numpy array of predictions\n",
    "        \"\"\"\n",
    "        # Preprocess test data\n",
    "        test_processed = process_test_data(\n",
    "            df_test,\n",
    "            self.numerical_cols,\n",
    "            self.categorical_cols,\n",
    "            self.encoder,\n",
    "            self.scaler,\n",
    "            include_position_features=True,\n",
    "            include_text_features=True,\n",
    "        )\n",
    "        \n",
    "        # Create feature types list for XGBoost\n",
    "        feature_types = [\n",
    "            \"c\" if col in self.categorical_cols else \"q\" \n",
    "            for col in self.numerical_cols + self.categorical_cols\n",
    "        ]\n",
    "        \n",
    "        # Create XGBoost DMatrix for test data\n",
    "        test_dmatrix = xgb.DMatrix(\n",
    "            data=test_processed[self.numerical_cols + self.categorical_cols],\n",
    "            feature_types=feature_types,\n",
    "            enable_categorical=True\n",
    "        )\n",
    "        \n",
    "        # Get predictions from all models\n",
    "        predictions = np.mean([\n",
    "            model.predict(test_dmatrix)\n",
    "            for model in self.models\n",
    "        ], axis=0)\n",
    "        # predictions = np.clip(predictions, -1, 1)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def predict(self, test: polars.DataFrame, sample_sub: polars.DataFrame):\n",
    "        test_pd = test.to_pandas()\n",
    "        predictions = self.predict_array(test_pd)\n",
    "        submission = sample_sub.with_columns(polars.Series(\"utility_agent1\", predictions))\n",
    "        return submission\n",
    "\n",
    "\n",
    "# model_xgboost = XGBoostInference(\n",
    "#    models=xgboost_artifacts[\"models\"],\n",
    "#    numerical_cols=xgboost_artifacts[\"numerical_cols\"],\n",
    "#    categorical_cols=xgboost_artifacts[\"categorical_cols\"],\n",
    "#    encoder=xgboost_artifacts[\"encoder\"],\n",
    "#    scaler=xgboost_artifacts[\"scaler\"],\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88e65d73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:03.071536Z",
     "iopub.status.busy": "2024-12-02T22:20:03.070977Z",
     "iopub.status.idle": "2024-12-02T22:20:03.074713Z",
     "shell.execute_reply": "2024-12-02T22:20:03.073911Z"
    },
    "papermill": {
     "duration": 0.014868,
     "end_time": "2024-12-02T22:20:03.076254",
     "exception": false,
     "start_time": "2024-12-02T22:20:03.061386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "# test = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\n",
    "# sample_sub = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\")\n",
    "# model_xgboost.predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc087c",
   "metadata": {
    "papermill": {
     "duration": 0.00824,
     "end_time": "2024-12-02T22:20:03.093131",
     "exception": false,
     "start_time": "2024-12-02T22:20:03.084891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "452f0a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:03.111135Z",
     "iopub.status.busy": "2024-12-02T22:20:03.110835Z",
     "iopub.status.idle": "2024-12-02T22:20:03.115820Z",
     "shell.execute_reply": "2024-12-02T22:20:03.114987Z"
    },
    "papermill": {
     "duration": 0.015948,
     "end_time": "2024-12-02T22:20:03.117465",
     "exception": false,
     "start_time": "2024-12-02T22:20:03.101517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test, sample_sub):\n",
    "    pred_cat = model_catboost.predict(test, sample_sub)\n",
    "    pred_1dcnn = model_1dcnn.predict(test, sample_sub)\n",
    "    pred_mlp = model_mlp.predict(test, sample_sub)\n",
    "    # pred_gandalf = model_gandalf.predict(test, sample_sub)\n",
    "\n",
    "    out = pred_cat.clone()\n",
    "    out = out.with_columns(\n",
    "        (\n",
    "            0.4922 * pred_cat[\"utility_agent1\"] +\n",
    "            0.1715 * pred_1dcnn[\"utility_agent1\"] +\n",
    "            0.3363 * pred_mlp[\"utility_agent1\"]\n",
    "            # 0.1669 * pred_gandalf[\"utility_agent1\"]\n",
    "        ).clip(-1, 1).alias(\"utility_agent1\")\n",
    "    )\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d918d433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:03.135777Z",
     "iopub.status.busy": "2024-12-02T22:20:03.135085Z",
     "iopub.status.idle": "2024-12-02T22:20:05.085332Z",
     "shell.execute_reply": "2024-12-02T22:20:05.084486Z"
    },
    "papermill": {
     "duration": 1.961428,
     "end_time": "2024-12-02T22:20:05.087251",
     "exception": false,
     "start_time": "2024-12-02T22:20:03.125823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2413545367.py:118: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_pd = test.to_pandas().fillna(0)\n",
      "/tmp/ipykernel_23/1309123747.py:118: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_pd = test.to_pandas().fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Id</th><th>utility_agent1</th></tr><tr><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>233234</td><td>0.136193</td></tr><tr><td>233235</td><td>-0.162299</td></tr><tr><td>233236</td><td>-0.004167</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌────────┬────────────────┐\n",
       "│ Id     ┆ utility_agent1 │\n",
       "│ ---    ┆ ---            │\n",
       "│ i64    ┆ f64            │\n",
       "╞════════╪════════════════╡\n",
       "│ 233234 ┆ 0.136193       │\n",
       "│ 233235 ┆ -0.162299      │\n",
       "│ 233236 ┆ -0.004167      │\n",
       "└────────┴────────────────┘"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "test = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv\")\n",
    "sample_sub = polars.read_csv(\"/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv\")\n",
    "predict(test, sample_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffd7e18",
   "metadata": {
    "papermill": {
     "duration": 0.012122,
     "end_time": "2024-12-02T22:20:05.112225",
     "exception": false,
     "start_time": "2024-12-02T22:20:05.100103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***\n",
    "### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79edbcef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T22:20:05.132852Z",
     "iopub.status.busy": "2024-12-02T22:20:05.132309Z",
     "iopub.status.idle": "2024-12-02T22:20:07.196605Z",
     "shell.execute_reply": "2024-12-02T22:20:07.195695Z"
    },
    "papermill": {
     "duration": 2.076151,
     "end_time": "2024-12-02T22:20:07.198958",
     "exception": false,
     "start_time": "2024-12-02T22:20:05.122807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2413545367.py:118: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_pd = test.to_pandas().fillna(0)\n",
      "/tmp/ipykernel_23/1309123747.py:118: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_pd = test.to_pandas().fillna(0)\n"
     ]
    }
   ],
   "source": [
    "inference_server = kaggle_evaluation.mcts_inference_server.MCTSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/test.csv',\n",
    "            '/kaggle/input/um-game-playing-strength-of-mcts-variants/sample_submission.csv'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7491f1b1",
   "metadata": {
    "papermill": {
     "duration": 0.008782,
     "end_time": "2024-12-02T22:20:07.220938",
     "exception": false,
     "start_time": "2024-12-02T22:20:07.212156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9515283,
     "sourceId": 70089,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 10359367,
     "datasetId": 5909723,
     "sourceId": 10081535,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10356707,
     "datasetId": 6170268,
     "sourceId": 10079181,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 258.764069,
   "end_time": "2024-12-02T22:20:10.638025",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-02T22:15:51.873956",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
