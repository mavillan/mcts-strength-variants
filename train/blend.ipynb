{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import Bounds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_results = Path(\"../data/results/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utility_agent1_true</th>\n",
       "      <th>fold</th>\n",
       "      <th>utility_agent1_pred_lightgbm</th>\n",
       "      <th>utility_agent1_pred_lightgbm_linear</th>\n",
       "      <th>utility_agent1_pred_xgboost</th>\n",
       "      <th>utility_agent1_pred_catboost</th>\n",
       "      <th>utility_agent1_pred_mlp</th>\n",
       "      <th>utility_agent1_pred_1dcnn</th>\n",
       "      <th>utility_agent1_pred_gandalf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.466667</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.312711</td>\n",
       "      <td>-0.343538</td>\n",
       "      <td>-0.371282</td>\n",
       "      <td>-0.140778</td>\n",
       "      <td>-0.194608</td>\n",
       "      <td>-0.232008</td>\n",
       "      <td>0.048197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.067989</td>\n",
       "      <td>-0.130576</td>\n",
       "      <td>0.013122</td>\n",
       "      <td>-0.060329</td>\n",
       "      <td>-0.087002</td>\n",
       "      <td>0.250238</td>\n",
       "      <td>0.253728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.066667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028722</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>0.175175</td>\n",
       "      <td>0.236053</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.328399</td>\n",
       "      <td>0.336407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.027028</td>\n",
       "      <td>0.038348</td>\n",
       "      <td>0.157617</td>\n",
       "      <td>0.111223</td>\n",
       "      <td>-0.167267</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>0.249325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053506</td>\n",
       "      <td>0.117267</td>\n",
       "      <td>0.196683</td>\n",
       "      <td>0.093483</td>\n",
       "      <td>-0.028701</td>\n",
       "      <td>0.366571</td>\n",
       "      <td>0.429119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208603</th>\n",
       "      <td>-0.733333</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.455402</td>\n",
       "      <td>-0.408042</td>\n",
       "      <td>-0.443232</td>\n",
       "      <td>-0.465189</td>\n",
       "      <td>-0.271464</td>\n",
       "      <td>-0.527001</td>\n",
       "      <td>-0.513383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208604</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.233319</td>\n",
       "      <td>-0.216536</td>\n",
       "      <td>-0.243728</td>\n",
       "      <td>-0.096964</td>\n",
       "      <td>0.077222</td>\n",
       "      <td>-0.097327</td>\n",
       "      <td>-0.264358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208605</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>-0.042721</td>\n",
       "      <td>0.086905</td>\n",
       "      <td>0.123920</td>\n",
       "      <td>-0.114086</td>\n",
       "      <td>-0.074179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208606</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.044354</td>\n",
       "      <td>-0.070769</td>\n",
       "      <td>-0.093249</td>\n",
       "      <td>0.123682</td>\n",
       "      <td>0.098985</td>\n",
       "      <td>-0.154095</td>\n",
       "      <td>-0.084955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208607</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.008996</td>\n",
       "      <td>-0.044946</td>\n",
       "      <td>-0.105162</td>\n",
       "      <td>-0.010971</td>\n",
       "      <td>0.162171</td>\n",
       "      <td>0.030240</td>\n",
       "      <td>-0.147750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208608 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        utility_agent1_true  fold  utility_agent1_pred_lightgbm  \\\n",
       "0                 -0.466667     2                     -0.312711   \n",
       "1                 -0.333333     2                     -0.067989   \n",
       "2                 -0.066667     2                      0.028722   \n",
       "3                 -0.333333     2                     -0.027028   \n",
       "4                 -0.333333     2                      0.053506   \n",
       "...                     ...   ...                           ...   \n",
       "208603            -0.733333     3                     -0.455402   \n",
       "208604             0.266667     3                     -0.233319   \n",
       "208605             0.666667     3                      0.005615   \n",
       "208606             0.666667     3                     -0.044354   \n",
       "208607             0.266667     3                     -0.008996   \n",
       "\n",
       "        utility_agent1_pred_lightgbm_linear  utility_agent1_pred_xgboost  \\\n",
       "0                                 -0.343538                    -0.371282   \n",
       "1                                 -0.130576                     0.013122   \n",
       "2                                  0.110679                     0.175175   \n",
       "3                                  0.038348                     0.157617   \n",
       "4                                  0.117267                     0.196683   \n",
       "...                                     ...                          ...   \n",
       "208603                            -0.408042                    -0.443232   \n",
       "208604                            -0.216536                    -0.243728   \n",
       "208605                             0.040002                    -0.042721   \n",
       "208606                            -0.070769                    -0.093249   \n",
       "208607                            -0.044946                    -0.105162   \n",
       "\n",
       "        utility_agent1_pred_catboost  utility_agent1_pred_mlp  \\\n",
       "0                          -0.140778                -0.194608   \n",
       "1                          -0.060329                -0.087002   \n",
       "2                           0.236053                 0.002282   \n",
       "3                           0.111223                -0.167267   \n",
       "4                           0.093483                -0.028701   \n",
       "...                              ...                      ...   \n",
       "208603                     -0.465189                -0.271464   \n",
       "208604                     -0.096964                 0.077222   \n",
       "208605                      0.086905                 0.123920   \n",
       "208606                      0.123682                 0.098985   \n",
       "208607                     -0.010971                 0.162171   \n",
       "\n",
       "        utility_agent1_pred_1dcnn  utility_agent1_pred_gandalf  \n",
       "0                       -0.232008                     0.048197  \n",
       "1                        0.250238                     0.253728  \n",
       "2                        0.328399                     0.336407  \n",
       "3                        0.148452                     0.249325  \n",
       "4                        0.366571                     0.429119  \n",
       "...                           ...                          ...  \n",
       "208603                  -0.527001                    -0.513383  \n",
       "208604                  -0.097327                    -0.264358  \n",
       "208605                  -0.114086                    -0.074179  \n",
       "208606                  -0.154095                    -0.084955  \n",
       "208607                   0.030240                    -0.147750  \n",
       "\n",
       "[208608 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = \"cv3\"\n",
    "\n",
    "all_oof = {\n",
    "    \"lightgbm\": pd.read_parquet(path_results / f\"oof_lightgbm_int97_{cv}.parquet\"),\n",
    "    \"lightgbm_linear\": pd.read_parquet(path_results / f\"oof_lightgbm_linear_uni95_{cv}.parquet\"),\n",
    "    \"xgboost\": pd.read_parquet(path_results / f\"oof_xgboost_uni80_{cv}.parquet\"), \n",
    "    \"catboost\": pd.read_parquet(path_results / f\"oof_catboost_int99_{cv}.parquet\"),\n",
    "    # --------------------------------------------------------------------------------------------\n",
    "    \"mlp\": pd.read_parquet(path_results / f\"oof_nn-mlp_uni95_{cv}.parquet\"),\n",
    "    \"1dcnn\": pd.read_parquet(path_results / f\"oof_nn-1dcnn_uni95_{cv}.parquet\"),\n",
    "    \"gandalf\": pd.read_parquet(path_results / f\"oof_nn-gandalf_uni95_{cv}.parquet\"),\n",
    "}\n",
    "\n",
    "combined_df = all_oof[\"lightgbm\"][[\"utility_agent1_true\",\"fold\"]]\n",
    "for model, df in all_oof.items():\n",
    "    combined_df[f'utility_agent1_pred_{model}'] = df['utility_agent1_pred']\n",
    "\n",
    "combined_df = combined_df.dropna(subset=[\"fold\"], ignore_index=True)\n",
    "combined_df[\"fold\"] = combined_df[\"fold\"].astype(int)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## blend test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "utility_agent1_pred_lightgbm:\n",
      "Scores per fold: ['0.4301', '0.4138', '0.4199', '0.4133', '0.4252']\n",
      "Average score: 0.4204\n",
      "\n",
      "utility_agent1_pred_lightgbm_linear:\n",
      "Scores per fold: ['0.4372', '0.4158', '0.4355', '0.4126', '0.4317']\n",
      "Average score: 0.4266\n",
      "\n",
      "utility_agent1_pred_xgboost:\n",
      "Scores per fold: ['0.4350', '0.4130', '0.4239', '0.4140', '0.4275']\n",
      "Average score: 0.4227\n",
      "\n",
      "utility_agent1_pred_catboost:\n",
      "Scores per fold: ['0.4213', '0.4073', '0.4117', '0.4142', '0.4202']\n",
      "Average score: 0.4150\n",
      "\n",
      "utility_agent1_pred_mlp:\n",
      "Scores per fold: ['0.4391', '0.4310', '0.4372', '0.4168', '0.4215']\n",
      "Average score: 0.4291\n",
      "\n",
      "utility_agent1_pred_1dcnn:\n",
      "Scores per fold: ['0.4401', '0.4202', '0.4377', '0.4183', '0.4263']\n",
      "Average score: 0.4285\n",
      "\n",
      "utility_agent1_pred_gandalf:\n",
      "Scores per fold: ['0.4344', '0.4258', '0.4279', '0.4284', '0.4376']\n",
      "Average score: 0.4308\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store scores for each model\n",
    "model_scores = {}\n",
    "\n",
    "# Get all prediction columns\n",
    "pred_columns = [col for col in combined_df.columns if 'pred' in col]\n",
    "\n",
    "for model_col in pred_columns:\n",
    "    scores = list()\n",
    "    \n",
    "    for _, df in combined_df.groupby(\"fold\"):\n",
    "        pred = df[model_col].clip(-1, 1)\n",
    "        squared_errors = (df['utility_agent1_true'] - pred)**2\n",
    "        rmse = np.sqrt(squared_errors.mean())\n",
    "        scores.append(rmse)\n",
    "        \n",
    "    model_scores[model_col] = scores\n",
    "    print(f\"\\n{model_col}:\")\n",
    "    print(\"Scores per fold:\", [f\"{score:.4f}\" for score in scores])\n",
    "    print(\"Average score: {:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Optimizing blend using Nelder-Mead:\n",
      "\n",
      "Optimized blend using Nelder-Mead:\n",
      "Optimal weights:\n",
      "utility_agent1_pred_catboost: 0.4806\n",
      "utility_agent1_pred_mlp: 0.1569\n",
      "utility_agent1_pred_1dcnn: 0.1763\n",
      "utility_agent1_pred_gandalf: 0.1861\n",
      "\n",
      "Scores per fold: ['0.4146', '0.3996', '0.4066', '0.4051', '0.4106']\n",
      "Average score: 0.4073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Optimizing blend using Powell:\n",
      "\n",
      "Optimized blend using Powell:\n",
      "Optimal weights:\n",
      "utility_agent1_pred_catboost: 0.4804\n",
      "utility_agent1_pred_mlp: 0.1572\n",
      "utility_agent1_pred_1dcnn: 0.1764\n",
      "utility_agent1_pred_gandalf: 0.1861\n",
      "\n",
      "Scores per fold: ['0.4146', '0.3996', '0.4066', '0.4051', '0.4106']\n",
      "Average score: 0.4073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Optimizing blend using CG:\n",
      "\n",
      "Optimized blend using CG:\n",
      "Optimal weights:\n",
      "utility_agent1_pred_catboost: 0.4803\n",
      "utility_agent1_pred_mlp: 0.1570\n",
      "utility_agent1_pred_1dcnn: 0.1765\n",
      "utility_agent1_pred_gandalf: 0.1862\n",
      "\n",
      "Scores per fold: ['0.4146', '0.3996', '0.4066', '0.4051', '0.4106']\n",
      "Average score: 0.4073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Optimizing blend using BFGS:\n",
      "\n",
      "Optimized blend using BFGS:\n",
      "Optimal weights:\n",
      "utility_agent1_pred_catboost: 0.4808\n",
      "utility_agent1_pred_mlp: 0.1566\n",
      "utility_agent1_pred_1dcnn: 0.1756\n",
      "utility_agent1_pred_gandalf: 0.1869\n",
      "\n",
      "Scores per fold: ['0.4146', '0.3996', '0.4066', '0.4051', '0.4106']\n",
      "Average score: 0.4073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Optimizing blend using L-BFGS-B:\n",
      "\n",
      "Optimized blend using L-BFGS-B:\n",
      "Optimal weights:\n",
      "utility_agent1_pred_catboost: 0.4807\n",
      "utility_agent1_pred_mlp: 0.1581\n",
      "utility_agent1_pred_1dcnn: 0.1754\n",
      "utility_agent1_pred_gandalf: 0.1859\n",
      "\n",
      "Scores per fold: ['0.4146', '0.3996', '0.4066', '0.4050', '0.4105']\n",
      "Average score: 0.4073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Optimizing blend using TNC:\n",
      "\n",
      "Optimized blend using TNC:\n",
      "Optimal weights:\n",
      "utility_agent1_pred_catboost: 0.4804\n",
      "utility_agent1_pred_mlp: 0.1575\n",
      "utility_agent1_pred_1dcnn: 0.1762\n",
      "utility_agent1_pred_gandalf: 0.1859\n",
      "\n",
      "Scores per fold: ['0.4146', '0.3996', '0.4066', '0.4050', '0.4105']\n",
      "Average score: 0.4073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Optimizing blend using COBYLA:\n",
      "\n",
      "Optimized blend using COBYLA:\n",
      "Optimal weights:\n",
      "utility_agent1_pred_catboost: 0.4806\n",
      "utility_agent1_pred_mlp: 0.1569\n",
      "utility_agent1_pred_1dcnn: 0.1763\n",
      "utility_agent1_pred_gandalf: 0.1862\n",
      "\n",
      "Scores per fold: ['0.4146', '0.3996', '0.4066', '0.4051', '0.4106']\n",
      "Average score: 0.4073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Optimizing blend using SLSQP:\n",
      "\n",
      "Optimized blend using SLSQP:\n",
      "Optimal weights:\n",
      "utility_agent1_pred_catboost: 0.4749\n",
      "utility_agent1_pred_mlp: 0.1598\n",
      "utility_agent1_pred_1dcnn: 0.1662\n",
      "utility_agent1_pred_gandalf: 0.1991\n",
      "\n",
      "Scores per fold: ['0.4145', '0.3996', '0.4065', '0.4051', '0.4107']\n",
      "Average score: 0.4073\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Optimizing blend using trust-constr:\n",
      "\n",
      "Optimized blend using trust-constr:\n",
      "Optimal weights:\n",
      "utility_agent1_pred_catboost: 0.4806\n",
      "utility_agent1_pred_mlp: 0.1569\n",
      "utility_agent1_pred_1dcnn: 0.1763\n",
      "utility_agent1_pred_gandalf: 0.1861\n",
      "\n",
      "Scores per fold: ['0.4146', '0.3996', '0.4066', '0.4051', '0.4106']\n",
      "Average score: 0.4073\n"
     ]
    }
   ],
   "source": [
    "# Create a linear blend of all predictions \n",
    "pred_columns = [\n",
    "    # 'utility_agent1_pred_lightgbm',\n",
    "    # 'utility_agent1_pred_lightgbm_linear',\n",
    "    # 'utility_agent1_pred_xgboost',\n",
    "    'utility_agent1_pred_catboost',\n",
    "    'utility_agent1_pred_mlp',\n",
    "    'utility_agent1_pred_1dcnn',\n",
    "    'utility_agent1_pred_gandalf',\n",
    "]\n",
    "\n",
    "# Function to calculate RMSE for given weights\n",
    "def calculate_blend_rmse(weights, pred_cols, df):\n",
    "    # Convert raw weights to normalized weights using softmax\n",
    "    weights = np.exp(weights) / np.sum(np.exp(weights))\n",
    "    \n",
    "    blended_predictions = np.zeros(len(df))\n",
    "    for i, col in enumerate(pred_cols):\n",
    "        blended_predictions += weights[i] * df[col].values\n",
    "        \n",
    "    scores = []\n",
    "    for _, fold_df in df.groupby(\"fold\"):\n",
    "        fold_preds = blended_predictions[fold_df.index].clip(-1, 1)\n",
    "        squared_errors = (fold_df['utility_agent1_true'] - fold_preds)**2\n",
    "        rmse = np.sqrt(squared_errors.mean())\n",
    "        scores.append(rmse)\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Initial weights - equal raw weights that will be converted to normalized weights\n",
    "initial_weights = np.zeros(len(pred_columns))\n",
    "\n",
    "# Try different optimization methods\n",
    "methods = [\n",
    "    'Nelder-Mead',\n",
    "    'Powell',\n",
    "    'CG',\n",
    "    'BFGS',\n",
    "    'L-BFGS-B',\n",
    "    'TNC',\n",
    "    'COBYLA',\n",
    "    'SLSQP',\n",
    "    'trust-constr',\n",
    "]\n",
    "\n",
    "for method in methods:\n",
    "    print(\"-\"*100)\n",
    "    print(f\"Optimizing blend using {method}:\")\n",
    "    try:\n",
    "        result = minimize(\n",
    "            lambda w: calculate_blend_rmse(w, pred_columns, combined_df),\n",
    "            initial_weights,\n",
    "            method=method\n",
    "        )\n",
    "            \n",
    "        if not result.success:\n",
    "            print(f\"\\nOptimizer {method} failed to converge\")\n",
    "            continue\n",
    "            \n",
    "        raw_weights = result.x\n",
    "        optimal_weights = np.exp(raw_weights) / np.sum(np.exp(raw_weights))\n",
    "\n",
    "        # Calculate final blended predictions with optimal weights\n",
    "        blended_predictions = np.zeros(len(combined_df))\n",
    "        for i, col in enumerate(pred_columns):\n",
    "            blended_predictions += optimal_weights[i] * combined_df[col].values\n",
    "\n",
    "        # Calculate and print final scores\n",
    "        blend_scores = []\n",
    "        for _, df in combined_df.groupby(\"fold\"):\n",
    "            fold_preds = blended_predictions[df.index].clip(-1, 1)\n",
    "            squared_errors = (df['utility_agent1_true'] - fold_preds)**2\n",
    "            rmse = np.sqrt(squared_errors.mean())\n",
    "            blend_scores.append(rmse)\n",
    "\n",
    "        print(f\"\\nOptimized blend using {method}:\")\n",
    "        print(\"Optimal weights:\")\n",
    "        for col, weight in zip(pred_columns, optimal_weights):\n",
    "            print(f\"{col}: {weight:.4f}\")\n",
    "        print(\"\\nScores per fold:\", [f\"{score:.4f}\" for score in blend_scores])\n",
    "        print(\"Average score: {:.4f}\".format(np.mean(blend_scores)))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nOptimizer {method} failed with error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/hkbjn4190p76_0dtnrpy7zwm0000gn/T/ipykernel_30647/808166944.py:16: ExperimentalWarning: QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n",
      "  sampler=optuna.samplers.QMCSampler()\n",
      "/Users/mavillan/Library/Caches/pypoetry/virtualenvs/mcts-strength-variants-E8z0EJ47-py3.10/lib/python3.10/site-packages/optuna/_experimental.py:30: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/Users/mavillan/Library/Caches/pypoetry/virtualenvs/mcts-strength-variants-E8z0EJ47-py3.10/lib/python3.10/site-packages/optuna/_experimental.py:30: ExperimentalWarning: Argument ``constant_liar`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimized blend using Optuna:\n",
      "Optimal weights:\n",
      "utility_agent1_pred_catboost: 0.9976\n",
      "utility_agent1_pred_mlp: 0.0000\n",
      "utility_agent1_pred_1dcnn: 0.0000\n",
      "utility_agent1_pred_gandalf: 0.0024\n",
      "\n",
      "Scores per fold: ['0.4213', '0.4072', '0.4117', '0.4141', '0.4202']\n",
      "Average score: 0.4149\n"
     ]
    }
   ],
   "source": [
    "# optimize using optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate weights that sum to 1 using softmax\n",
    "    raw_weights = [trial.suggest_float(f'w_{i}', -10, 10) for i in range(len(pred_columns))]\n",
    "    weights = np.exp(raw_weights) / np.sum(np.exp(raw_weights))\n",
    "    return calculate_blend_rmse(weights, pred_columns, combined_df)\n",
    "\n",
    "# Create and run study\n",
    "# First 1000 trials with QMC sampler\n",
    "study_qmc = optuna.create_study(\n",
    "    study_name=\"blend_optuna\",\n",
    "    direction='minimize',\n",
    "    load_if_exists=False,\n",
    "    sampler=optuna.samplers.QMCSampler()\n",
    ")\n",
    "study_qmc.optimize(objective, n_trials=1000)\n",
    "\n",
    "# Next 1000 trials with TPE sampler, starting from QMC results\n",
    "study_tpe = optuna.create_study(\n",
    "    study_name=\"blend_optuna\",\n",
    "    direction='minimize',\n",
    "    load_if_exists=True,\n",
    "    sampler=optuna.samplers.TPESampler(\n",
    "        n_startup_trials=1,    # Increase random sampling at start\n",
    "        n_ei_candidates=100,   # Consider more candidates\n",
    "        multivariate=True,     # Enable multivariate sampling\n",
    "        constant_liar=True     # Help with parallel optimization\n",
    "    )\n",
    ")\n",
    "\n",
    "# Transfer trials from QMC study to TPE study\n",
    "for trial in study_qmc.trials:\n",
    "    if trial.state == optuna.trial.TrialState.COMPLETE:\n",
    "        study_tpe.add_trial(trial)\n",
    "\n",
    "# Continue optimization with TPE sampler\n",
    "study_tpe.optimize(objective, n_trials=2000)\n",
    "\n",
    "# Get best weights using softmax\n",
    "raw_weights = [study_tpe.best_params[f'w_{i}'] for i in range(len(pred_columns))]\n",
    "optimal_weights = np.exp(raw_weights) / np.sum(np.exp(raw_weights))\n",
    "\n",
    "# Calculate final blended predictions with optimal weights\n",
    "blended_predictions = np.zeros(len(combined_df))\n",
    "for i, col in enumerate(pred_columns):\n",
    "    blended_predictions += optimal_weights[i] * combined_df[col].values\n",
    "\n",
    "# Calculate and print final scores\n",
    "blend_scores = []\n",
    "for _, df in combined_df.groupby(\"fold\"):\n",
    "    fold_preds = blended_predictions[df.index].clip(-1, 1)\n",
    "    squared_errors = (df['utility_agent1_true'] - fold_preds)**2\n",
    "    rmse = np.sqrt(squared_errors.mean())\n",
    "    blend_scores.append(rmse)\n",
    "\n",
    "print(\"\\nOptimized blend using Optuna:\")\n",
    "print(\"Optimal weights:\")\n",
    "for col, weight in zip(pred_columns, optimal_weights):\n",
    "    print(f\"{col}: {weight:.4f}\")\n",
    "print(\"\\nScores per fold:\", [f\"{score:.4f}\" for score in blend_scores])\n",
    "print(\"Average score: {:.4f}\".format(np.mean(blend_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, LassoCV, ElasticNetCV\n",
    " \n",
    "# # Create a linear blend of all predictions (excluding dt_nn) using sklearn LinearRegression\n",
    "# pred_columns = [\n",
    "#     col for col in combined_df.columns \n",
    "#     if 'pred' in col\n",
    "#     and 'dt_nn' not in col\n",
    "# ]\n",
    "\n",
    "# # Split data by fold and fit/predict on each fold\n",
    "# blend_scores = []\n",
    "# blended_predictions = np.zeros(len(combined_df))\n",
    "\n",
    "# for fold in combined_df['fold'].unique():\n",
    "#     # Split into train/test for this fold\n",
    "#     train_mask = combined_df['fold'] != fold\n",
    "#     test_mask = combined_df['fold'] == fold\n",
    "    \n",
    "#     X_train = combined_df.loc[train_mask, pred_columns]\n",
    "#     y_train = combined_df.loc[train_mask, 'utility_agent1_true']\n",
    "#     X_test = combined_df.loc[test_mask, pred_columns]\n",
    "#     y_test = combined_df.loc[test_mask, 'utility_agent1_true']\n",
    "    \n",
    "#     # Fit linear regression\n",
    "#     lr = LinearRegression(positive=True)  # Enforce positive weights\n",
    "#     # lr = Ridge(positive=True)\n",
    "#     # lr = RidgeCV()\n",
    "#     # lr = LassoCV()\n",
    "#     # lr = ElasticNetCV()\n",
    "#     lr.fit(X_train, y_train)\n",
    "    \n",
    "#     # Make predictions\n",
    "#     fold_preds = lr.predict(X_test).clip(-1, 1)\n",
    "#     blended_predictions[test_mask] = fold_preds\n",
    "    \n",
    "#     # Calculate score for this fold\n",
    "#     squared_errors = (y_test - fold_preds)**2\n",
    "#     rmse = np.sqrt(squared_errors.mean())\n",
    "#     blend_scores.append(rmse)\n",
    "\n",
    "# # Get final weights by fitting on all data\n",
    "# # lr_final = LinearRegression(positive=True)\n",
    "# # lr_final = RidgeCV()\n",
    "# # lr_final = LassoCV()\n",
    "# # lr_final = ElasticNetCV()\n",
    "# # lr_final = LinearSVR()\n",
    "\n",
    "# # lr_final.fit(combined_df[pred_columns], combined_df['utility_agent1_true'])\n",
    "# # optimal_weights = lr_final.coef_\n",
    "# # # Normalize weights to sum to 1\n",
    "# # optimal_weights = optimal_weights / np.sum(optimal_weights)\n",
    "\n",
    "# # print(\"\\nOptimized blend:\")\n",
    "# # print(\"Optimal weights:\")\n",
    "# # for col, weight in zip(pred_columns, optimal_weights):\n",
    "# #     print(f\"{col}: {weight:.4f}\")\n",
    "\n",
    "# print(\"\\nScores per fold:\", [f\"{score:.4f}\" for score in blend_scores])\n",
    "# print(\"Average score: {:.4f}\".format(np.mean(blend_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## post-proc test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof = pd.read_csv(path_results / \"oof_catboost_cv1.csv\")\n",
    "oof = oof.dropna(subset=[\"fold\"], ignore_index=True)\n",
    "oof[\"fold\"] = oof[\"fold\"].astype(int)\n",
    "oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cv_score(oof_df):\n",
    "    scores = list()\n",
    "    for _, df in oof_df.groupby(\"fold\"):\n",
    "        pred = df[\"utility_agent1_pred\"].clip(-1, 1)\n",
    "        squared_errors = (df['utility_agent1_true'] - pred)**2\n",
    "        rmse = np.sqrt(squared_errors.mean())\n",
    "        scores.append(rmse)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cv_score(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_oof = oof.copy()\n",
    "\n",
    "w = 1.1\n",
    "shift=0\n",
    "p_min = -0.985\n",
    "p_max = 0.985\n",
    "\n",
    "_oof[\"utility_agent1_pred\"] = (_oof[\"utility_agent1_pred\"] * w + shift).clip(p_min, p_max)\n",
    "\n",
    "compute_cv_score(_oof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcts-strength-variants-kSTIVMm8-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
