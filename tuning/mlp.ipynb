{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1\n",
      "PyTorch Lightning version: 2.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mavillan/Library/Caches/pypoetry/virtualenvs/mcts-strength-variants-E8z0EJ47-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union, Tuple, List\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pl.__version__}\")\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import (\n",
    "    plot_edf\n",
    "    , plot_optimization_history\n",
    "    , plot_parallel_coordinate\n",
    "    , plot_param_importances\n",
    "\n",
    "    , plot_slice\n",
    ")\n",
    "\n",
    "# local modules\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from preproc import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 2112\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import seed_everything\n",
    "seed_everything(2112, workers=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>GameRulesetName</th>\n",
       "      <th>agent1</th>\n",
       "      <th>agent2</th>\n",
       "      <th>Properties</th>\n",
       "      <th>Format</th>\n",
       "      <th>Time</th>\n",
       "      <th>Discrete</th>\n",
       "      <th>Realtime</th>\n",
       "      <th>Turns</th>\n",
       "      <th>...</th>\n",
       "      <th>DoLudeme</th>\n",
       "      <th>Trigger</th>\n",
       "      <th>PlayoutsPerSecond</th>\n",
       "      <th>MovesPerSecond</th>\n",
       "      <th>EnglishRules</th>\n",
       "      <th>LudRules</th>\n",
       "      <th>num_wins_agent1</th>\n",
       "      <th>num_draws_agent1</th>\n",
       "      <th>num_losses_agent1</th>\n",
       "      <th>utility_agent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00Y</td>\n",
       "      <td>MCTS-ProgressiveHistory-0.1-MAST-false</td>\n",
       "      <td>MCTS-ProgressiveHistory-0.6-Random200-false</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>298.07</td>\n",
       "      <td>18877.17</td>\n",
       "      <td>Goal: Connect all three edge colors with a sin...</td>\n",
       "      <td>(game \"00'Y'\" (players 2) (equipment { (board ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00Y</td>\n",
       "      <td>MCTS-ProgressiveHistory-0.1-MAST-false</td>\n",
       "      <td>MCTS-UCB1GRAVE-0.6-NST-true</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>298.07</td>\n",
       "      <td>18877.17</td>\n",
       "      <td>Goal: Connect all three edge colors with a sin...</td>\n",
       "      <td>(game \"00'Y'\" (players 2) (equipment { (board ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00Y</td>\n",
       "      <td>MCTS-ProgressiveHistory-0.1-MAST-true</td>\n",
       "      <td>MCTS-UCB1-0.1-NST-false</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>298.07</td>\n",
       "      <td>18877.17</td>\n",
       "      <td>Goal: Connect all three edge colors with a sin...</td>\n",
       "      <td>(game \"00'Y'\" (players 2) (equipment { (board ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00Y</td>\n",
       "      <td>MCTS-ProgressiveHistory-0.1-MAST-true</td>\n",
       "      <td>MCTS-UCB1-0.6-NST-false</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>298.07</td>\n",
       "      <td>18877.17</td>\n",
       "      <td>Goal: Connect all three edge colors with a sin...</td>\n",
       "      <td>(game \"00'Y'\" (players 2) (equipment { (board ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00Y</td>\n",
       "      <td>MCTS-ProgressiveHistory-0.1-MAST-true</td>\n",
       "      <td>MCTS-UCB1GRAVE-1.41421356237-NST-false</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>298.07</td>\n",
       "      <td>18877.17</td>\n",
       "      <td>Goal: Connect all three edge colors with a sin...</td>\n",
       "      <td>(game \"00'Y'\" (players 2) (equipment { (board ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233229</th>\n",
       "      <td>233229</td>\n",
       "      <td>Zuz_Mel_7x7</td>\n",
       "      <td>MCTS-UCB1Tuned-1.41421356237-NST-false</td>\n",
       "      <td>MCTS-ProgressiveHistory-1.41421356237-Random20...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157.52</td>\n",
       "      <td>157174.58</td>\n",
       "      <td>7x7 board. 24 pieces per player. Pieces begin ...</td>\n",
       "      <td>(game \"Zuz Mel (7x7)\" (players 2) (equipment {...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233230</th>\n",
       "      <td>233230</td>\n",
       "      <td>Zuz_Mel_7x7</td>\n",
       "      <td>MCTS-UCB1Tuned-1.41421356237-Random200-false</td>\n",
       "      <td>MCTS-UCB1-0.6-MAST-false</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157.52</td>\n",
       "      <td>157174.58</td>\n",
       "      <td>7x7 board. 24 pieces per player. Pieces begin ...</td>\n",
       "      <td>(game \"Zuz Mel (7x7)\" (players 2) (equipment {...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233231</th>\n",
       "      <td>233231</td>\n",
       "      <td>Zuz_Mel_7x7</td>\n",
       "      <td>MCTS-UCB1Tuned-1.41421356237-Random200-false</td>\n",
       "      <td>MCTS-UCB1GRAVE-1.41421356237-NST-false</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157.52</td>\n",
       "      <td>157174.58</td>\n",
       "      <td>7x7 board. 24 pieces per player. Pieces begin ...</td>\n",
       "      <td>(game \"Zuz Mel (7x7)\" (players 2) (equipment {...</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233232</th>\n",
       "      <td>233232</td>\n",
       "      <td>Zuz_Mel_7x7</td>\n",
       "      <td>MCTS-UCB1Tuned-1.41421356237-Random200-false</td>\n",
       "      <td>MCTS-UCB1GRAVE-1.41421356237-NST-true</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157.52</td>\n",
       "      <td>157174.58</td>\n",
       "      <td>7x7 board. 24 pieces per player. Pieces begin ...</td>\n",
       "      <td>(game \"Zuz Mel (7x7)\" (players 2) (equipment {...</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233233</th>\n",
       "      <td>233233</td>\n",
       "      <td>Zuz_Mel_7x7</td>\n",
       "      <td>MCTS-UCB1Tuned-1.41421356237-Random200-true</td>\n",
       "      <td>MCTS-UCB1Tuned-0.6-MAST-false</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157.52</td>\n",
       "      <td>157174.58</td>\n",
       "      <td>7x7 board. 24 pieces per player. Pieces begin ...</td>\n",
       "      <td>(game \"Zuz Mel (7x7)\" (players 2) (equipment {...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233234 rows Ã— 814 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id GameRulesetName                                        agent1  \\\n",
       "0            0             00Y        MCTS-ProgressiveHistory-0.1-MAST-false   \n",
       "1            1             00Y        MCTS-ProgressiveHistory-0.1-MAST-false   \n",
       "2            2             00Y         MCTS-ProgressiveHistory-0.1-MAST-true   \n",
       "3            3             00Y         MCTS-ProgressiveHistory-0.1-MAST-true   \n",
       "4            4             00Y         MCTS-ProgressiveHistory-0.1-MAST-true   \n",
       "...        ...             ...                                           ...   \n",
       "233229  233229     Zuz_Mel_7x7        MCTS-UCB1Tuned-1.41421356237-NST-false   \n",
       "233230  233230     Zuz_Mel_7x7  MCTS-UCB1Tuned-1.41421356237-Random200-false   \n",
       "233231  233231     Zuz_Mel_7x7  MCTS-UCB1Tuned-1.41421356237-Random200-false   \n",
       "233232  233232     Zuz_Mel_7x7  MCTS-UCB1Tuned-1.41421356237-Random200-false   \n",
       "233233  233233     Zuz_Mel_7x7   MCTS-UCB1Tuned-1.41421356237-Random200-true   \n",
       "\n",
       "                                                   agent2  Properties  Format  \\\n",
       "0             MCTS-ProgressiveHistory-0.6-Random200-false           1       1   \n",
       "1                             MCTS-UCB1GRAVE-0.6-NST-true           1       1   \n",
       "2                                 MCTS-UCB1-0.1-NST-false           1       1   \n",
       "3                                 MCTS-UCB1-0.6-NST-false           1       1   \n",
       "4                  MCTS-UCB1GRAVE-1.41421356237-NST-false           1       1   \n",
       "...                                                   ...         ...     ...   \n",
       "233229  MCTS-ProgressiveHistory-1.41421356237-Random20...           1       1   \n",
       "233230                           MCTS-UCB1-0.6-MAST-false           1       1   \n",
       "233231             MCTS-UCB1GRAVE-1.41421356237-NST-false           1       1   \n",
       "233232              MCTS-UCB1GRAVE-1.41421356237-NST-true           1       1   \n",
       "233233                      MCTS-UCB1Tuned-0.6-MAST-false           1       1   \n",
       "\n",
       "        Time  Discrete  Realtime  Turns  ...  DoLudeme  Trigger  \\\n",
       "0          1         1         0      1  ...         0        1   \n",
       "1          1         1         0      1  ...         0        1   \n",
       "2          1         1         0      1  ...         0        1   \n",
       "3          1         1         0      1  ...         0        1   \n",
       "4          1         1         0      1  ...         0        1   \n",
       "...      ...       ...       ...    ...  ...       ...      ...   \n",
       "233229     1         1         0      1  ...         0        0   \n",
       "233230     1         1         0      1  ...         0        0   \n",
       "233231     1         1         0      1  ...         0        0   \n",
       "233232     1         1         0      1  ...         0        0   \n",
       "233233     1         1         0      1  ...         0        0   \n",
       "\n",
       "        PlayoutsPerSecond  MovesPerSecond  \\\n",
       "0                  298.07        18877.17   \n",
       "1                  298.07        18877.17   \n",
       "2                  298.07        18877.17   \n",
       "3                  298.07        18877.17   \n",
       "4                  298.07        18877.17   \n",
       "...                   ...             ...   \n",
       "233229             157.52       157174.58   \n",
       "233230             157.52       157174.58   \n",
       "233231             157.52       157174.58   \n",
       "233232             157.52       157174.58   \n",
       "233233             157.52       157174.58   \n",
       "\n",
       "                                             EnglishRules  \\\n",
       "0       Goal: Connect all three edge colors with a sin...   \n",
       "1       Goal: Connect all three edge colors with a sin...   \n",
       "2       Goal: Connect all three edge colors with a sin...   \n",
       "3       Goal: Connect all three edge colors with a sin...   \n",
       "4       Goal: Connect all three edge colors with a sin...   \n",
       "...                                                   ...   \n",
       "233229  7x7 board. 24 pieces per player. Pieces begin ...   \n",
       "233230  7x7 board. 24 pieces per player. Pieces begin ...   \n",
       "233231  7x7 board. 24 pieces per player. Pieces begin ...   \n",
       "233232  7x7 board. 24 pieces per player. Pieces begin ...   \n",
       "233233  7x7 board. 24 pieces per player. Pieces begin ...   \n",
       "\n",
       "                                                 LudRules  num_wins_agent1  \\\n",
       "0       (game \"00'Y'\" (players 2) (equipment { (board ...                4   \n",
       "1       (game \"00'Y'\" (players 2) (equipment { (board ...                5   \n",
       "2       (game \"00'Y'\" (players 2) (equipment { (board ...                7   \n",
       "3       (game \"00'Y'\" (players 2) (equipment { (board ...                5   \n",
       "4       (game \"00'Y'\" (players 2) (equipment { (board ...                5   \n",
       "...                                                   ...              ...   \n",
       "233229  (game \"Zuz Mel (7x7)\" (players 2) (equipment {...                2   \n",
       "233230  (game \"Zuz Mel (7x7)\" (players 2) (equipment {...                9   \n",
       "233231  (game \"Zuz Mel (7x7)\" (players 2) (equipment {...               11   \n",
       "233232  (game \"Zuz Mel (7x7)\" (players 2) (equipment {...               24   \n",
       "233233  (game \"Zuz Mel (7x7)\" (players 2) (equipment {...                9   \n",
       "\n",
       "        num_draws_agent1  num_losses_agent1  utility_agent1  \n",
       "0                      0                 11       -0.466667  \n",
       "1                      0                 10       -0.333333  \n",
       "2                      0                  8       -0.066667  \n",
       "3                      0                 10       -0.333333  \n",
       "4                      0                 10       -0.333333  \n",
       "...                  ...                ...             ...  \n",
       "233229                 0                 13       -0.733333  \n",
       "233230                 1                  5        0.266667  \n",
       "233231                 3                  1        0.666667  \n",
       "233232                 2                  4        0.666667  \n",
       "233233                 1                  5        0.266667  \n",
       "\n",
       "[233234 rows x 814 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define some paths\n",
    "path_raw = Path(\"../data/raw\")\n",
    "path_processed = Path(\"../data/processed\")\n",
    "path_results = Path(\"../data/results\")\n",
    "\n",
    "# load data\n",
    "df_train = pd.read_csv(path_raw / \"train.csv\")\n",
    "df_test = pd.read_csv(path_raw / \"test.csv\")\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: 588\n",
      "Categorical Columns: 10\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "df_train, df_test, numerical_cols, categorical_cols = preprocess_data(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    scale_utility=True\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "print(\"Numerical Columns:\", len(numerical_cols))\n",
    "print(\"Categorical Columns:\", len(categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_train['utility_agent1_scaled'], bins=100)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.xlabel('Utility Agent 1')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 72, 4, 3, 3, 2, 4, 3, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "df_train[numerical_cols] = df_train[numerical_cols].astype(np.float32)\n",
    "df_train[categorical_cols] = df_train[categorical_cols].astype(np.int32)\n",
    "\n",
    "cat_input_dims = df_train[categorical_cols].nunique(axis=0).values.tolist()\n",
    "print(cat_input_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns have been scaled using StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical columns of df_train\n",
    "df_train[numerical_cols] = scaler.fit_transform(df_train[numerical_cols])\n",
    "\n",
    "# Print a message to confirm the scaling\n",
    "print(\"Numerical columns have been scaled using StandardScaler.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "            num_input_dim: int,\n",
    "            cat_input_dims: list[int],\n",
    "            output_dim: int,\n",
    "            layers: str,\n",
    "            dropout: float,\n",
    "            learning_rate: float = 1e-3,\n",
    "            weight_decay: float = 1e-5,\n",
    "            initialization: str = 'kaiming_uniform',\n",
    "            embedding_dim: Optional[List[int]] = None,\n",
    "            pct_start: float = 0.2,\n",
    "            div_factor: float = 10.0,\n",
    "            final_div_factor: float = 1e4,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.dropout = dropout\n",
    "        self.pct_start = pct_start\n",
    "        self.div_factor = div_factor\n",
    "        self.final_div_factor = final_div_factor\n",
    "\n",
    "        # Initialize embedding dimensions if not provided\n",
    "        if embedding_dim is None:\n",
    "            # Rule of thumb: min(50, num_unique // 2 + 1) for each categorical feature\n",
    "            embedding_dim = [min(50, int(1 + np.ceil(np.sqrt(dim)))) for dim in cat_input_dims]\n",
    "\n",
    "        elif len(embedding_dim) != len(cat_input_dims):\n",
    "            raise ValueError(\"Length of embedding_dim must match number of categorical features.\")\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # Create embedding layers\n",
    "        self.create_embeddings(cat_input_dims, embedding_dim)\n",
    "\n",
    "        # Create backbone layers\n",
    "        self.create_backbone(num_input_dim, layers)\n",
    "\n",
    "        # Create head layers\n",
    "        self.create_head(output_dim)\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.initialization = initialization\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "        # Initialize lists to store validation outputs\n",
    "        self.validation_targets = []\n",
    "        self.validation_predictions = []\n",
    "\n",
    "    def create_embeddings(self, cat_input_dims: list[int], embedding_dim: list[int]):\n",
    "        self.embeddings = nn.ModuleList(\n",
    "            [nn.Embedding(dim, emb_dim) for dim, emb_dim in zip(cat_input_dims, embedding_dim)]\n",
    "        )\n",
    "\n",
    "    def create_backbone(self, num_input_dim: int, layers: str):\n",
    "        # Calculate total input dimension after embeddings\n",
    "        total_embedding_dim = sum(self.embedding_dim)\n",
    "        total_input_dim = num_input_dim + total_embedding_dim\n",
    "\n",
    "        # Parse layers string\n",
    "        layer_sizes = [int(size) for size in layers.split('-')]\n",
    "\n",
    "        # Create backbone network layers\n",
    "        backbone_layers = []\n",
    "        prev_size = total_input_dim\n",
    "        for size in layer_sizes:\n",
    "            backbone_layers.extend([\n",
    "                nn.BatchNorm1d(prev_size),\n",
    "                nn.Linear(prev_size, size),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.hparams.dropout),\n",
    "            ])\n",
    "            prev_size = size\n",
    "        self.backbone = nn.Sequential(*backbone_layers)\n",
    "        self.backbone_output_size = prev_size\n",
    "\n",
    "    def create_head(self, output_dim: int):\n",
    "        # Output layer\n",
    "        self.head = nn.Sequential(\n",
    "            nn.BatchNorm1d(self.backbone_output_size),\n",
    "            nn.Linear(self.backbone_output_size, output_dim)\n",
    "        )\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                if any(module is m for m in self.head.modules()):\n",
    "                    nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('tanh'))\n",
    "                else:\n",
    "                    if self.initialization == 'kaiming_uniform':\n",
    "                        nn.init.kaiming_uniform_(module.weight, nonlinearity='relu')\n",
    "                    elif self.initialization == 'kaiming_normal':\n",
    "                        nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "                    elif self.initialization == 'xavier_uniform':\n",
    "                        nn.init.xavier_uniform_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                    elif self.initialization == 'xavier_normal':\n",
    "                        nn.init.xavier_normal_(module.weight, gain=nn.init.calculate_gain('relu'))\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unsupported initialization method: {self.initialization}\")\n",
    "                \n",
    "                # Initialize bias to small values\n",
    "                if module.bias is not None:\n",
    "                    nn.init.uniform_(module.bias, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        # Process categorical variables\n",
    "        embedded = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        embedded = torch.cat(embedded, dim=1)\n",
    "        \n",
    "        # Concatenate numerical and embedded categorical features\n",
    "        x = torch.cat([x_num, embedded], dim=1)\n",
    "        \n",
    "        # Pass through backbone\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # Pass through head\n",
    "        x = self.head(x)\n",
    "        x = nn.functional.hardtanh(x)\n",
    "\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x_num, x_cat, y = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('valid_loss', loss, prog_bar=True)\n",
    "        # Store targets and predictions for later use\n",
    "        self.validation_targets.append(y)\n",
    "        self.validation_predictions.append(y_hat)\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        if len(batch) == 2:\n",
    "            x_num, x_cat = batch\n",
    "        elif len(batch) == 3:\n",
    "            x_num, x_cat, _ = batch\n",
    "        y_hat = self(x_num, x_cat)\n",
    "        return y_hat\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Concatenate all targets and predictions\n",
    "        y = torch.cat(self.validation_targets)\n",
    "        y_hat = torch.cat(self.validation_predictions)\n",
    "        rmse = torch.sqrt(F.mse_loss(y_hat, y))\n",
    "        self.log('val_rmse', rmse, prog_bar=True)\n",
    "        # Clear the lists for next epoch\n",
    "        self.validation_targets.clear()\n",
    "        self.validation_predictions.clear()\n",
    "                \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), \n",
    "            lr=self.learning_rate, \n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr=self.learning_rate,\n",
    "            total_steps=self.trainer.estimated_stepping_batches,\n",
    "            pct_start=self.pct_start,\n",
    "            div_factor=self.div_factor,\n",
    "            final_div_factor=self.final_div_factor,\n",
    "            anneal_strategy='cos',\n",
    "            cycle_momentum=True,\n",
    "            base_momentum=0.85,\n",
    "            max_momentum=0.95,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Define the column for stratified or group k-fold\n",
    "groups_col = 'GameRulesetName'\n",
    "gkf = GroupKFold(n_splits=num_folds)\n",
    "split_list = list(gkf.split(df_train, groups=df_train[groups_col]))\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor='val_rmse',\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "def train_and_score(\n",
    "        batch_size,\n",
    "        dropout,\n",
    "        input_layer_size,\n",
    "        n_layers,\n",
    "        learning_rate,\n",
    "        weight_decay,\n",
    "        initialization,\n",
    "        pct_start,\n",
    "        div_factor,\n",
    "        final_div_factor,\n",
    "    ):\n",
    "    oof_scores = []\n",
    "\n",
    "    # Perform cross-validation\n",
    "    for _, (train_index, val_index) in enumerate(split_list, 1):\n",
    "        \n",
    "        # Split the data\n",
    "        train, valid = df_train.iloc[train_index], df_train.iloc[val_index]\n",
    "\n",
    "        train_dataset = TensorDataset(\n",
    "            torch.tensor(train[numerical_cols].values, dtype=torch.float32),\n",
    "            torch.tensor(train[categorical_cols].values, dtype=torch.int32),\n",
    "            torch.tensor(train['utility_agent1'].values, dtype=torch.float32)\n",
    "        )\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=8,\n",
    "            persistent_workers=True\n",
    "        )\n",
    "\n",
    "        valid_dataset = TensorDataset(\n",
    "            torch.tensor(valid[numerical_cols].values, dtype=torch.float32),\n",
    "            torch.tensor(valid[categorical_cols].values, dtype=torch.int32),\n",
    "            torch.tensor(valid['utility_agent1'].values, dtype=torch.float32)\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=8,\n",
    "            persistent_workers=True\n",
    "        )\n",
    "\n",
    "        # Construct the layers string based on input_layer_size and n_layers\n",
    "        layers = \"-\".join([str(input_layer_size // (2 ** i)) for i in range(n_layers)])\n",
    "\n",
    "        model = MLP(\n",
    "            num_input_dim=len(numerical_cols),\n",
    "            cat_input_dims=cat_input_dims,\n",
    "            output_dim=1,\n",
    "            layers=layers,\n",
    "            dropout=dropout,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            initialization=initialization,\n",
    "            pct_start=pct_start,\n",
    "            div_factor=div_factor,\n",
    "            final_div_factor=final_div_factor,\n",
    "        )\n",
    "        trainer = pl.Trainer(\n",
    "            min_epochs=20,\n",
    "            max_epochs=100, \n",
    "            deterministic=True,\n",
    "            accelerator=\"mps\",\n",
    "            enable_progress_bar=False,\n",
    "            enable_model_summary=False,\n",
    "            callbacks=[\n",
    "                early_stop_callback, \n",
    "                ModelCheckpoint(monitor='val_rmse', mode='min', save_top_k=1),\n",
    "            ],\n",
    "        );\n",
    "        trainer.fit(\n",
    "            model, \n",
    "            train_loader,\n",
    "            valid_loader,\n",
    "        );\n",
    "\n",
    "        # Load the best model\n",
    "        best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "        model = MLP.load_from_checkpoint(best_model_path)\n",
    "\n",
    "        # Predict on validation set using trainer.predict with the prediction DataLoader\n",
    "        predictions = trainer.predict(model, dataloaders=valid_loader)\n",
    "        y_pred = torch.cat(predictions).squeeze().cpu().numpy()\n",
    "         \n",
    "        # Compute RMSE on scaled values\n",
    "        y_valid = valid['utility_agent1'].values\n",
    "        rmse = np.sqrt(np.mean((y_pred - y_valid) ** 2))\n",
    "        oof_scores.append(rmse)\n",
    "\n",
    "    return np.mean(oof_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters to tune\n",
    "    batch_size = trial.suggest_int('batch_size', 128, 512, step=64)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.3, step=0.05)\n",
    "    input_layer_size = trial.suggest_int('input_layer_size', 512, 1024, step=64)\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 4)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True)\n",
    "    pct_start = trial.suggest_float('pct_start', 0.05, 0.2, step=0.05)\n",
    "    div_factor = trial.suggest_float('div_factor', 1.0, 100.0, step=1.0)\n",
    "    final_div_factor = trial.suggest_float('final_div_factor', 1e0, 1e4, log=True)\n",
    "\n",
    "    # Train and evaluate the model with the suggested hyperparameters\n",
    "    oof_score = train_and_score(\n",
    "        batch_size=batch_size,\n",
    "        dropout=dropout,\n",
    "        input_layer_size=input_layer_size,\n",
    "        n_layers=n_layers,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        initialization=\"kaiming_uniform\",\n",
    "        pct_start=pct_start,\n",
    "        div_factor=div_factor,\n",
    "        final_div_factor=final_div_factor,\n",
    "    )\n",
    "\n",
    "    return oof_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-05 12:14:23,520] Using an existing study with name 'mlp' instead of creating a new one.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/mavillan/Library/Caches/pypoetry/virtualenvs/mcts-strength-variants-E8z0EJ47-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 12:28:42,030] Trial 80 finished with value: 0.4891283724311615 and parameters: {'batch_size': 448, 'dropout': 0.05, 'input_layer_size': 640, 'n_layers': 2, 'learning_rate': 0.0008437985806555495, 'weight_decay': 0.0002743539761243927, 'pct_start': 0.15000000000000002, 'div_factor': 78.0, 'final_div_factor': 578.3298906606126}. Best is trial 55 with value: 0.46765089132423154.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 12:42:24,171] Trial 81 finished with value: 0.47146206060207463 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0016721885391653116, 'weight_decay': 0.00041619059627920693, 'pct_start': 0.05, 'div_factor': 59.0, 'final_div_factor': 9890.35577806349}. Best is trial 55 with value: 0.46765089132423154.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 12:56:05,775] Trial 82 finished with value: 0.4725066716247543 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.001798210661220461, 'weight_decay': 0.0003483263169371521, 'pct_start': 0.05, 'div_factor': 63.0, 'final_div_factor': 7180.778667353889}. Best is trial 55 with value: 0.46765089132423154.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 13:11:55,634] Trial 83 finished with value: 0.47421981432720495 and parameters: {'batch_size': 384, 'dropout': 0.0, 'input_layer_size': 896, 'n_layers': 4, 'learning_rate': 0.0012278334119140393, 'weight_decay': 0.0005083204529828265, 'pct_start': 0.05, 'div_factor': 60.0, 'final_div_factor': 4025.7501923145373}. Best is trial 55 with value: 0.46765089132423154.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 13:25:45,108] Trial 84 finished with value: 0.47509827674326494 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 1024, 'n_layers': 4, 'learning_rate': 0.0016799848334505796, 'weight_decay': 0.00042603254651470574, 'pct_start': 0.05, 'div_factor': 16.0, 'final_div_factor': 5605.051643784766}. Best is trial 55 with value: 0.46765089132423154.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 13:37:55,900] Trial 85 finished with value: 0.467506767790427 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0024718408263323865, 'weight_decay': 0.0001916307882604006, 'pct_start': 0.05, 'div_factor': 50.0, 'final_div_factor': 169.8490646338428}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 13:50:10,045] Trial 86 finished with value: 0.48101392759986794 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0027097425147124157, 'weight_decay': 0.0007362811055687027, 'pct_start': 0.05, 'div_factor': 52.0, 'final_div_factor': 185.77153317791382}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 14:02:24,894] Trial 87 finished with value: 0.476056847897639 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.00402965810370141, 'weight_decay': 0.00019592030310977223, 'pct_start': 0.05, 'div_factor': 49.0, 'final_div_factor': 80.73418443533755}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 14:14:35,484] Trial 88 finished with value: 0.4864916518815289 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0023684066691862763, 'weight_decay': 0.002438469697807971, 'pct_start': 0.05, 'div_factor': 57.0, 'final_div_factor': 404.65019465356903}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 14:34:14,327] Trial 89 finished with value: 0.4764027842181404 and parameters: {'batch_size': 320, 'dropout': 0.05, 'input_layer_size': 1024, 'n_layers': 4, 'learning_rate': 0.0014293689230552352, 'weight_decay': 0.00013840530659470088, 'pct_start': 0.05, 'div_factor': 42.0, 'final_div_factor': 8699.959785231998}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 14:48:03,168] Trial 90 finished with value: 0.4710527345378048 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0030892057749508607, 'weight_decay': 0.00022898061249597245, 'pct_start': 0.05, 'div_factor': 55.0, 'final_div_factor': 134.2824958159751}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 15:01:49,663] Trial 91 finished with value: 0.47533313375982755 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.003632696604335304, 'weight_decay': 0.000228513069141484, 'pct_start': 0.05, 'div_factor': 65.0, 'final_div_factor': 126.93897833303627}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 15:15:40,338] Trial 92 finished with value: 0.476651268681432 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 768, 'n_layers': 4, 'learning_rate': 0.0029847270877637797, 'weight_decay': 0.0002632977109583292, 'pct_start': 0.05, 'div_factor': 55.0, 'final_div_factor': 61.103795953635135}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 15:29:27,799] Trial 93 finished with value: 0.47011212845426753 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0019517052141859363, 'weight_decay': 0.00017320583008140336, 'pct_start': 0.05, 'div_factor': 63.0, 'final_div_factor': 124.71499218858786}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 15:43:17,214] Trial 94 finished with value: 0.4678993784002907 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.001954526669597874, 'weight_decay': 0.00016141079337028477, 'pct_start': 0.05, 'div_factor': 68.0, 'final_div_factor': 117.96549330827749}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 15:57:03,485] Trial 95 finished with value: 0.47614993484406687 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0025010367996584214, 'weight_decay': 0.00012311443581728367, 'pct_start': 0.05, 'div_factor': 70.0, 'final_div_factor': 111.51138887595032}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 16:12:54,563] Trial 96 finished with value: 0.4699721327650116 and parameters: {'batch_size': 384, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0020103768406555477, 'weight_decay': 0.00010245305639032575, 'pct_start': 0.05, 'div_factor': 75.0, 'final_div_factor': 166.80605383010212}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 16:28:48,128] Trial 97 finished with value: 0.47817908620643507 and parameters: {'batch_size': 384, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0019175830650159684, 'weight_decay': 0.00010158637042178419, 'pct_start': 0.05, 'div_factor': 75.0, 'final_div_factor': 145.18309416764177}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 16:42:38,182] Trial 98 finished with value: 0.47195365450561433 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0021230644640334185, 'weight_decay': 0.00015699556853067138, 'pct_start': 0.05, 'div_factor': 67.0, 'final_div_factor': 209.02911070298367}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 16:56:25,648] Trial 99 finished with value: 0.47098801612099744 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.004711783238308327, 'weight_decay': 0.00011291452373247455, 'pct_start': 0.05, 'div_factor': 82.0, 'final_div_factor': 64.12015163151655}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 17:13:05,955] Trial 100 finished with value: 0.47361158599473674 and parameters: {'batch_size': 384, 'dropout': 0.05, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.005995828159654584, 'weight_decay': 0.00010775068739997858, 'pct_start': 0.05, 'div_factor': 84.0, 'final_div_factor': 69.04903108816522}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 17:26:54,241] Trial 101 finished with value: 0.4734281162019044 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.004646904673134746, 'weight_decay': 0.00012636536633555648, 'pct_start': 0.05, 'div_factor': 78.0, 'final_div_factor': 33.058536747584064}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 17:40:45,687] Trial 102 finished with value: 0.46773682273024947 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.005848662257234637, 'weight_decay': 0.00011169079801714288, 'pct_start': 0.05, 'div_factor': 83.0, 'final_div_factor': 100.15477371068445}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 17:54:40,099] Trial 103 finished with value: 0.47442986625995054 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 768, 'n_layers': 4, 'learning_rate': 0.007135404849144521, 'weight_decay': 0.0001092764398713156, 'pct_start': 0.05, 'div_factor': 85.0, 'final_div_factor': 43.970369285685464}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 18:08:28,021] Trial 104 finished with value: 0.47992965659307973 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.009881028664983504, 'weight_decay': 0.0001462632497971228, 'pct_start': 0.05, 'div_factor': 82.0, 'final_div_factor': 167.86346224550027}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 18:24:20,412] Trial 105 finished with value: 0.4803537810227622 and parameters: {'batch_size': 384, 'dropout': 0.0, 'input_layer_size': 768, 'n_layers': 4, 'learning_rate': 0.006487683921332241, 'weight_decay': 0.00011614691916624065, 'pct_start': 0.05, 'div_factor': 90.0, 'final_div_factor': 83.51825613102835}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 18:38:08,766] Trial 106 finished with value: 0.47782849991800813 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.007884725782773817, 'weight_decay': 0.00013319830128850075, 'pct_start': 0.05, 'div_factor': 73.0, 'final_div_factor': 116.9405239402451}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 18:51:58,853] Trial 107 finished with value: 0.4755833048830165 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.005618349165551915, 'weight_decay': 0.00017305757406693934, 'pct_start': 0.05, 'div_factor': 81.0, 'final_div_factor': 260.3860686876697}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 19:05:50,519] Trial 108 finished with value: 0.47442427700593404 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 768, 'n_layers': 4, 'learning_rate': 0.004244858975246592, 'weight_decay': 0.00016264053160329508, 'pct_start': 0.05, 'div_factor': 64.0, 'final_div_factor': 97.03367828129187}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 19:22:36,918] Trial 109 finished with value: 0.47152652209703544 and parameters: {'batch_size': 384, 'dropout': 0.05, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0022427699341500333, 'weight_decay': 0.000148115202982413, 'pct_start': 0.05, 'div_factor': 77.0, 'final_div_factor': 327.3017302435278}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 19:36:27,490] Trial 110 finished with value: 0.47418346018185636 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 576, 'n_layers': 4, 'learning_rate': 0.0034018048938390575, 'weight_decay': 0.00019160560199752458, 'pct_start': 0.05, 'div_factor': 87.0, 'final_div_factor': 67.12404842911144}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 19:50:16,391] Trial 111 finished with value: 0.47059656434887476 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.002878012049058467, 'weight_decay': 0.00011450514803913479, 'pct_start': 0.05, 'div_factor': 51.0, 'final_div_factor': 47.26600606846899}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 20:04:05,560] Trial 112 finished with value: 0.4726290772044729 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.002601913282618621, 'weight_decay': 0.00010919986208274353, 'pct_start': 0.05, 'div_factor': 51.0, 'final_div_factor': 15.817979218812525}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 20:17:58,961] Trial 113 finished with value: 0.4765326919998197 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0019963123356674336, 'weight_decay': 0.00012926695802538938, 'pct_start': 0.05, 'div_factor': 93.0, 'final_div_factor': 53.92216880614223}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 20:30:09,446] Trial 114 finished with value: 0.47697419245679706 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.00291886859734924, 'weight_decay': 0.00011273614675604906, 'pct_start': 0.05, 'div_factor': 46.0, 'final_div_factor': 30.627509739396043}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 20:44:00,015] Trial 115 finished with value: 0.47808491617680593 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0013421038927177934, 'weight_decay': 0.00010142008595495492, 'pct_start': 0.05, 'div_factor': 68.0, 'final_div_factor': 45.120645183726126}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 20:57:50,087] Trial 116 finished with value: 0.4733793731938419 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0018763547424458956, 'weight_decay': 0.00014194986150155032, 'pct_start': 0.05, 'div_factor': 53.0, 'final_div_factor': 21.39726322111083}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 21:10:04,409] Trial 117 finished with value: 0.4726823801968501 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 768, 'n_layers': 4, 'learning_rate': 0.0016376642645953873, 'weight_decay': 0.0001620388935980509, 'pct_start': 0.05, 'div_factor': 62.0, 'final_div_factor': 72.86186552739736}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 21:24:29,346] Trial 118 finished with value: 0.4698592048259145 and parameters: {'batch_size': 448, 'dropout': 0.05, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0022056844149485723, 'weight_decay': 0.00018462500016201933, 'pct_start': 0.05, 'div_factor': 44.0, 'final_div_factor': 100.08006602350139}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 21:41:10,997] Trial 119 finished with value: 0.47211085906567885 and parameters: {'batch_size': 384, 'dropout': 0.05, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0021550769832010476, 'weight_decay': 0.00021516483099917488, 'pct_start': 0.05, 'div_factor': 43.0, 'final_div_factor': 5.466394474656609}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 21:55:41,093] Trial 120 finished with value: 0.47244852982364655 and parameters: {'batch_size': 448, 'dropout': 0.05, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0024408391945993217, 'weight_decay': 0.0001802256911268041, 'pct_start': 0.05, 'div_factor': 48.0, 'final_div_factor': 227.22274146402242}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 22:09:26,966] Trial 121 finished with value: 0.47838932217908525 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0017690679881125723, 'weight_decay': 0.00012696632661677264, 'pct_start': 0.05, 'div_factor': 75.0, 'final_div_factor': 157.48702447608616}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 22:23:13,487] Trial 122 finished with value: 0.48037627474070604 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.005264538801610082, 'weight_decay': 0.0002047561283958063, 'pct_start': 0.05, 'div_factor': 45.0, 'final_div_factor': 92.08738055984361}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 22:37:41,484] Trial 123 finished with value: 0.47918118849053537 and parameters: {'batch_size': 448, 'dropout': 0.05, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.00202348196666755, 'weight_decay': 0.00011706034840997335, 'pct_start': 0.05, 'div_factor': 71.0, 'final_div_factor': 34.07163844200518}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 22:51:27,017] Trial 124 finished with value: 0.4741612926631936 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 576, 'n_layers': 4, 'learning_rate': 0.0022696173046276957, 'weight_decay': 0.0003738691939148039, 'pct_start': 0.05, 'div_factor': 50.0, 'final_div_factor': 107.00125566825993}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 23:03:44,865] Trial 125 finished with value: 0.4728438033902339 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0028148436626532066, 'weight_decay': 0.00015191151589422427, 'pct_start': 0.05, 'div_factor': 41.0, 'final_div_factor': 55.232000996049564}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 23:19:40,689] Trial 126 finished with value: 0.47374695314225157 and parameters: {'batch_size': 384, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.00441159656220877, 'weight_decay': 0.00017983498526603518, 'pct_start': 0.05, 'div_factor': 37.0, 'final_div_factor': 175.73065336464336}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 23:33:33,006] Trial 127 finished with value: 0.4717925652091289 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0015581377517392206, 'weight_decay': 0.0001394135756010294, 'pct_start': 0.05, 'div_factor': 57.0, 'final_div_factor': 81.51227079613224}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-05 23:47:28,770] Trial 128 finished with value: 0.4802410386796166 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0037065977085008195, 'weight_decay': 0.0005627568137705138, 'pct_start': 0.2, 'div_factor': 47.0, 'final_div_factor': 1.1364212056994833}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 00:01:18,735] Trial 129 finished with value: 0.4696368344828613 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0025468322465428106, 'weight_decay': 0.0003008301169983658, 'pct_start': 0.05, 'div_factor': 80.0, 'final_div_factor': 101.20740205177643}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 00:14:11,502] Trial 130 finished with value: 0.4757084202950518 and parameters: {'batch_size': 512, 'dropout': 0.05, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.003199490695979665, 'weight_decay': 0.0002989331190118074, 'pct_start': 0.05, 'div_factor': 65.0, 'final_div_factor': 134.35640088083352}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 00:28:05,073] Trial 131 finished with value: 0.47374940389009607 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.002535189798530011, 'weight_decay': 0.00024179323164855382, 'pct_start': 0.05, 'div_factor': 82.0, 'final_div_factor': 115.77045262866183}. Best is trial 85 with value: 0.467506767790427.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 00:41:54,434] Trial 132 finished with value: 0.46740088270443064 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0017902381479678216, 'weight_decay': 0.0003339096474946611, 'pct_start': 0.05, 'div_factor': 74.0, 'final_div_factor': 39.31519465021811}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 00:55:48,047] Trial 133 finished with value: 0.47205506449530016 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0017892227969294957, 'weight_decay': 0.0003664521062264116, 'pct_start': 0.05, 'div_factor': 75.0, 'final_div_factor': 47.68712902949748}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 01:09:34,766] Trial 134 finished with value: 0.4701365183923391 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0019658700902409304, 'weight_decay': 0.00028375833318134677, 'pct_start': 0.05, 'div_factor': 73.0, 'final_div_factor': 37.00196636478465}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 01:23:24,450] Trial 135 finished with value: 0.47411675921598045 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0014338256982313557, 'weight_decay': 0.0003127081069390654, 'pct_start': 0.05, 'div_factor': 72.0, 'final_div_factor': 9.297137355017743}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 01:37:13,470] Trial 136 finished with value: 0.47143572671749556 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0019199046328073352, 'weight_decay': 0.0003295096586027058, 'pct_start': 0.05, 'div_factor': 80.0, 'final_div_factor': 22.625806997939893}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 01:51:10,382] Trial 137 finished with value: 0.46767101671620426 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.002222371623277783, 'weight_decay': 0.00026761424617924745, 'pct_start': 0.05, 'div_factor': 69.0, 'final_div_factor': 198.1295051574072}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 02:03:27,042] Trial 138 finished with value: 0.4773971007552863 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.002226336920072351, 'weight_decay': 0.00027284838714712606, 'pct_start': 0.05, 'div_factor': 77.0, 'final_div_factor': 204.17466115092523}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 02:17:19,558] Trial 139 finished with value: 0.47186851126008583 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 768, 'n_layers': 4, 'learning_rate': 0.0016946279835980205, 'weight_decay': 0.00025822628503633434, 'pct_start': 0.05, 'div_factor': 69.0, 'final_div_factor': 379.37647186333857}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 02:31:08,117] Trial 140 finished with value: 0.4726959032666368 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 576, 'n_layers': 4, 'learning_rate': 0.001348125811839606, 'weight_decay': 0.00044862227230969067, 'pct_start': 0.05, 'div_factor': 67.0, 'final_div_factor': 35.88684598243863}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 02:45:02,823] Trial 141 finished with value: 0.480404100490545 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0021176200770539255, 'weight_decay': 0.0002969646714440739, 'pct_start': 0.05, 'div_factor': 74.0, 'final_div_factor': 155.19559664910116}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 02:58:58,309] Trial 142 finished with value: 0.4725809782928513 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0019515789000444986, 'weight_decay': 0.0003932102126072857, 'pct_start': 0.05, 'div_factor': 61.0, 'final_div_factor': 255.75558238717986}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 03:12:53,712] Trial 143 finished with value: 0.47610778828381245 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0024578921296118427, 'weight_decay': 0.00021750611648465817, 'pct_start': 0.05, 'div_factor': 71.0, 'final_div_factor': 98.91240690610786}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 03:26:50,621] Trial 144 finished with value: 0.4725246665125689 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0016782284137755663, 'weight_decay': 0.00027834476712400405, 'pct_start': 0.05, 'div_factor': 66.0, 'final_div_factor': 184.08810580313218}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 03:40:47,332] Trial 145 finished with value: 0.46920679239328467 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0015363302714005939, 'weight_decay': 0.00033462496750132705, 'pct_start': 0.05, 'div_factor': 79.0, 'final_div_factor': 129.6835928990538}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 03:56:43,780] Trial 146 finished with value: 0.4747861185140221 and parameters: {'batch_size': 384, 'dropout': 0.0, 'input_layer_size': 896, 'n_layers': 4, 'learning_rate': 0.0011994619193719978, 'weight_decay': 0.00033532182219345364, 'pct_start': 0.05, 'div_factor': 79.0, 'final_div_factor': 128.834329160655}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 04:10:39,939] Trial 147 finished with value: 0.47425826551568157 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 1024, 'n_layers': 4, 'learning_rate': 0.0014506002723293067, 'weight_decay': 0.000195755673819026, 'pct_start': 0.05, 'div_factor': 76.0, 'final_div_factor': 102.76672649015565}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 04:25:11,392] Trial 148 finished with value: 0.4801263660247838 and parameters: {'batch_size': 448, 'dropout': 0.1, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0009311012354072914, 'weight_decay': 0.00023569877560062193, 'pct_start': 0.05, 'div_factor': 69.0, 'final_div_factor': 78.0559838241223}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 04:38:02,382] Trial 149 finished with value: 0.4754080991120146 and parameters: {'batch_size': 512, 'dropout': 0.05, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0010829844417766141, 'weight_decay': 0.0003618273690138366, 'pct_start': 0.05, 'div_factor': 73.0, 'final_div_factor': 148.3861015882646}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 04:53:53,855] Trial 150 finished with value: 0.4727588315492456 and parameters: {'batch_size': 384, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0015319453667741098, 'weight_decay': 0.0004713936376554219, 'pct_start': 0.05, 'div_factor': 80.0, 'final_div_factor': 216.33086907606665}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 05:07:48,062] Trial 151 finished with value: 0.476782389620511 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0018820965618550772, 'weight_decay': 0.00032449086992358963, 'pct_start': 0.05, 'div_factor': 83.0, 'final_div_factor': 116.12526237150085}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 05:21:41,568] Trial 152 finished with value: 0.4745475629573795 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0022902348664587254, 'weight_decay': 0.0002571668472127104, 'pct_start': 0.05, 'div_factor': 63.0, 'final_div_factor': 88.47140519306649}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 05:35:35,713] Trial 153 finished with value: 0.4744544017281635 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0020510578255722267, 'weight_decay': 0.0004006253288538742, 'pct_start': 0.05, 'div_factor': 44.0, 'final_div_factor': 7936.959152192446}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 05:49:29,893] Trial 154 finished with value: 0.4733290955868358 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0026867786514655372, 'weight_decay': 0.00030065841689346293, 'pct_start': 0.05, 'div_factor': 59.0, 'final_div_factor': 309.66423026087256}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 06:03:27,254] Trial 155 finished with value: 0.4736699109515882 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 960, 'n_layers': 4, 'learning_rate': 0.0017922096430485418, 'weight_decay': 0.00043431261539511205, 'pct_start': 0.05, 'div_factor': 86.0, 'final_div_factor': 175.0062433120965}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 06:17:15,182] Trial 156 finished with value: 0.47054529547851914 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0015833133748020993, 'weight_decay': 0.0003454084721556179, 'pct_start': 0.05, 'div_factor': 67.0, 'final_div_factor': 6422.083773921282}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 06:31:04,212] Trial 157 finished with value: 0.47366229101686796 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0012742420270781302, 'weight_decay': 0.00034323650549377587, 'pct_start': 0.05, 'div_factor': 67.0, 'final_div_factor': 6535.420720140304}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 06:44:52,808] Trial 158 finished with value: 0.4792159338518216 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0015457351608856753, 'weight_decay': 0.00021275248182807638, 'pct_start': 0.05, 'div_factor': 71.0, 'final_div_factor': 4765.223665315717}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 06:57:09,385] Trial 159 finished with value: 0.46934150880573294 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0016234810929234309, 'weight_decay': 0.0005234998245423523, 'pct_start': 0.05, 'div_factor': 69.0, 'final_div_factor': 6524.841870967312}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 07:09:19,990] Trial 160 finished with value: 0.4769028784945505 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 576, 'n_layers': 4, 'learning_rate': 0.0023069044860626908, 'weight_decay': 0.0005051763228538528, 'pct_start': 0.05, 'div_factor': 73.0, 'final_div_factor': 60.45633932734144}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 07:21:35,051] Trial 161 finished with value: 0.46872593803518087 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0016270061997998464, 'weight_decay': 0.00036940605853713393, 'pct_start': 0.05, 'div_factor': 68.0, 'final_div_factor': 6295.375492096433}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 07:33:50,001] Trial 162 finished with value: 0.47270859089255834 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0013823949870248385, 'weight_decay': 0.0002864711516465651, 'pct_start': 0.05, 'div_factor': 69.0, 'final_div_factor': 5415.013655382414}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 07:46:05,278] Trial 163 finished with value: 0.4728450761737221 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0017001041635459164, 'weight_decay': 0.0007077194566242875, 'pct_start': 0.05, 'div_factor': 64.0, 'final_div_factor': 8088.560727698736}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 07:58:22,319] Trial 164 finished with value: 0.5580999826108497 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 576, 'n_layers': 4, 'learning_rate': 0.00016290292327420216, 'weight_decay': 0.000389736977353419, 'pct_start': 0.05, 'div_factor': 77.0, 'final_div_factor': 3759.1851646055898}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 08:10:40,610] Trial 165 finished with value: 0.46771894252505664 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.001881796353438737, 'weight_decay': 0.0006539672782851887, 'pct_start': 0.05, 'div_factor': 71.0, 'final_div_factor': 8528.927254890787}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 08:23:36,724] Trial 166 finished with value: 0.4804232071647254 and parameters: {'batch_size': 512, 'dropout': 0.1, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.00209162058501249, 'weight_decay': 0.0007984049910412703, 'pct_start': 0.15000000000000002, 'div_factor': 70.0, 'final_div_factor': 141.3485212895777}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 08:35:53,823] Trial 167 finished with value: 0.4726844681399382 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0018551263877306947, 'weight_decay': 0.0006062445051933062, 'pct_start': 0.05, 'div_factor': 74.0, 'final_div_factor': 5016.227690746624}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 08:48:11,932] Trial 168 finished with value: 0.469114960247079 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0010389817893428385, 'weight_decay': 0.000533916074151074, 'pct_start': 0.05, 'div_factor': 79.0, 'final_div_factor': 6231.571773270622}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 09:00:27,959] Trial 169 finished with value: 0.4730066615858699 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0010605883186534035, 'weight_decay': 0.0005515610587001059, 'pct_start': 0.05, 'div_factor': 80.0, 'final_div_factor': 6466.336258235017}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 09:12:43,682] Trial 170 finished with value: 0.4766316778854428 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0011472171100875052, 'weight_decay': 0.0004845719473984121, 'pct_start': 0.05, 'div_factor': 76.0, 'final_div_factor': 99.34826561451787}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 09:25:01,252] Trial 171 finished with value: 0.4777947693777608 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.000983874910767221, 'weight_decay': 0.001008536580918341, 'pct_start': 0.05, 'div_factor': 71.0, 'final_div_factor': 4356.077341919209}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 09:37:19,104] Trial 172 finished with value: 0.47425675049708216 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0012500909819697537, 'weight_decay': 0.0005444835396849118, 'pct_start': 0.05, 'div_factor': 79.0, 'final_div_factor': 7360.713881338771}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 09:49:36,296] Trial 173 finished with value: 0.47897224965076085 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0024655462595811572, 'weight_decay': 0.0006364608996191926, 'pct_start': 0.05, 'div_factor': 73.0, 'final_div_factor': 5780.626036673183}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 10:01:55,856] Trial 174 finished with value: 0.4765646195693587 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0019991257928097662, 'weight_decay': 0.00019334616103726756, 'pct_start': 0.05, 'div_factor': 68.0, 'final_div_factor': 9977.238862669585}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 10:14:46,983] Trial 175 finished with value: 0.48050106290402317 and parameters: {'batch_size': 512, 'dropout': 0.25, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0017925471188781014, 'weight_decay': 0.0006458609960473965, 'pct_start': 0.05, 'div_factor': 88.0, 'final_div_factor': 123.1249783371983}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 10:28:37,727] Trial 176 finished with value: 0.47234244081827503 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.002194283246104362, 'weight_decay': 0.00016580981895592418, 'pct_start': 0.05, 'div_factor': 84.0, 'final_div_factor': 3274.355923659921}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 10:42:28,231] Trial 177 finished with value: 0.4711346738732935 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.00143522049460481, 'weight_decay': 0.00022645177184003252, 'pct_start': 0.05, 'div_factor': 65.0, 'final_div_factor': 77.39252948474294}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 10:54:44,947] Trial 178 finished with value: 0.4821882633205762 and parameters: {'batch_size': 512, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0007529590746927326, 'weight_decay': 0.009472046534333606, 'pct_start': 0.05, 'div_factor': 78.0, 'final_div_factor': 28.180547593444906}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 11:08:36,236] Trial 179 finished with value: 0.471824871131317 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.0025745935228616364, 'weight_decay': 0.0002495238702309941, 'pct_start': 0.05, 'div_factor': 75.0, 'final_div_factor': 37.90039783022425}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 11:23:06,390] Trial 180 finished with value: 0.46895306889291594 and parameters: {'batch_size': 448, 'dropout': 0.05, 'input_layer_size': 768, 'n_layers': 4, 'learning_rate': 0.0019356184297058823, 'weight_decay': 0.0005159655579547837, 'pct_start': 0.05, 'div_factor': 62.0, 'final_div_factor': 15.869266177366658}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 11:37:37,254] Trial 181 finished with value: 0.4766971441821295 and parameters: {'batch_size': 448, 'dropout': 0.05, 'input_layer_size': 768, 'n_layers': 4, 'learning_rate': 0.0019277264013594661, 'weight_decay': 0.0004991474658092436, 'pct_start': 0.05, 'div_factor': 61.0, 'final_div_factor': 15.203933468158418}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 11:52:06,047] Trial 182 finished with value: 0.47818710608691867 and parameters: {'batch_size': 448, 'dropout': 0.05, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.0008610507693893002, 'weight_decay': 0.0005855091504663304, 'pct_start': 0.05, 'div_factor': 66.0, 'final_div_factor': 19.16949896835637}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 12:05:52,243] Trial 183 finished with value: 0.4737086022486089 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 704, 'n_layers': 4, 'learning_rate': 0.001692893811428472, 'weight_decay': 0.0007753988864656752, 'pct_start': 0.05, 'div_factor': 63.0, 'final_div_factor': 12.755085664052597}. Best is trial 132 with value: 0.46740088270443064.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Trainer was signaled to stop but the required `min_epochs=20` or `min_steps=None` has not been met. Training will continue...\n",
      "[I 2024-10-06 12:19:39,591] Trial 184 finished with value: 0.4725758218822527 and parameters: {'batch_size': 448, 'dropout': 0.0, 'input_layer_size': 640, 'n_layers': 4, 'learning_rate': 0.002248178643280508, 'weight_decay': 0.0006998149590402936, 'pct_start': 0.05, 'div_factor': 71.0, 'final_div_factor': 7.026603272766902}. Best is trial 132 with value: 0.46740088270443064.\n"
     ]
    }
   ],
   "source": [
    "do_optimize = True\n",
    "timeout = 3600 * 24\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=\"mlp\",\n",
    "    direction='minimize',\n",
    "    storage='sqlite:///mlp.db',\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "if do_optimize:\n",
    "    study.optimize(\n",
    "        objective, \n",
    "        n_trials=1000, \n",
    "        timeout=timeout,\n",
    "        n_jobs=1, \n",
    "        gc_after_trial=True,\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_div_factor</th>\n",
       "      <th>params_dropout</th>\n",
       "      <th>params_final_div_factor</th>\n",
       "      <th>params_input_layer_size</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_n_layers</th>\n",
       "      <th>params_pct_start</th>\n",
       "      <th>params_weight_decay</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>0.467401</td>\n",
       "      <td>2024-10-06 00:28:05.170796</td>\n",
       "      <td>2024-10-06 00:41:54.429892</td>\n",
       "      <td>0 days 00:13:49.259096</td>\n",
       "      <td>448</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.315195</td>\n",
       "      <td>640</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>0.467507</td>\n",
       "      <td>2024-10-05 13:25:45.203470</td>\n",
       "      <td>2024-10-05 13:37:55.895783</td>\n",
       "      <td>0 days 00:12:10.692313</td>\n",
       "      <td>512</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>169.849065</td>\n",
       "      <td>960</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>2024-10-04 17:10:49.296720</td>\n",
       "      <td>2024-10-04 17:24:55.690101</td>\n",
       "      <td>0 days 00:14:06.393381</td>\n",
       "      <td>448</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7063.974394</td>\n",
       "      <td>960</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>0.467671</td>\n",
       "      <td>2024-10-06 01:37:13.567972</td>\n",
       "      <td>2024-10-06 01:51:10.378225</td>\n",
       "      <td>0 days 00:13:56.810253</td>\n",
       "      <td>448</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>198.129505</td>\n",
       "      <td>960</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>165</td>\n",
       "      <td>0.467719</td>\n",
       "      <td>2024-10-06 07:58:22.412565</td>\n",
       "      <td>2024-10-06 08:10:40.605091</td>\n",
       "      <td>0 days 00:12:18.192526</td>\n",
       "      <td>512</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8528.927255</td>\n",
       "      <td>704</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>0.467737</td>\n",
       "      <td>2024-10-05 17:26:54.340015</td>\n",
       "      <td>2024-10-05 17:40:45.682745</td>\n",
       "      <td>0 days 00:13:51.342730</td>\n",
       "      <td>448</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.154774</td>\n",
       "      <td>704</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>0.467899</td>\n",
       "      <td>2024-10-05 15:29:27.891178</td>\n",
       "      <td>2024-10-05 15:43:17.210418</td>\n",
       "      <td>0 days 00:13:49.319240</td>\n",
       "      <td>448</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>117.965493</td>\n",
       "      <td>704</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>161</td>\n",
       "      <td>0.468726</td>\n",
       "      <td>2024-10-06 07:09:20.093379</td>\n",
       "      <td>2024-10-06 07:21:35.045517</td>\n",
       "      <td>0 days 00:12:14.952138</td>\n",
       "      <td>512</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6295.375492</td>\n",
       "      <td>640</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>0.468953</td>\n",
       "      <td>2024-10-06 11:08:36.332027</td>\n",
       "      <td>2024-10-06 11:23:06.385174</td>\n",
       "      <td>0 days 00:14:30.053147</td>\n",
       "      <td>448</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>15.869266</td>\n",
       "      <td>768</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>168</td>\n",
       "      <td>0.469115</td>\n",
       "      <td>2024-10-06 08:35:53.924920</td>\n",
       "      <td>2024-10-06 08:48:11.927130</td>\n",
       "      <td>0 days 00:12:18.002210</td>\n",
       "      <td>512</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6231.571773</td>\n",
       "      <td>640</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>0.469207</td>\n",
       "      <td>2024-10-06 03:26:50.719388</td>\n",
       "      <td>2024-10-06 03:40:47.328081</td>\n",
       "      <td>0 days 00:13:56.608693</td>\n",
       "      <td>448</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>129.683593</td>\n",
       "      <td>960</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>159</td>\n",
       "      <td>0.469342</td>\n",
       "      <td>2024-10-06 06:44:52.903225</td>\n",
       "      <td>2024-10-06 06:57:09.381039</td>\n",
       "      <td>0 days 00:12:16.477814</td>\n",
       "      <td>512</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6524.841871</td>\n",
       "      <td>640</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.469602</td>\n",
       "      <td>2024-10-04 10:32:25.224433</td>\n",
       "      <td>2024-10-04 10:46:40.931869</td>\n",
       "      <td>0 days 00:14:15.707436</td>\n",
       "      <td>448</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4928.928490</td>\n",
       "      <td>960</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>0.469637</td>\n",
       "      <td>2024-10-05 23:47:28.867221</td>\n",
       "      <td>2024-10-06 00:01:18.730941</td>\n",
       "      <td>0 days 00:13:49.863720</td>\n",
       "      <td>448</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>101.207402</td>\n",
       "      <td>704</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>0.469859</td>\n",
       "      <td>2024-10-05 21:10:04.505590</td>\n",
       "      <td>2024-10-05 21:24:29.341317</td>\n",
       "      <td>0 days 00:14:24.835727</td>\n",
       "      <td>448</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100.080066</td>\n",
       "      <td>640</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0.469972</td>\n",
       "      <td>2024-10-05 15:57:03.592246</td>\n",
       "      <td>2024-10-05 16:12:54.558745</td>\n",
       "      <td>0 days 00:15:50.966499</td>\n",
       "      <td>384</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>166.806054</td>\n",
       "      <td>704</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>0.470112</td>\n",
       "      <td>2024-10-05 15:15:40.437350</td>\n",
       "      <td>2024-10-05 15:29:27.794646</td>\n",
       "      <td>0 days 00:13:47.357296</td>\n",
       "      <td>448</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>124.714992</td>\n",
       "      <td>704</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>0.470137</td>\n",
       "      <td>2024-10-06 00:55:48.143836</td>\n",
       "      <td>2024-10-06 01:09:34.762072</td>\n",
       "      <td>0 days 00:13:46.618236</td>\n",
       "      <td>448</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37.001966</td>\n",
       "      <td>640</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.470153</td>\n",
       "      <td>2024-10-04 07:20:45.034355</td>\n",
       "      <td>2024-10-04 07:35:37.988749</td>\n",
       "      <td>0 days 00:14:52.954394</td>\n",
       "      <td>448</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2648.037144</td>\n",
       "      <td>960</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>0.470336</td>\n",
       "      <td>2024-10-04 22:18:42.508693</td>\n",
       "      <td>2024-10-04 22:31:12.496905</td>\n",
       "      <td>0 days 00:12:29.988212</td>\n",
       "      <td>512</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9202.799953</td>\n",
       "      <td>960</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     number     value             datetime_start          datetime_complete  \\\n",
       "132     132  0.467401 2024-10-06 00:28:05.170796 2024-10-06 00:41:54.429892   \n",
       "85       85  0.467507 2024-10-05 13:25:45.203470 2024-10-05 13:37:55.895783   \n",
       "55       55  0.467651 2024-10-04 17:10:49.296720 2024-10-04 17:24:55.690101   \n",
       "137     137  0.467671 2024-10-06 01:37:13.567972 2024-10-06 01:51:10.378225   \n",
       "165     165  0.467719 2024-10-06 07:58:22.412565 2024-10-06 08:10:40.605091   \n",
       "102     102  0.467737 2024-10-05 17:26:54.340015 2024-10-05 17:40:45.682745   \n",
       "94       94  0.467899 2024-10-05 15:29:27.891178 2024-10-05 15:43:17.210418   \n",
       "161     161  0.468726 2024-10-06 07:09:20.093379 2024-10-06 07:21:35.045517   \n",
       "180     180  0.468953 2024-10-06 11:08:36.332027 2024-10-06 11:23:06.385174   \n",
       "168     168  0.469115 2024-10-06 08:35:53.924920 2024-10-06 08:48:11.927130   \n",
       "145     145  0.469207 2024-10-06 03:26:50.719388 2024-10-06 03:40:47.328081   \n",
       "159     159  0.469342 2024-10-06 06:44:52.903225 2024-10-06 06:57:09.381039   \n",
       "33       33  0.469602 2024-10-04 10:32:25.224433 2024-10-04 10:46:40.931869   \n",
       "129     129  0.469637 2024-10-05 23:47:28.867221 2024-10-06 00:01:18.730941   \n",
       "118     118  0.469859 2024-10-05 21:10:04.505590 2024-10-05 21:24:29.341317   \n",
       "96       96  0.469972 2024-10-05 15:57:03.592246 2024-10-05 16:12:54.558745   \n",
       "93       93  0.470112 2024-10-05 15:15:40.437350 2024-10-05 15:29:27.794646   \n",
       "134     134  0.470137 2024-10-06 00:55:48.143836 2024-10-06 01:09:34.762072   \n",
       "22       22  0.470153 2024-10-04 07:20:45.034355 2024-10-04 07:35:37.988749   \n",
       "74       74  0.470336 2024-10-04 22:18:42.508693 2024-10-04 22:31:12.496905   \n",
       "\n",
       "                  duration  params_batch_size  params_div_factor  \\\n",
       "132 0 days 00:13:49.259096                448               74.0   \n",
       "85  0 days 00:12:10.692313                512               50.0   \n",
       "55  0 days 00:14:06.393381                448               48.0   \n",
       "137 0 days 00:13:56.810253                448               69.0   \n",
       "165 0 days 00:12:18.192526                512               71.0   \n",
       "102 0 days 00:13:51.342730                448               83.0   \n",
       "94  0 days 00:13:49.319240                448               68.0   \n",
       "161 0 days 00:12:14.952138                512               68.0   \n",
       "180 0 days 00:14:30.053147                448               62.0   \n",
       "168 0 days 00:12:18.002210                512               79.0   \n",
       "145 0 days 00:13:56.608693                448               79.0   \n",
       "159 0 days 00:12:16.477814                512               69.0   \n",
       "33  0 days 00:14:15.707436                448               60.0   \n",
       "129 0 days 00:13:49.863720                448               80.0   \n",
       "118 0 days 00:14:24.835727                448               44.0   \n",
       "96  0 days 00:15:50.966499                384               75.0   \n",
       "93  0 days 00:13:47.357296                448               63.0   \n",
       "134 0 days 00:13:46.618236                448               73.0   \n",
       "22  0 days 00:14:52.954394                448               64.0   \n",
       "74  0 days 00:12:29.988212                512               51.0   \n",
       "\n",
       "     params_dropout  params_final_div_factor  params_input_layer_size  \\\n",
       "132            0.00                39.315195                      640   \n",
       "85             0.00               169.849065                      960   \n",
       "55             0.00              7063.974394                      960   \n",
       "137            0.00               198.129505                      960   \n",
       "165            0.00              8528.927255                      704   \n",
       "102            0.00               100.154774                      704   \n",
       "94             0.00               117.965493                      704   \n",
       "161            0.00              6295.375492                      640   \n",
       "180            0.05                15.869266                      768   \n",
       "168            0.00              6231.571773                      640   \n",
       "145            0.00               129.683593                      960   \n",
       "159            0.00              6524.841871                      640   \n",
       "33             0.00              4928.928490                      960   \n",
       "129            0.00               101.207402                      704   \n",
       "118            0.05               100.080066                      640   \n",
       "96             0.00               166.806054                      704   \n",
       "93             0.00               124.714992                      704   \n",
       "134            0.00                37.001966                      640   \n",
       "22             0.10              2648.037144                      960   \n",
       "74             0.00              9202.799953                      960   \n",
       "\n",
       "     params_learning_rate  params_n_layers  params_pct_start  \\\n",
       "132              0.001790                4              0.05   \n",
       "85               0.002472                4              0.05   \n",
       "55               0.001225                4              0.05   \n",
       "137              0.002222                4              0.05   \n",
       "165              0.001882                4              0.05   \n",
       "102              0.005849                4              0.05   \n",
       "94               0.001955                4              0.05   \n",
       "161              0.001627                4              0.05   \n",
       "180              0.001936                4              0.05   \n",
       "168              0.001039                4              0.05   \n",
       "145              0.001536                4              0.05   \n",
       "159              0.001623                4              0.05   \n",
       "33               0.001084                4              0.05   \n",
       "129              0.002547                4              0.05   \n",
       "118              0.002206                4              0.05   \n",
       "96               0.002010                4              0.05   \n",
       "93               0.001952                4              0.05   \n",
       "134              0.001966                4              0.05   \n",
       "22               0.002214                4              0.05   \n",
       "74               0.001632                4              0.05   \n",
       "\n",
       "     params_weight_decay     state  \n",
       "132             0.000334  COMPLETE  \n",
       "85              0.000192  COMPLETE  \n",
       "55              0.000560  COMPLETE  \n",
       "137             0.000268  COMPLETE  \n",
       "165             0.000654  COMPLETE  \n",
       "102             0.000112  COMPLETE  \n",
       "94              0.000161  COMPLETE  \n",
       "161             0.000369  COMPLETE  \n",
       "180             0.000516  COMPLETE  \n",
       "168             0.000534  COMPLETE  \n",
       "145             0.000335  COMPLETE  \n",
       "159             0.000523  COMPLETE  \n",
       "33              0.000378  COMPLETE  \n",
       "129             0.000301  COMPLETE  \n",
       "118             0.000185  COMPLETE  \n",
       "96              0.000102  COMPLETE  \n",
       "93              0.000173  COMPLETE  \n",
       "134             0.000284  COMPLETE  \n",
       "22              0.000221  COMPLETE  \n",
       "74              0.000429  COMPLETE  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe().sort_values(\"value\", ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184
         ],
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.48582076595330836,
          0.49587634066649217,
          0.5560792513104827,
          0.49097770875755825,
          0.5471641810764196,
          0.4710884659460451,
          0.5192872211135511,
          0.4720872759986644,
          0.4780043560672921,
          0.4783535459108627,
          0.488548144677984,
          0.4749128374145374,
          0.487769105549433,
          0.47458700663798725,
          0.47753635333064803,
          0.47975956101430856,
          0.47947758102598936,
          0.49103530289164443,
          0.4789503351840474,
          0.4701534300838065,
          0.4804629293430363,
          0.4752618935408578,
          0.474945696293687,
          0.481977635714154,
          0.4863866662540127,
          0.48186299640489916,
          0.4922695804451491,
          0.508653296464621,
          0.4794973851669492,
          0.4737243393326588,
          0.46960232107520977,
          0.47120738116290567,
          0.4814090757681261,
          0.4757593588922349,
          0.47896822428703595,
          0.4788739237015786,
          0.4853290016196741,
          0.48325651304304423,
          0.4899098494396619,
          0.476696629183824,
          0.4765966158354703,
          0.4748064759492319,
          0.48392333305005486,
          0.47938930652759854,
          0.4745539856098385,
          0.48092740797674294,
          0.4753333800279938,
          0.5060278962560338,
          0.47373214689969584,
          0.47244882948448763,
          0.47652775516288504,
          0.47999415219853664,
          0.46765089132423154,
          0.4750165791239908,
          0.4879987234342427,
          0.5157825625317525,
          0.48817027384220946,
          0.47435968325415523,
          0.4728887151357227,
          0.47056914603092376,
          0.4739508108943912,
          0.47426974341841915,
          0.4728146041285085,
          0.4931526315687284,
          0.48179250246934996,
          0.47499075944337904,
          0.4792153890867136,
          0.4752772806530471,
          0.47720184036313684,
          0.49111532730738194,
          0.4749740798152371,
          0.4703356771093289,
          0.47245721636041516,
          0.4792768420228019,
          0.47744524798157534,
          0.47992130553746615,
          0.47413360385770825,
          0.4891283724311615,
          0.47146206060207463,
          0.4725066716247543,
          0.47421981432720495,
          0.47509827674326494,
          0.467506767790427,
          0.48101392759986794,
          0.476056847897639,
          0.4864916518815289,
          0.4764027842181404,
          0.4710527345378048,
          0.47533313375982755,
          0.476651268681432,
          0.47011212845426753,
          0.4678993784002907,
          0.47614993484406687,
          0.4699721327650116,
          0.47817908620643507,
          0.47195365450561433,
          0.47098801612099744,
          0.47361158599473674,
          0.4734281162019044,
          0.46773682273024947,
          0.47442986625995054,
          0.47992965659307973,
          0.4803537810227622,
          0.47782849991800813,
          0.4755833048830165,
          0.47442427700593404,
          0.47152652209703544,
          0.47418346018185636,
          0.47059656434887476,
          0.4726290772044729,
          0.4765326919998197,
          0.47697419245679706,
          0.47808491617680593,
          0.4733793731938419,
          0.4726823801968501,
          0.4698592048259145,
          0.47211085906567885,
          0.47244852982364655,
          0.47838932217908525,
          0.48037627474070604,
          0.47918118849053537,
          0.4741612926631936,
          0.4728438033902339,
          0.47374695314225157,
          0.4717925652091289,
          0.4802410386796166,
          0.4696368344828613,
          0.4757084202950518,
          0.47374940389009607,
          0.46740088270443064,
          0.47205506449530016,
          0.4701365183923391,
          0.47411675921598045,
          0.47143572671749556,
          0.46767101671620426,
          0.4773971007552863,
          0.47186851126008583,
          0.4726959032666368,
          0.480404100490545,
          0.4725809782928513,
          0.47610778828381245,
          0.4725246665125689,
          0.46920679239328467,
          0.4747861185140221,
          0.47425826551568157,
          0.4801263660247838,
          0.4754080991120146,
          0.4727588315492456,
          0.476782389620511,
          0.4745475629573795,
          0.4744544017281635,
          0.4733290955868358,
          0.4736699109515882,
          0.47054529547851914,
          0.47366229101686796,
          0.4792159338518216,
          0.46934150880573294,
          0.4769028784945505,
          0.46872593803518087,
          0.47270859089255834,
          0.4728450761737221,
          0.5580999826108497,
          0.46771894252505664,
          0.4804232071647254,
          0.4726844681399382,
          0.469114960247079,
          0.4730066615858699,
          0.4766316778854428,
          0.4777947693777608,
          0.47425675049708216,
          0.47897224965076085,
          0.4765646195693587,
          0.48050106290402317,
          0.47234244081827503,
          0.4711346738732935,
          0.4821882633205762,
          0.471824871131317,
          0.46895306889291594,
          0.4766971441821295,
          0.47818710608691867,
          0.4737086022486089,
          0.4725758218822527
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184
         ],
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.4813471719885105,
          0.4813471719885105,
          0.4813471719885105,
          0.4813471719885105,
          0.4813471719885105,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4710884659460451,
          0.4701534300838065,
          0.4701534300838065,
          0.4701534300838065,
          0.4701534300838065,
          0.4701534300838065,
          0.4701534300838065,
          0.4701534300838065,
          0.4701534300838065,
          0.4701534300838065,
          0.4701534300838065,
          0.4701534300838065,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46960232107520977,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.46765089132423154,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.467506767790427,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064,
          0.46740088270443064
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "cliponaxis": false,
         "hovertemplate": [
          "final_div_factor (FloatDistribution): 0.0034220470454144223<extra></extra>",
          "batch_size (IntDistribution): 0.004395123249752621<extra></extra>",
          "pct_start (FloatDistribution): 0.008249115461468386<extra></extra>",
          "n_layers (IntDistribution): 0.01732327690244944<extra></extra>",
          "input_layer_size (IntDistribution): 0.02475700971152129<extra></extra>",
          "div_factor (FloatDistribution): 0.04710133569636168<extra></extra>",
          "dropout (FloatDistribution): 0.09154121339157431<extra></extra>",
          "weight_decay (FloatDistribution): 0.15236747511792326<extra></extra>",
          "learning_rate (FloatDistribution): 0.6508434034235345<extra></extra>"
         ],
         "name": "Objective Value",
         "orientation": "h",
         "text": [
          "<0.01",
          "<0.01",
          "<0.01",
          "0.02",
          "0.02",
          "0.05",
          "0.09",
          "0.15",
          "0.65"
         ],
         "textposition": "outside",
         "type": "bar",
         "x": [
          0.0034220470454144223,
          0.004395123249752621,
          0.008249115461468386,
          0.01732327690244944,
          0.02475700971152129,
          0.04710133569636168,
          0.09154121339157431,
          0.15236747511792326,
          0.6508434034235345
         ],
         "y": [
          "final_div_factor",
          "batch_size",
          "pct_start",
          "n_layers",
          "input_layer_size",
          "div_factor",
          "dropout",
          "weight_decay",
          "learning_rate"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hyperparameter Importances"
        },
        "xaxis": {
         "title": {
          "text": "Hyperparameter Importance"
         }
        },
        "yaxis": {
         "title": {
          "text": "Hyperparameter"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": true
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          448,
          320,
          384,
          128,
          128,
          384,
          512,
          256,
          320,
          320,
          192,
          192,
          256,
          192,
          256,
          192,
          384,
          512,
          320,
          128,
          448,
          384,
          448,
          448,
          320,
          256,
          448,
          192,
          512,
          384,
          320,
          384,
          448,
          448,
          512,
          512,
          448,
          512,
          448,
          512,
          384,
          448,
          128,
          512,
          512,
          256,
          448,
          384,
          320,
          192,
          512,
          448,
          448,
          384,
          128,
          448,
          256,
          384,
          320,
          192,
          448,
          448,
          448,
          512,
          384,
          448,
          512,
          448,
          384,
          256,
          320,
          448,
          448,
          448,
          512,
          512,
          512,
          512,
          512,
          512,
          448,
          448,
          448,
          384,
          448,
          512,
          512,
          512,
          512,
          320,
          448,
          448,
          448,
          448,
          448,
          448,
          384,
          384,
          448,
          448,
          384,
          448,
          448,
          448,
          448,
          384,
          448,
          448,
          448,
          384,
          448,
          448,
          448,
          448,
          512,
          448,
          448,
          512,
          448,
          384,
          448,
          448,
          448,
          448,
          448,
          512,
          384,
          448,
          448,
          448,
          512,
          448,
          448,
          448,
          448,
          448,
          448,
          448,
          512,
          448,
          448,
          448,
          448,
          448,
          448,
          448,
          384,
          448,
          448,
          512,
          384,
          448,
          448,
          448,
          448,
          448,
          448,
          448,
          448,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          512,
          448,
          448,
          512,
          448,
          448,
          448,
          448,
          448,
          448
         ],
         "xaxis": "x",
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.48582076595330836,
          0.49587634066649217,
          0.5560792513104827,
          0.49097770875755825,
          0.5471641810764196,
          0.4710884659460451,
          0.5192872211135511,
          0.4720872759986644,
          0.4780043560672921,
          0.4783535459108627,
          0.488548144677984,
          0.4749128374145374,
          0.487769105549433,
          0.47458700663798725,
          0.47753635333064803,
          0.47975956101430856,
          0.47947758102598936,
          0.49103530289164443,
          0.4789503351840474,
          0.4701534300838065,
          0.4804629293430363,
          0.4752618935408578,
          0.474945696293687,
          0.481977635714154,
          0.4863866662540127,
          0.48186299640489916,
          0.4922695804451491,
          0.508653296464621,
          0.4794973851669492,
          0.4737243393326588,
          0.46960232107520977,
          0.47120738116290567,
          0.4814090757681261,
          0.4757593588922349,
          0.47896822428703595,
          0.4788739237015786,
          0.4853290016196741,
          0.48325651304304423,
          0.4899098494396619,
          0.476696629183824,
          0.4765966158354703,
          0.4748064759492319,
          0.48392333305005486,
          0.47938930652759854,
          0.4745539856098385,
          0.48092740797674294,
          0.4753333800279938,
          0.5060278962560338,
          0.47373214689969584,
          0.47244882948448763,
          0.47652775516288504,
          0.47999415219853664,
          0.46765089132423154,
          0.4750165791239908,
          0.4879987234342427,
          0.5157825625317525,
          0.48817027384220946,
          0.47435968325415523,
          0.4728887151357227,
          0.47056914603092376,
          0.4739508108943912,
          0.47426974341841915,
          0.4728146041285085,
          0.4931526315687284,
          0.48179250246934996,
          0.47499075944337904,
          0.4792153890867136,
          0.4752772806530471,
          0.47720184036313684,
          0.49111532730738194,
          0.4749740798152371,
          0.4703356771093289,
          0.47245721636041516,
          0.4792768420228019,
          0.47744524798157534,
          0.47992130553746615,
          0.47413360385770825,
          0.4891283724311615,
          0.47146206060207463,
          0.4725066716247543,
          0.47421981432720495,
          0.47509827674326494,
          0.467506767790427,
          0.48101392759986794,
          0.476056847897639,
          0.4864916518815289,
          0.4764027842181404,
          0.4710527345378048,
          0.47533313375982755,
          0.476651268681432,
          0.47011212845426753,
          0.4678993784002907,
          0.47614993484406687,
          0.4699721327650116,
          0.47817908620643507,
          0.47195365450561433,
          0.47098801612099744,
          0.47361158599473674,
          0.4734281162019044,
          0.46773682273024947,
          0.47442986625995054,
          0.47992965659307973,
          0.4803537810227622,
          0.47782849991800813,
          0.4755833048830165,
          0.47442427700593404,
          0.47152652209703544,
          0.47418346018185636,
          0.47059656434887476,
          0.4726290772044729,
          0.4765326919998197,
          0.47697419245679706,
          0.47808491617680593,
          0.4733793731938419,
          0.4726823801968501,
          0.4698592048259145,
          0.47211085906567885,
          0.47244852982364655,
          0.47838932217908525,
          0.48037627474070604,
          0.47918118849053537,
          0.4741612926631936,
          0.4728438033902339,
          0.47374695314225157,
          0.4717925652091289,
          0.4802410386796166,
          0.4696368344828613,
          0.4757084202950518,
          0.47374940389009607,
          0.46740088270443064,
          0.47205506449530016,
          0.4701365183923391,
          0.47411675921598045,
          0.47143572671749556,
          0.46767101671620426,
          0.4773971007552863,
          0.47186851126008583,
          0.4726959032666368,
          0.480404100490545,
          0.4725809782928513,
          0.47610778828381245,
          0.4725246665125689,
          0.46920679239328467,
          0.4747861185140221,
          0.47425826551568157,
          0.4801263660247838,
          0.4754080991120146,
          0.4727588315492456,
          0.476782389620511,
          0.4745475629573795,
          0.4744544017281635,
          0.4733290955868358,
          0.4736699109515882,
          0.47054529547851914,
          0.47366229101686796,
          0.4792159338518216,
          0.46934150880573294,
          0.4769028784945505,
          0.46872593803518087,
          0.47270859089255834,
          0.4728450761737221,
          0.5580999826108497,
          0.46771894252505664,
          0.4804232071647254,
          0.4726844681399382,
          0.469114960247079,
          0.4730066615858699,
          0.4766316778854428,
          0.4777947693777608,
          0.47425675049708216,
          0.47897224965076085,
          0.4765646195693587,
          0.48050106290402317,
          0.47234244081827503,
          0.4711346738732935,
          0.4821882633205762,
          0.471824871131317,
          0.46895306889291594,
          0.4766971441821295,
          0.47818710608691867,
          0.4737086022486089,
          0.4725758218822527
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          47,
          8,
          36,
          13,
          96,
          67,
          38,
          80,
          16,
          68,
          20,
          23,
          2,
          25,
          27,
          17,
          53,
          36,
          1,
          51,
          17,
          56,
          64,
          65,
          78,
          43,
          28,
          75,
          89,
          61,
          44,
          51,
          58,
          60,
          12,
          8,
          73,
          11,
          32,
          45,
          89,
          18,
          20,
          7,
          11,
          63,
          31,
          70,
          39,
          22,
          6,
          57,
          58,
          14,
          69,
          48,
          85,
          100,
          3,
          40,
          25,
          63,
          52,
          48,
          14,
          53,
          48,
          54,
          61,
          33,
          72,
          66,
          59,
          55,
          51,
          42,
          50,
          36,
          11,
          46,
          78,
          59,
          63,
          60,
          16,
          50,
          52,
          49,
          57,
          42,
          55,
          65,
          55,
          63,
          68,
          70,
          75,
          75,
          67,
          82,
          84,
          78,
          83,
          85,
          82,
          90,
          73,
          81,
          64,
          77,
          87,
          51,
          51,
          93,
          46,
          68,
          53,
          62,
          44,
          43,
          48,
          75,
          45,
          71,
          50,
          41,
          37,
          57,
          47,
          80,
          65,
          82,
          74,
          75,
          73,
          72,
          80,
          69,
          77,
          69,
          67,
          74,
          61,
          71,
          66,
          79,
          79,
          76,
          69,
          73,
          80,
          83,
          63,
          44,
          59,
          86,
          67,
          67,
          71,
          69,
          73,
          68,
          69,
          64,
          77,
          71,
          70,
          74,
          79,
          80,
          76,
          71,
          79,
          73,
          68,
          88,
          84,
          65,
          78,
          75,
          62,
          61,
          66,
          63,
          71
         ],
         "xaxis": "x2",
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.48582076595330836,
          0.49587634066649217,
          0.5560792513104827,
          0.49097770875755825,
          0.5471641810764196,
          0.4710884659460451,
          0.5192872211135511,
          0.4720872759986644,
          0.4780043560672921,
          0.4783535459108627,
          0.488548144677984,
          0.4749128374145374,
          0.487769105549433,
          0.47458700663798725,
          0.47753635333064803,
          0.47975956101430856,
          0.47947758102598936,
          0.49103530289164443,
          0.4789503351840474,
          0.4701534300838065,
          0.4804629293430363,
          0.4752618935408578,
          0.474945696293687,
          0.481977635714154,
          0.4863866662540127,
          0.48186299640489916,
          0.4922695804451491,
          0.508653296464621,
          0.4794973851669492,
          0.4737243393326588,
          0.46960232107520977,
          0.47120738116290567,
          0.4814090757681261,
          0.4757593588922349,
          0.47896822428703595,
          0.4788739237015786,
          0.4853290016196741,
          0.48325651304304423,
          0.4899098494396619,
          0.476696629183824,
          0.4765966158354703,
          0.4748064759492319,
          0.48392333305005486,
          0.47938930652759854,
          0.4745539856098385,
          0.48092740797674294,
          0.4753333800279938,
          0.5060278962560338,
          0.47373214689969584,
          0.47244882948448763,
          0.47652775516288504,
          0.47999415219853664,
          0.46765089132423154,
          0.4750165791239908,
          0.4879987234342427,
          0.5157825625317525,
          0.48817027384220946,
          0.47435968325415523,
          0.4728887151357227,
          0.47056914603092376,
          0.4739508108943912,
          0.47426974341841915,
          0.4728146041285085,
          0.4931526315687284,
          0.48179250246934996,
          0.47499075944337904,
          0.4792153890867136,
          0.4752772806530471,
          0.47720184036313684,
          0.49111532730738194,
          0.4749740798152371,
          0.4703356771093289,
          0.47245721636041516,
          0.4792768420228019,
          0.47744524798157534,
          0.47992130553746615,
          0.47413360385770825,
          0.4891283724311615,
          0.47146206060207463,
          0.4725066716247543,
          0.47421981432720495,
          0.47509827674326494,
          0.467506767790427,
          0.48101392759986794,
          0.476056847897639,
          0.4864916518815289,
          0.4764027842181404,
          0.4710527345378048,
          0.47533313375982755,
          0.476651268681432,
          0.47011212845426753,
          0.4678993784002907,
          0.47614993484406687,
          0.4699721327650116,
          0.47817908620643507,
          0.47195365450561433,
          0.47098801612099744,
          0.47361158599473674,
          0.4734281162019044,
          0.46773682273024947,
          0.47442986625995054,
          0.47992965659307973,
          0.4803537810227622,
          0.47782849991800813,
          0.4755833048830165,
          0.47442427700593404,
          0.47152652209703544,
          0.47418346018185636,
          0.47059656434887476,
          0.4726290772044729,
          0.4765326919998197,
          0.47697419245679706,
          0.47808491617680593,
          0.4733793731938419,
          0.4726823801968501,
          0.4698592048259145,
          0.47211085906567885,
          0.47244852982364655,
          0.47838932217908525,
          0.48037627474070604,
          0.47918118849053537,
          0.4741612926631936,
          0.4728438033902339,
          0.47374695314225157,
          0.4717925652091289,
          0.4802410386796166,
          0.4696368344828613,
          0.4757084202950518,
          0.47374940389009607,
          0.46740088270443064,
          0.47205506449530016,
          0.4701365183923391,
          0.47411675921598045,
          0.47143572671749556,
          0.46767101671620426,
          0.4773971007552863,
          0.47186851126008583,
          0.4726959032666368,
          0.480404100490545,
          0.4725809782928513,
          0.47610778828381245,
          0.4725246665125689,
          0.46920679239328467,
          0.4747861185140221,
          0.47425826551568157,
          0.4801263660247838,
          0.4754080991120146,
          0.4727588315492456,
          0.476782389620511,
          0.4745475629573795,
          0.4744544017281635,
          0.4733290955868358,
          0.4736699109515882,
          0.47054529547851914,
          0.47366229101686796,
          0.4792159338518216,
          0.46934150880573294,
          0.4769028784945505,
          0.46872593803518087,
          0.47270859089255834,
          0.4728450761737221,
          0.5580999826108497,
          0.46771894252505664,
          0.4804232071647254,
          0.4726844681399382,
          0.469114960247079,
          0.4730066615858699,
          0.4766316778854428,
          0.4777947693777608,
          0.47425675049708216,
          0.47897224965076085,
          0.4765646195693587,
          0.48050106290402317,
          0.47234244081827503,
          0.4711346738732935,
          0.4821882633205762,
          0.471824871131317,
          0.46895306889291594,
          0.4766971441821295,
          0.47818710608691867,
          0.4737086022486089,
          0.4725758218822527
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.3,
          0.05,
          0.2,
          0.1,
          0.3,
          0,
          0.25,
          0.3,
          0.1,
          0.3,
          0.15000000000000002,
          0.15000000000000002,
          0.15000000000000002,
          0.1,
          0.1,
          0.2,
          0.05,
          0.2,
          0.05,
          0,
          0.15000000000000002,
          0.05,
          0.1,
          0.1,
          0.1,
          0.15000000000000002,
          0.2,
          0.1,
          0.15000000000000002,
          0.25,
          0.05,
          0.05,
          0,
          0,
          0,
          0,
          0,
          0.05,
          0.05,
          0,
          0,
          0.1,
          0.1,
          0.2,
          0.15000000000000002,
          0.1,
          0.15000000000000002,
          0.25,
          0.05,
          0,
          0.1,
          0,
          0,
          0,
          0.05,
          0,
          0.05,
          0.2,
          0.15000000000000002,
          0,
          0.1,
          0,
          0,
          0.05,
          0,
          0,
          0.15000000000000002,
          0.05,
          0,
          0.05,
          0.3,
          0,
          0,
          0,
          0,
          0,
          0.1,
          0.05,
          0.15000000000000002,
          0,
          0.05,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.05,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.05,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.05,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.05,
          0.05,
          0.05,
          0,
          0,
          0.05,
          0,
          0,
          0,
          0,
          0,
          0,
          0.05,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.1,
          0.05,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.25,
          0,
          0,
          0,
          0,
          0.05,
          0.05,
          0.05,
          0,
          0
         ],
         "xaxis": "x3",
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.48582076595330836,
          0.49587634066649217,
          0.5560792513104827,
          0.49097770875755825,
          0.5471641810764196,
          0.4710884659460451,
          0.5192872211135511,
          0.4720872759986644,
          0.4780043560672921,
          0.4783535459108627,
          0.488548144677984,
          0.4749128374145374,
          0.487769105549433,
          0.47458700663798725,
          0.47753635333064803,
          0.47975956101430856,
          0.47947758102598936,
          0.49103530289164443,
          0.4789503351840474,
          0.4701534300838065,
          0.4804629293430363,
          0.4752618935408578,
          0.474945696293687,
          0.481977635714154,
          0.4863866662540127,
          0.48186299640489916,
          0.4922695804451491,
          0.508653296464621,
          0.4794973851669492,
          0.4737243393326588,
          0.46960232107520977,
          0.47120738116290567,
          0.4814090757681261,
          0.4757593588922349,
          0.47896822428703595,
          0.4788739237015786,
          0.4853290016196741,
          0.48325651304304423,
          0.4899098494396619,
          0.476696629183824,
          0.4765966158354703,
          0.4748064759492319,
          0.48392333305005486,
          0.47938930652759854,
          0.4745539856098385,
          0.48092740797674294,
          0.4753333800279938,
          0.5060278962560338,
          0.47373214689969584,
          0.47244882948448763,
          0.47652775516288504,
          0.47999415219853664,
          0.46765089132423154,
          0.4750165791239908,
          0.4879987234342427,
          0.5157825625317525,
          0.48817027384220946,
          0.47435968325415523,
          0.4728887151357227,
          0.47056914603092376,
          0.4739508108943912,
          0.47426974341841915,
          0.4728146041285085,
          0.4931526315687284,
          0.48179250246934996,
          0.47499075944337904,
          0.4792153890867136,
          0.4752772806530471,
          0.47720184036313684,
          0.49111532730738194,
          0.4749740798152371,
          0.4703356771093289,
          0.47245721636041516,
          0.4792768420228019,
          0.47744524798157534,
          0.47992130553746615,
          0.47413360385770825,
          0.4891283724311615,
          0.47146206060207463,
          0.4725066716247543,
          0.47421981432720495,
          0.47509827674326494,
          0.467506767790427,
          0.48101392759986794,
          0.476056847897639,
          0.4864916518815289,
          0.4764027842181404,
          0.4710527345378048,
          0.47533313375982755,
          0.476651268681432,
          0.47011212845426753,
          0.4678993784002907,
          0.47614993484406687,
          0.4699721327650116,
          0.47817908620643507,
          0.47195365450561433,
          0.47098801612099744,
          0.47361158599473674,
          0.4734281162019044,
          0.46773682273024947,
          0.47442986625995054,
          0.47992965659307973,
          0.4803537810227622,
          0.47782849991800813,
          0.4755833048830165,
          0.47442427700593404,
          0.47152652209703544,
          0.47418346018185636,
          0.47059656434887476,
          0.4726290772044729,
          0.4765326919998197,
          0.47697419245679706,
          0.47808491617680593,
          0.4733793731938419,
          0.4726823801968501,
          0.4698592048259145,
          0.47211085906567885,
          0.47244852982364655,
          0.47838932217908525,
          0.48037627474070604,
          0.47918118849053537,
          0.4741612926631936,
          0.4728438033902339,
          0.47374695314225157,
          0.4717925652091289,
          0.4802410386796166,
          0.4696368344828613,
          0.4757084202950518,
          0.47374940389009607,
          0.46740088270443064,
          0.47205506449530016,
          0.4701365183923391,
          0.47411675921598045,
          0.47143572671749556,
          0.46767101671620426,
          0.4773971007552863,
          0.47186851126008583,
          0.4726959032666368,
          0.480404100490545,
          0.4725809782928513,
          0.47610778828381245,
          0.4725246665125689,
          0.46920679239328467,
          0.4747861185140221,
          0.47425826551568157,
          0.4801263660247838,
          0.4754080991120146,
          0.4727588315492456,
          0.476782389620511,
          0.4745475629573795,
          0.4744544017281635,
          0.4733290955868358,
          0.4736699109515882,
          0.47054529547851914,
          0.47366229101686796,
          0.4792159338518216,
          0.46934150880573294,
          0.4769028784945505,
          0.46872593803518087,
          0.47270859089255834,
          0.4728450761737221,
          0.5580999826108497,
          0.46771894252505664,
          0.4804232071647254,
          0.4726844681399382,
          0.469114960247079,
          0.4730066615858699,
          0.4766316778854428,
          0.4777947693777608,
          0.47425675049708216,
          0.47897224965076085,
          0.4765646195693587,
          0.48050106290402317,
          0.47234244081827503,
          0.4711346738732935,
          0.4821882633205762,
          0.471824871131317,
          0.46895306889291594,
          0.4766971441821295,
          0.47818710608691867,
          0.4737086022486089,
          0.4725758218822527
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          152.9293389975958,
          3178.606104172227,
          273.77316467840114,
          11.579361003902376,
          9.963493952574607,
          323.78260720353535,
          2.4571568567171074,
          1370.8979091492308,
          464.6568529595805,
          51.07617565207476,
          6474.425324295503,
          9206.180393630231,
          1173.5249619682854,
          4282.81019331996,
          830.8236730202907,
          42.85120208073097,
          8418.086311084093,
          627.8417139358914,
          3149.93640307578,
          1.030811001697049,
          55.495659412931396,
          7141.514832868491,
          2648.037143906544,
          1724.7573078198764,
          491.5135374480021,
          1977.4683176929118,
          141.8352210767818,
          4273.367414151046,
          331.4782137731802,
          2315.757330175246,
          738.9455344960226,
          9788.321865833266,
          5000.383664265422,
          4928.928490253396,
          2616.3196483543643,
          2802.9550959961957,
          223.13347051513557,
          1066.6528973405404,
          1746.2865528404973,
          462.27866963256474,
          13.931719866341203,
          4448.934703012777,
          5868.9286241695445,
          2763.332849952728,
          1097.8989865464162,
          3558.4479610837634,
          5904.151407123139,
          90.10817018120717,
          1516.084078588227,
          2479.517918125988,
          6756.921344615096,
          4971.752698008143,
          9761.910416591032,
          9738.5124801978,
          3528.3664861666443,
          7063.974394096631,
          978.5061265111428,
          1474.1067444430428,
          3519.725986699553,
          6655.343209609583,
          25.659347658793727,
          7157.885691747439,
          2087.007160872736,
          2463.0192394852734,
          1933.006340343667,
          4084.5473770644016,
          488.60607394361256,
          804.0995365594688,
          1312.7826196579429,
          269.9127942688276,
          2041.625947685551,
          8111.756503846018,
          5267.528323100736,
          3240.233626707255,
          9202.799953303887,
          3.515724359132952,
          4456.739447695535,
          7695.318625009765,
          2860.947814192304,
          5661.063871889712,
          578.3298906606126,
          9890.35577806349,
          7180.778667353889,
          4025.7501923145373,
          5605.051643784766,
          169.8490646338428,
          185.77153317791382,
          80.73418443533755,
          404.65019465356903,
          8699.959785231998,
          134.2824958159751,
          126.93897833303627,
          61.103795953635135,
          124.71499218858786,
          117.96549330827749,
          111.51138887595032,
          166.80605383010212,
          145.18309416764177,
          209.02911070298367,
          64.12015163151655,
          69.04903108816522,
          33.058536747584064,
          100.15477371068445,
          43.970369285685464,
          167.86346224550027,
          83.51825613102835,
          116.9405239402451,
          260.3860686876697,
          97.03367828129187,
          327.3017302435278,
          67.12404842911144,
          47.26600606846899,
          15.817979218812525,
          53.92216880614223,
          30.627509739396043,
          45.120645183726126,
          21.39726322111083,
          72.86186552739736,
          100.08006602350139,
          5.466394474656609,
          227.22274146402242,
          157.48702447608616,
          92.08738055984361,
          34.07163844200518,
          107.00125566825993,
          55.232000996049564,
          175.73065336464336,
          81.51227079613224,
          1.1364212056994833,
          101.20740205177643,
          134.35640088083352,
          115.77045262866183,
          39.31519465021811,
          47.68712902949748,
          37.00196636478465,
          9.297137355017743,
          22.625806997939893,
          198.1295051574072,
          204.17466115092523,
          379.37647186333857,
          35.88684598243863,
          155.19559664910116,
          255.75558238717986,
          98.91240690610786,
          184.08810580313218,
          129.6835928990538,
          128.834329160655,
          102.76672649015565,
          78.0559838241223,
          148.3861015882646,
          216.33086907606665,
          116.12526237150085,
          88.47140519306649,
          7936.959152192446,
          309.66423026087256,
          175.0062433120965,
          6422.083773921282,
          6535.420720140304,
          4765.223665315717,
          6524.841870967312,
          60.45633932734144,
          6295.375492096433,
          5415.013655382414,
          8088.560727698736,
          3759.1851646055898,
          8528.927254890787,
          141.3485212895777,
          5016.227690746624,
          6231.571773270622,
          6466.336258235017,
          99.34826561451787,
          4356.077341919209,
          7360.713881338771,
          5780.626036673183,
          9977.238862669585,
          123.1249783371983,
          3274.355923659921,
          77.39252948474294,
          28.180547593444906,
          37.90039783022425,
          15.869266177366658,
          15.203933468158418,
          19.16949896835637,
          12.755085664052597,
          7.026603272766902
         ],
         "xaxis": "x4",
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.48582076595330836,
          0.49587634066649217,
          0.5560792513104827,
          0.49097770875755825,
          0.5471641810764196,
          0.4710884659460451,
          0.5192872211135511,
          0.4720872759986644,
          0.4780043560672921,
          0.4783535459108627,
          0.488548144677984,
          0.4749128374145374,
          0.487769105549433,
          0.47458700663798725,
          0.47753635333064803,
          0.47975956101430856,
          0.47947758102598936,
          0.49103530289164443,
          0.4789503351840474,
          0.4701534300838065,
          0.4804629293430363,
          0.4752618935408578,
          0.474945696293687,
          0.481977635714154,
          0.4863866662540127,
          0.48186299640489916,
          0.4922695804451491,
          0.508653296464621,
          0.4794973851669492,
          0.4737243393326588,
          0.46960232107520977,
          0.47120738116290567,
          0.4814090757681261,
          0.4757593588922349,
          0.47896822428703595,
          0.4788739237015786,
          0.4853290016196741,
          0.48325651304304423,
          0.4899098494396619,
          0.476696629183824,
          0.4765966158354703,
          0.4748064759492319,
          0.48392333305005486,
          0.47938930652759854,
          0.4745539856098385,
          0.48092740797674294,
          0.4753333800279938,
          0.5060278962560338,
          0.47373214689969584,
          0.47244882948448763,
          0.47652775516288504,
          0.47999415219853664,
          0.46765089132423154,
          0.4750165791239908,
          0.4879987234342427,
          0.5157825625317525,
          0.48817027384220946,
          0.47435968325415523,
          0.4728887151357227,
          0.47056914603092376,
          0.4739508108943912,
          0.47426974341841915,
          0.4728146041285085,
          0.4931526315687284,
          0.48179250246934996,
          0.47499075944337904,
          0.4792153890867136,
          0.4752772806530471,
          0.47720184036313684,
          0.49111532730738194,
          0.4749740798152371,
          0.4703356771093289,
          0.47245721636041516,
          0.4792768420228019,
          0.47744524798157534,
          0.47992130553746615,
          0.47413360385770825,
          0.4891283724311615,
          0.47146206060207463,
          0.4725066716247543,
          0.47421981432720495,
          0.47509827674326494,
          0.467506767790427,
          0.48101392759986794,
          0.476056847897639,
          0.4864916518815289,
          0.4764027842181404,
          0.4710527345378048,
          0.47533313375982755,
          0.476651268681432,
          0.47011212845426753,
          0.4678993784002907,
          0.47614993484406687,
          0.4699721327650116,
          0.47817908620643507,
          0.47195365450561433,
          0.47098801612099744,
          0.47361158599473674,
          0.4734281162019044,
          0.46773682273024947,
          0.47442986625995054,
          0.47992965659307973,
          0.4803537810227622,
          0.47782849991800813,
          0.4755833048830165,
          0.47442427700593404,
          0.47152652209703544,
          0.47418346018185636,
          0.47059656434887476,
          0.4726290772044729,
          0.4765326919998197,
          0.47697419245679706,
          0.47808491617680593,
          0.4733793731938419,
          0.4726823801968501,
          0.4698592048259145,
          0.47211085906567885,
          0.47244852982364655,
          0.47838932217908525,
          0.48037627474070604,
          0.47918118849053537,
          0.4741612926631936,
          0.4728438033902339,
          0.47374695314225157,
          0.4717925652091289,
          0.4802410386796166,
          0.4696368344828613,
          0.4757084202950518,
          0.47374940389009607,
          0.46740088270443064,
          0.47205506449530016,
          0.4701365183923391,
          0.47411675921598045,
          0.47143572671749556,
          0.46767101671620426,
          0.4773971007552863,
          0.47186851126008583,
          0.4726959032666368,
          0.480404100490545,
          0.4725809782928513,
          0.47610778828381245,
          0.4725246665125689,
          0.46920679239328467,
          0.4747861185140221,
          0.47425826551568157,
          0.4801263660247838,
          0.4754080991120146,
          0.4727588315492456,
          0.476782389620511,
          0.4745475629573795,
          0.4744544017281635,
          0.4733290955868358,
          0.4736699109515882,
          0.47054529547851914,
          0.47366229101686796,
          0.4792159338518216,
          0.46934150880573294,
          0.4769028784945505,
          0.46872593803518087,
          0.47270859089255834,
          0.4728450761737221,
          0.5580999826108497,
          0.46771894252505664,
          0.4804232071647254,
          0.4726844681399382,
          0.469114960247079,
          0.4730066615858699,
          0.4766316778854428,
          0.4777947693777608,
          0.47425675049708216,
          0.47897224965076085,
          0.4765646195693587,
          0.48050106290402317,
          0.47234244081827503,
          0.4711346738732935,
          0.4821882633205762,
          0.471824871131317,
          0.46895306889291594,
          0.4766971441821295,
          0.47818710608691867,
          0.4737086022486089,
          0.4725758218822527
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          960,
          640,
          832,
          896,
          704,
          640,
          896,
          640,
          704,
          640,
          512,
          512,
          512,
          768,
          512,
          768,
          1024,
          576,
          704,
          576,
          768,
          1024,
          960,
          896,
          832,
          960,
          576,
          704,
          832,
          960,
          1024,
          1024,
          960,
          960,
          896,
          896,
          832,
          960,
          896,
          960,
          832,
          704,
          896,
          960,
          896,
          640,
          768,
          1024,
          512,
          640,
          576,
          960,
          960,
          896,
          1024,
          960,
          896,
          832,
          768,
          960,
          1024,
          960,
          960,
          960,
          896,
          1024,
          512,
          576,
          704,
          896,
          1024,
          960,
          960,
          960,
          960,
          1024,
          960,
          896,
          832,
          960,
          640,
          960,
          960,
          896,
          1024,
          960,
          960,
          960,
          960,
          1024,
          704,
          704,
          768,
          704,
          704,
          704,
          704,
          704,
          704,
          640,
          640,
          640,
          704,
          768,
          640,
          768,
          704,
          704,
          768,
          640,
          576,
          704,
          704,
          704,
          640,
          704,
          704,
          768,
          640,
          704,
          704,
          640,
          640,
          640,
          576,
          960,
          960,
          704,
          960,
          704,
          704,
          704,
          640,
          704,
          640,
          640,
          640,
          960,
          640,
          768,
          576,
          960,
          960,
          960,
          960,
          960,
          896,
          1024,
          960,
          960,
          640,
          960,
          960,
          960,
          960,
          960,
          640,
          640,
          640,
          640,
          576,
          640,
          640,
          640,
          576,
          704,
          704,
          704,
          640,
          640,
          640,
          640,
          704,
          640,
          704,
          704,
          640,
          640,
          704,
          704,
          768,
          768,
          640,
          704,
          640
         ],
         "xaxis": "x5",
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.48582076595330836,
          0.49587634066649217,
          0.5560792513104827,
          0.49097770875755825,
          0.5471641810764196,
          0.4710884659460451,
          0.5192872211135511,
          0.4720872759986644,
          0.4780043560672921,
          0.4783535459108627,
          0.488548144677984,
          0.4749128374145374,
          0.487769105549433,
          0.47458700663798725,
          0.47753635333064803,
          0.47975956101430856,
          0.47947758102598936,
          0.49103530289164443,
          0.4789503351840474,
          0.4701534300838065,
          0.4804629293430363,
          0.4752618935408578,
          0.474945696293687,
          0.481977635714154,
          0.4863866662540127,
          0.48186299640489916,
          0.4922695804451491,
          0.508653296464621,
          0.4794973851669492,
          0.4737243393326588,
          0.46960232107520977,
          0.47120738116290567,
          0.4814090757681261,
          0.4757593588922349,
          0.47896822428703595,
          0.4788739237015786,
          0.4853290016196741,
          0.48325651304304423,
          0.4899098494396619,
          0.476696629183824,
          0.4765966158354703,
          0.4748064759492319,
          0.48392333305005486,
          0.47938930652759854,
          0.4745539856098385,
          0.48092740797674294,
          0.4753333800279938,
          0.5060278962560338,
          0.47373214689969584,
          0.47244882948448763,
          0.47652775516288504,
          0.47999415219853664,
          0.46765089132423154,
          0.4750165791239908,
          0.4879987234342427,
          0.5157825625317525,
          0.48817027384220946,
          0.47435968325415523,
          0.4728887151357227,
          0.47056914603092376,
          0.4739508108943912,
          0.47426974341841915,
          0.4728146041285085,
          0.4931526315687284,
          0.48179250246934996,
          0.47499075944337904,
          0.4792153890867136,
          0.4752772806530471,
          0.47720184036313684,
          0.49111532730738194,
          0.4749740798152371,
          0.4703356771093289,
          0.47245721636041516,
          0.4792768420228019,
          0.47744524798157534,
          0.47992130553746615,
          0.47413360385770825,
          0.4891283724311615,
          0.47146206060207463,
          0.4725066716247543,
          0.47421981432720495,
          0.47509827674326494,
          0.467506767790427,
          0.48101392759986794,
          0.476056847897639,
          0.4864916518815289,
          0.4764027842181404,
          0.4710527345378048,
          0.47533313375982755,
          0.476651268681432,
          0.47011212845426753,
          0.4678993784002907,
          0.47614993484406687,
          0.4699721327650116,
          0.47817908620643507,
          0.47195365450561433,
          0.47098801612099744,
          0.47361158599473674,
          0.4734281162019044,
          0.46773682273024947,
          0.47442986625995054,
          0.47992965659307973,
          0.4803537810227622,
          0.47782849991800813,
          0.4755833048830165,
          0.47442427700593404,
          0.47152652209703544,
          0.47418346018185636,
          0.47059656434887476,
          0.4726290772044729,
          0.4765326919998197,
          0.47697419245679706,
          0.47808491617680593,
          0.4733793731938419,
          0.4726823801968501,
          0.4698592048259145,
          0.47211085906567885,
          0.47244852982364655,
          0.47838932217908525,
          0.48037627474070604,
          0.47918118849053537,
          0.4741612926631936,
          0.4728438033902339,
          0.47374695314225157,
          0.4717925652091289,
          0.4802410386796166,
          0.4696368344828613,
          0.4757084202950518,
          0.47374940389009607,
          0.46740088270443064,
          0.47205506449530016,
          0.4701365183923391,
          0.47411675921598045,
          0.47143572671749556,
          0.46767101671620426,
          0.4773971007552863,
          0.47186851126008583,
          0.4726959032666368,
          0.480404100490545,
          0.4725809782928513,
          0.47610778828381245,
          0.4725246665125689,
          0.46920679239328467,
          0.4747861185140221,
          0.47425826551568157,
          0.4801263660247838,
          0.4754080991120146,
          0.4727588315492456,
          0.476782389620511,
          0.4745475629573795,
          0.4744544017281635,
          0.4733290955868358,
          0.4736699109515882,
          0.47054529547851914,
          0.47366229101686796,
          0.4792159338518216,
          0.46934150880573294,
          0.4769028784945505,
          0.46872593803518087,
          0.47270859089255834,
          0.4728450761737221,
          0.5580999826108497,
          0.46771894252505664,
          0.4804232071647254,
          0.4726844681399382,
          0.469114960247079,
          0.4730066615858699,
          0.4766316778854428,
          0.4777947693777608,
          0.47425675049708216,
          0.47897224965076085,
          0.4765646195693587,
          0.48050106290402317,
          0.47234244081827503,
          0.4711346738732935,
          0.4821882633205762,
          0.471824871131317,
          0.46895306889291594,
          0.4766971441821295,
          0.47818710608691867,
          0.4737086022486089,
          0.4725758218822527
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.0002588664181525908,
          0.000161057278681128,
          0.0016396856036401907,
          0.002872368186003481,
          0.004008237305299722,
          0.00013802314804892883,
          0.00023253919450148347,
          0.00012154154415700199,
          0.0015518839171447306,
          0.00044346412623993796,
          0.0007867671588114747,
          0.0009105145308432245,
          0.0007751313391533974,
          0.006339292269888179,
          0.0014115863467828163,
          0.0005184262379793942,
          0.002177630028862958,
          0.008974174280781714,
          0.0005324327333782856,
          0.0012674668633158024,
          0.00399980892859015,
          0.002170112580673651,
          0.002213682448427426,
          0.0007882354727916414,
          0.0030388312269541504,
          0.0011423756574218567,
          0.0018364677422010227,
          0.0003868863843780092,
          0.0006735719029118501,
          0.004970889687212739,
          0.00033058529409793106,
          0.0023945933966466625,
          0.0017653239541636021,
          0.0010841343282614558,
          0.0011495302755249457,
          0.0011167015260717561,
          0.0015341248734946288,
          0.0030941629626280104,
          0.000987350688259612,
          0.00020160720678968517,
          0.0005792631828130376,
          0.0008555712237307468,
          0.0013626941841421915,
          0.0006849151989582644,
          0.001813860160907638,
          0.00105355632001879,
          0.002361057928038119,
          0.0034615385682522444,
          0.0013987775064345205,
          0.0009161453056577809,
          0.0003126354223164865,
          0.0017490621418131777,
          0.002115386117471151,
          0.0021196521829694678,
          0.002695827265627391,
          0.0012253008061648713,
          0.0012032869956553522,
          0.0006302457439006027,
          0.00010010247605973642,
          0.0004831418738768299,
          0.0007397359532053902,
          0.0015066031766113614,
          0.002023174748138908,
          0.0012689047207273157,
          0.0009866794786861797,
          0.0015700096964809407,
          0.0008178691110082472,
          0.004878083708582916,
          0.0020074176324200613,
          0.0026535649956526824,
          0.001126486008439787,
          0.0019475945889252417,
          0.0033873139351688272,
          0.002349358991179453,
          0.0016321512325525834,
          0.0012950910824329146,
          0.0015994952549205754,
          0.0009686488132484556,
          0.0014741950807590808,
          0.0010996998069573675,
          0.0008437985806555495,
          0.0016721885391653116,
          0.001798210661220461,
          0.0012278334119140393,
          0.0016799848334505796,
          0.0024718408263323865,
          0.0027097425147124157,
          0.00402965810370141,
          0.0023684066691862763,
          0.0014293689230552352,
          0.0030892057749508607,
          0.003632696604335304,
          0.0029847270877637797,
          0.0019517052141859363,
          0.001954526669597874,
          0.0025010367996584214,
          0.0020103768406555477,
          0.0019175830650159684,
          0.0021230644640334185,
          0.004711783238308327,
          0.005995828159654584,
          0.004646904673134746,
          0.005848662257234637,
          0.007135404849144521,
          0.009881028664983504,
          0.006487683921332241,
          0.007884725782773817,
          0.005618349165551915,
          0.004244858975246592,
          0.0022427699341500333,
          0.0034018048938390575,
          0.002878012049058467,
          0.002601913282618621,
          0.0019963123356674336,
          0.00291886859734924,
          0.0013421038927177934,
          0.0018763547424458956,
          0.0016376642645953873,
          0.0022056844149485723,
          0.0021550769832010476,
          0.0024408391945993217,
          0.0017690679881125723,
          0.005264538801610082,
          0.00202348196666755,
          0.0022696173046276957,
          0.0028148436626532066,
          0.00441159656220877,
          0.0015581377517392206,
          0.0037065977085008195,
          0.0025468322465428106,
          0.003199490695979665,
          0.002535189798530011,
          0.0017902381479678216,
          0.0017892227969294957,
          0.0019658700902409304,
          0.0014338256982313557,
          0.0019199046328073352,
          0.002222371623277783,
          0.002226336920072351,
          0.0016946279835980205,
          0.001348125811839606,
          0.0021176200770539255,
          0.0019515789000444986,
          0.0024578921296118427,
          0.0016782284137755663,
          0.0015363302714005939,
          0.0011994619193719978,
          0.0014506002723293067,
          0.0009311012354072914,
          0.0010829844417766141,
          0.0015319453667741098,
          0.0018820965618550772,
          0.0022902348664587254,
          0.0020510578255722267,
          0.0026867786514655372,
          0.0017922096430485418,
          0.0015833133748020993,
          0.0012742420270781302,
          0.0015457351608856753,
          0.0016234810929234309,
          0.0023069044860626908,
          0.0016270061997998464,
          0.0013823949870248385,
          0.0017001041635459164,
          0.00016290292327420216,
          0.001881796353438737,
          0.00209162058501249,
          0.0018551263877306947,
          0.0010389817893428385,
          0.0010605883186534035,
          0.0011472171100875052,
          0.000983874910767221,
          0.0012500909819697537,
          0.0024655462595811572,
          0.0019991257928097662,
          0.0017925471188781014,
          0.002194283246104362,
          0.00143522049460481,
          0.0007529590746927326,
          0.0025745935228616364,
          0.0019356184297058823,
          0.0019277264013594661,
          0.0008610507693893002,
          0.001692893811428472,
          0.002248178643280508
         ],
         "xaxis": "x6",
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.48582076595330836,
          0.49587634066649217,
          0.5560792513104827,
          0.49097770875755825,
          0.5471641810764196,
          0.4710884659460451,
          0.5192872211135511,
          0.4720872759986644,
          0.4780043560672921,
          0.4783535459108627,
          0.488548144677984,
          0.4749128374145374,
          0.487769105549433,
          0.47458700663798725,
          0.47753635333064803,
          0.47975956101430856,
          0.47947758102598936,
          0.49103530289164443,
          0.4789503351840474,
          0.4701534300838065,
          0.4804629293430363,
          0.4752618935408578,
          0.474945696293687,
          0.481977635714154,
          0.4863866662540127,
          0.48186299640489916,
          0.4922695804451491,
          0.508653296464621,
          0.4794973851669492,
          0.4737243393326588,
          0.46960232107520977,
          0.47120738116290567,
          0.4814090757681261,
          0.4757593588922349,
          0.47896822428703595,
          0.4788739237015786,
          0.4853290016196741,
          0.48325651304304423,
          0.4899098494396619,
          0.476696629183824,
          0.4765966158354703,
          0.4748064759492319,
          0.48392333305005486,
          0.47938930652759854,
          0.4745539856098385,
          0.48092740797674294,
          0.4753333800279938,
          0.5060278962560338,
          0.47373214689969584,
          0.47244882948448763,
          0.47652775516288504,
          0.47999415219853664,
          0.46765089132423154,
          0.4750165791239908,
          0.4879987234342427,
          0.5157825625317525,
          0.48817027384220946,
          0.47435968325415523,
          0.4728887151357227,
          0.47056914603092376,
          0.4739508108943912,
          0.47426974341841915,
          0.4728146041285085,
          0.4931526315687284,
          0.48179250246934996,
          0.47499075944337904,
          0.4792153890867136,
          0.4752772806530471,
          0.47720184036313684,
          0.49111532730738194,
          0.4749740798152371,
          0.4703356771093289,
          0.47245721636041516,
          0.4792768420228019,
          0.47744524798157534,
          0.47992130553746615,
          0.47413360385770825,
          0.4891283724311615,
          0.47146206060207463,
          0.4725066716247543,
          0.47421981432720495,
          0.47509827674326494,
          0.467506767790427,
          0.48101392759986794,
          0.476056847897639,
          0.4864916518815289,
          0.4764027842181404,
          0.4710527345378048,
          0.47533313375982755,
          0.476651268681432,
          0.47011212845426753,
          0.4678993784002907,
          0.47614993484406687,
          0.4699721327650116,
          0.47817908620643507,
          0.47195365450561433,
          0.47098801612099744,
          0.47361158599473674,
          0.4734281162019044,
          0.46773682273024947,
          0.47442986625995054,
          0.47992965659307973,
          0.4803537810227622,
          0.47782849991800813,
          0.4755833048830165,
          0.47442427700593404,
          0.47152652209703544,
          0.47418346018185636,
          0.47059656434887476,
          0.4726290772044729,
          0.4765326919998197,
          0.47697419245679706,
          0.47808491617680593,
          0.4733793731938419,
          0.4726823801968501,
          0.4698592048259145,
          0.47211085906567885,
          0.47244852982364655,
          0.47838932217908525,
          0.48037627474070604,
          0.47918118849053537,
          0.4741612926631936,
          0.4728438033902339,
          0.47374695314225157,
          0.4717925652091289,
          0.4802410386796166,
          0.4696368344828613,
          0.4757084202950518,
          0.47374940389009607,
          0.46740088270443064,
          0.47205506449530016,
          0.4701365183923391,
          0.47411675921598045,
          0.47143572671749556,
          0.46767101671620426,
          0.4773971007552863,
          0.47186851126008583,
          0.4726959032666368,
          0.480404100490545,
          0.4725809782928513,
          0.47610778828381245,
          0.4725246665125689,
          0.46920679239328467,
          0.4747861185140221,
          0.47425826551568157,
          0.4801263660247838,
          0.4754080991120146,
          0.4727588315492456,
          0.476782389620511,
          0.4745475629573795,
          0.4744544017281635,
          0.4733290955868358,
          0.4736699109515882,
          0.47054529547851914,
          0.47366229101686796,
          0.4792159338518216,
          0.46934150880573294,
          0.4769028784945505,
          0.46872593803518087,
          0.47270859089255834,
          0.4728450761737221,
          0.5580999826108497,
          0.46771894252505664,
          0.4804232071647254,
          0.4726844681399382,
          0.469114960247079,
          0.4730066615858699,
          0.4766316778854428,
          0.4777947693777608,
          0.47425675049708216,
          0.47897224965076085,
          0.4765646195693587,
          0.48050106290402317,
          0.47234244081827503,
          0.4711346738732935,
          0.4821882633205762,
          0.471824871131317,
          0.46895306889291594,
          0.4766971441821295,
          0.47818710608691867,
          0.4737086022486089,
          0.4725758218822527
         ],
         "yaxis": "y6"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          4,
          2,
          4,
          2,
          2,
          3,
          4,
          3,
          2,
          2,
          3,
          3,
          3,
          2,
          3,
          2,
          4,
          3,
          3,
          2,
          3,
          4,
          4,
          4,
          4,
          3,
          3,
          2,
          4,
          4,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          2,
          4,
          3,
          2,
          4,
          3,
          2,
          4,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          3,
          4,
          3,
          2,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          2,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          2,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4
         ],
         "xaxis": "x7",
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.48582076595330836,
          0.49587634066649217,
          0.5560792513104827,
          0.49097770875755825,
          0.5471641810764196,
          0.4710884659460451,
          0.5192872211135511,
          0.4720872759986644,
          0.4780043560672921,
          0.4783535459108627,
          0.488548144677984,
          0.4749128374145374,
          0.487769105549433,
          0.47458700663798725,
          0.47753635333064803,
          0.47975956101430856,
          0.47947758102598936,
          0.49103530289164443,
          0.4789503351840474,
          0.4701534300838065,
          0.4804629293430363,
          0.4752618935408578,
          0.474945696293687,
          0.481977635714154,
          0.4863866662540127,
          0.48186299640489916,
          0.4922695804451491,
          0.508653296464621,
          0.4794973851669492,
          0.4737243393326588,
          0.46960232107520977,
          0.47120738116290567,
          0.4814090757681261,
          0.4757593588922349,
          0.47896822428703595,
          0.4788739237015786,
          0.4853290016196741,
          0.48325651304304423,
          0.4899098494396619,
          0.476696629183824,
          0.4765966158354703,
          0.4748064759492319,
          0.48392333305005486,
          0.47938930652759854,
          0.4745539856098385,
          0.48092740797674294,
          0.4753333800279938,
          0.5060278962560338,
          0.47373214689969584,
          0.47244882948448763,
          0.47652775516288504,
          0.47999415219853664,
          0.46765089132423154,
          0.4750165791239908,
          0.4879987234342427,
          0.5157825625317525,
          0.48817027384220946,
          0.47435968325415523,
          0.4728887151357227,
          0.47056914603092376,
          0.4739508108943912,
          0.47426974341841915,
          0.4728146041285085,
          0.4931526315687284,
          0.48179250246934996,
          0.47499075944337904,
          0.4792153890867136,
          0.4752772806530471,
          0.47720184036313684,
          0.49111532730738194,
          0.4749740798152371,
          0.4703356771093289,
          0.47245721636041516,
          0.4792768420228019,
          0.47744524798157534,
          0.47992130553746615,
          0.47413360385770825,
          0.4891283724311615,
          0.47146206060207463,
          0.4725066716247543,
          0.47421981432720495,
          0.47509827674326494,
          0.467506767790427,
          0.48101392759986794,
          0.476056847897639,
          0.4864916518815289,
          0.4764027842181404,
          0.4710527345378048,
          0.47533313375982755,
          0.476651268681432,
          0.47011212845426753,
          0.4678993784002907,
          0.47614993484406687,
          0.4699721327650116,
          0.47817908620643507,
          0.47195365450561433,
          0.47098801612099744,
          0.47361158599473674,
          0.4734281162019044,
          0.46773682273024947,
          0.47442986625995054,
          0.47992965659307973,
          0.4803537810227622,
          0.47782849991800813,
          0.4755833048830165,
          0.47442427700593404,
          0.47152652209703544,
          0.47418346018185636,
          0.47059656434887476,
          0.4726290772044729,
          0.4765326919998197,
          0.47697419245679706,
          0.47808491617680593,
          0.4733793731938419,
          0.4726823801968501,
          0.4698592048259145,
          0.47211085906567885,
          0.47244852982364655,
          0.47838932217908525,
          0.48037627474070604,
          0.47918118849053537,
          0.4741612926631936,
          0.4728438033902339,
          0.47374695314225157,
          0.4717925652091289,
          0.4802410386796166,
          0.4696368344828613,
          0.4757084202950518,
          0.47374940389009607,
          0.46740088270443064,
          0.47205506449530016,
          0.4701365183923391,
          0.47411675921598045,
          0.47143572671749556,
          0.46767101671620426,
          0.4773971007552863,
          0.47186851126008583,
          0.4726959032666368,
          0.480404100490545,
          0.4725809782928513,
          0.47610778828381245,
          0.4725246665125689,
          0.46920679239328467,
          0.4747861185140221,
          0.47425826551568157,
          0.4801263660247838,
          0.4754080991120146,
          0.4727588315492456,
          0.476782389620511,
          0.4745475629573795,
          0.4744544017281635,
          0.4733290955868358,
          0.4736699109515882,
          0.47054529547851914,
          0.47366229101686796,
          0.4792159338518216,
          0.46934150880573294,
          0.4769028784945505,
          0.46872593803518087,
          0.47270859089255834,
          0.4728450761737221,
          0.5580999826108497,
          0.46771894252505664,
          0.4804232071647254,
          0.4726844681399382,
          0.469114960247079,
          0.4730066615858699,
          0.4766316778854428,
          0.4777947693777608,
          0.47425675049708216,
          0.47897224965076085,
          0.4765646195693587,
          0.48050106290402317,
          0.47234244081827503,
          0.4711346738732935,
          0.4821882633205762,
          0.471824871131317,
          0.46895306889291594,
          0.4766971441821295,
          0.47818710608691867,
          0.4737086022486089,
          0.4725758218822527
         ],
         "yaxis": "y7"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.1,
          0.05,
          0.1,
          0.2,
          0.05,
          0.15000000000000002,
          0.05,
          0.2,
          0.05,
          0.2,
          0.1,
          0.1,
          0.15000000000000002,
          0.05,
          0.1,
          0.15000000000000002,
          0.05,
          0.1,
          0.05,
          0.1,
          0.15000000000000002,
          0.05,
          0.05,
          0.05,
          0.1,
          0.05,
          0.1,
          0.05,
          0.05,
          0.1,
          0.1,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.1,
          0.05,
          0.1,
          0.05,
          0.2,
          0.05,
          0.15000000000000002,
          0.1,
          0.05,
          0.15000000000000002,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.1,
          0.05,
          0.05,
          0.2,
          0.1,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.1,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.1,
          0.05,
          0.15000000000000002,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.2,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.15000000000000002,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05,
          0.05
         ],
         "xaxis": "x8",
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.48582076595330836,
          0.49587634066649217,
          0.5560792513104827,
          0.49097770875755825,
          0.5471641810764196,
          0.4710884659460451,
          0.5192872211135511,
          0.4720872759986644,
          0.4780043560672921,
          0.4783535459108627,
          0.488548144677984,
          0.4749128374145374,
          0.487769105549433,
          0.47458700663798725,
          0.47753635333064803,
          0.47975956101430856,
          0.47947758102598936,
          0.49103530289164443,
          0.4789503351840474,
          0.4701534300838065,
          0.4804629293430363,
          0.4752618935408578,
          0.474945696293687,
          0.481977635714154,
          0.4863866662540127,
          0.48186299640489916,
          0.4922695804451491,
          0.508653296464621,
          0.4794973851669492,
          0.4737243393326588,
          0.46960232107520977,
          0.47120738116290567,
          0.4814090757681261,
          0.4757593588922349,
          0.47896822428703595,
          0.4788739237015786,
          0.4853290016196741,
          0.48325651304304423,
          0.4899098494396619,
          0.476696629183824,
          0.4765966158354703,
          0.4748064759492319,
          0.48392333305005486,
          0.47938930652759854,
          0.4745539856098385,
          0.48092740797674294,
          0.4753333800279938,
          0.5060278962560338,
          0.47373214689969584,
          0.47244882948448763,
          0.47652775516288504,
          0.47999415219853664,
          0.46765089132423154,
          0.4750165791239908,
          0.4879987234342427,
          0.5157825625317525,
          0.48817027384220946,
          0.47435968325415523,
          0.4728887151357227,
          0.47056914603092376,
          0.4739508108943912,
          0.47426974341841915,
          0.4728146041285085,
          0.4931526315687284,
          0.48179250246934996,
          0.47499075944337904,
          0.4792153890867136,
          0.4752772806530471,
          0.47720184036313684,
          0.49111532730738194,
          0.4749740798152371,
          0.4703356771093289,
          0.47245721636041516,
          0.4792768420228019,
          0.47744524798157534,
          0.47992130553746615,
          0.47413360385770825,
          0.4891283724311615,
          0.47146206060207463,
          0.4725066716247543,
          0.47421981432720495,
          0.47509827674326494,
          0.467506767790427,
          0.48101392759986794,
          0.476056847897639,
          0.4864916518815289,
          0.4764027842181404,
          0.4710527345378048,
          0.47533313375982755,
          0.476651268681432,
          0.47011212845426753,
          0.4678993784002907,
          0.47614993484406687,
          0.4699721327650116,
          0.47817908620643507,
          0.47195365450561433,
          0.47098801612099744,
          0.47361158599473674,
          0.4734281162019044,
          0.46773682273024947,
          0.47442986625995054,
          0.47992965659307973,
          0.4803537810227622,
          0.47782849991800813,
          0.4755833048830165,
          0.47442427700593404,
          0.47152652209703544,
          0.47418346018185636,
          0.47059656434887476,
          0.4726290772044729,
          0.4765326919998197,
          0.47697419245679706,
          0.47808491617680593,
          0.4733793731938419,
          0.4726823801968501,
          0.4698592048259145,
          0.47211085906567885,
          0.47244852982364655,
          0.47838932217908525,
          0.48037627474070604,
          0.47918118849053537,
          0.4741612926631936,
          0.4728438033902339,
          0.47374695314225157,
          0.4717925652091289,
          0.4802410386796166,
          0.4696368344828613,
          0.4757084202950518,
          0.47374940389009607,
          0.46740088270443064,
          0.47205506449530016,
          0.4701365183923391,
          0.47411675921598045,
          0.47143572671749556,
          0.46767101671620426,
          0.4773971007552863,
          0.47186851126008583,
          0.4726959032666368,
          0.480404100490545,
          0.4725809782928513,
          0.47610778828381245,
          0.4725246665125689,
          0.46920679239328467,
          0.4747861185140221,
          0.47425826551568157,
          0.4801263660247838,
          0.4754080991120146,
          0.4727588315492456,
          0.476782389620511,
          0.4745475629573795,
          0.4744544017281635,
          0.4733290955868358,
          0.4736699109515882,
          0.47054529547851914,
          0.47366229101686796,
          0.4792159338518216,
          0.46934150880573294,
          0.4769028784945505,
          0.46872593803518087,
          0.47270859089255834,
          0.4728450761737221,
          0.5580999826108497,
          0.46771894252505664,
          0.4804232071647254,
          0.4726844681399382,
          0.469114960247079,
          0.4730066615858699,
          0.4766316778854428,
          0.4777947693777608,
          0.47425675049708216,
          0.47897224965076085,
          0.4765646195693587,
          0.48050106290402317,
          0.47234244081827503,
          0.4711346738732935,
          0.4821882633205762,
          0.471824871131317,
          0.46895306889291594,
          0.4766971441821295,
          0.47818710608691867,
          0.4737086022486089,
          0.4725758218822527
         ],
         "yaxis": "y8"
        },
        {
         "marker": {
          "color": [
           0,
           1,
           2,
           3,
           4,
           5,
           6,
           7,
           8,
           9,
           10,
           11,
           12,
           13,
           14,
           15,
           16,
           17,
           18,
           19,
           20,
           21,
           22,
           23,
           24,
           25,
           26,
           27,
           28,
           29,
           30,
           31,
           32,
           33,
           34,
           35,
           36,
           37,
           38,
           39,
           40,
           41,
           42,
           43,
           44,
           45,
           46,
           47,
           48,
           49,
           50,
           51,
           52,
           53,
           54,
           55,
           56,
           57,
           58,
           59,
           60,
           61,
           62,
           63,
           64,
           65,
           66,
           67,
           68,
           69,
           70,
           71,
           72,
           73,
           74,
           75,
           76,
           77,
           78,
           79,
           80,
           81,
           82,
           83,
           84,
           85,
           86,
           87,
           88,
           89,
           90,
           91,
           92,
           93,
           94,
           95,
           96,
           97,
           98,
           99,
           100,
           101,
           102,
           103,
           104,
           105,
           106,
           107,
           108,
           109,
           110,
           111,
           112,
           113,
           114,
           115,
           116,
           117,
           118,
           119,
           120,
           121,
           122,
           123,
           124,
           125,
           126,
           127,
           128,
           129,
           130,
           131,
           132,
           133,
           134,
           135,
           136,
           137,
           138,
           139,
           140,
           141,
           142,
           143,
           144,
           145,
           146,
           147,
           148,
           149,
           150,
           151,
           152,
           153,
           154,
           155,
           156,
           157,
           158,
           159,
           160,
           161,
           162,
           163,
           164,
           165,
           166,
           167,
           168,
           169,
           170,
           171,
           172,
           173,
           174,
           175,
           176,
           177,
           178,
           179,
           180,
           181,
           182,
           183,
           184
          ],
          "colorbar": {
           "title": {
            "text": "Trial"
           },
           "x": 1,
           "xpad": 40
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "line": {
           "color": "Grey",
           "width": 0.5
          },
          "showscale": false
         },
         "mode": "markers",
         "name": "Feasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0.00082221906556219,
          0.001640600997391677,
          0.00015369837367894628,
          0.0027980574720835863,
          0.0010663361779302298,
          0.0007242903380502764,
          0.007065495565861469,
          0.0005033719120294154,
          0.0001804929050961871,
          0.00010311833386528417,
          0.00028351645859091203,
          0.0002796893011050871,
          0.00029403508838305543,
          0.0003170629661016891,
          0.00016716600670915169,
          0.00018302715957788505,
          0.0005292085626742237,
          0.00011699814929837793,
          0.0003399214863011736,
          0.001706625257406281,
          0.008062363517837083,
          0.00047331980024545767,
          0.00022076374190220199,
          0.00021930719529535304,
          0.00021648428079102983,
          0.00013443426629888342,
          0.0004178281808070368,
          0.0002173155079870575,
          0.0006472235180873076,
          0.0009485391419018526,
          0.00010416165449810195,
          0.000579149257359181,
          0.0003718342139791088,
          0.00037763936593207726,
          0.00025297399173705015,
          0.0001429384422934845,
          0.0015205072489274595,
          0.0002297273471817005,
          0.00017437895259046852,
          0.003455505793663584,
          0.00013332244054734682,
          0.0002495905590930693,
          0.0004101143609142418,
          0.0008299070970841205,
          0.00028653525497936003,
          0.00018374355313284773,
          0.00032938875953975527,
          0.0002659697655269599,
          0.00019052081624650454,
          0.0001497905809179422,
          0.00045328333699481857,
          0.0003633902544547695,
          0.00039783595856394456,
          0.0006959634083114542,
          0.00030235236583754725,
          0.000560100326563079,
          0.0005194500253350152,
          0.00025271552994540964,
          0.0006120390787126291,
          0.0008226998619500332,
          0.001094075836193364,
          0.00039967179888098127,
          0.0003231791952234229,
          0.00020761206017655428,
          0.00032405163324833013,
          0.00015796103246462563,
          0.00012051182125046402,
          0.00047361268524248867,
          0.0002455159413249541,
          0.0002849743191062715,
          0.00020479220914917408,
          0.0003581924769622819,
          0.005269196912458715,
          0.0005662146734531387,
          0.0004291354035635282,
          0.0004618808961813122,
          0.0003106051845810959,
          0.00023285323156932187,
          0.0001716425933657503,
          0.0012943824471550749,
          0.0002743539761243927,
          0.00041619059627920693,
          0.0003483263169371521,
          0.0005083204529828265,
          0.00042603254651470574,
          0.0001916307882604006,
          0.0007362811055687027,
          0.00019592030310977223,
          0.002438469697807971,
          0.00013840530659470088,
          0.00022898061249597245,
          0.000228513069141484,
          0.0002632977109583292,
          0.00017320583008140336,
          0.00016141079337028477,
          0.00012311443581728367,
          0.00010245305639032575,
          0.00010158637042178419,
          0.00015699556853067138,
          0.00011291452373247455,
          0.00010775068739997858,
          0.00012636536633555648,
          0.00011169079801714288,
          0.0001092764398713156,
          0.0001462632497971228,
          0.00011614691916624065,
          0.00013319830128850075,
          0.00017305757406693934,
          0.00016264053160329508,
          0.000148115202982413,
          0.00019160560199752458,
          0.00011450514803913479,
          0.00010919986208274353,
          0.00012926695802538938,
          0.00011273614675604906,
          0.00010142008595495492,
          0.00014194986150155032,
          0.0001620388935980509,
          0.00018462500016201933,
          0.00021516483099917488,
          0.0001802256911268041,
          0.00012696632661677264,
          0.0002047561283958063,
          0.00011706034840997335,
          0.0003738691939148039,
          0.00015191151589422427,
          0.00017983498526603518,
          0.0001394135756010294,
          0.0005627568137705138,
          0.0003008301169983658,
          0.0002989331190118074,
          0.00024179323164855382,
          0.0003339096474946611,
          0.0003664521062264116,
          0.00028375833318134677,
          0.0003127081069390654,
          0.0003295096586027058,
          0.00026761424617924745,
          0.00027284838714712606,
          0.00025822628503633434,
          0.00044862227230969067,
          0.0002969646714440739,
          0.0003932102126072857,
          0.00021750611648465817,
          0.00027834476712400405,
          0.00033462496750132705,
          0.00033532182219345364,
          0.000195755673819026,
          0.00023569877560062193,
          0.0003618273690138366,
          0.0004713936376554219,
          0.00032449086992358963,
          0.0002571668472127104,
          0.0004006253288538742,
          0.00030065841689346293,
          0.00043431261539511205,
          0.0003454084721556179,
          0.00034323650549377587,
          0.00021275248182807638,
          0.0005234998245423523,
          0.0005051763228538528,
          0.00036940605853713393,
          0.0002864711516465651,
          0.0007077194566242875,
          0.000389736977353419,
          0.0006539672782851887,
          0.0007984049910412703,
          0.0006062445051933062,
          0.000533916074151074,
          0.0005515610587001059,
          0.0004845719473984121,
          0.001008536580918341,
          0.0005444835396849118,
          0.0006364608996191926,
          0.00019334616103726756,
          0.0006458609960473965,
          0.00016580981895592418,
          0.00022645177184003252,
          0.009472046534333606,
          0.0002495238702309941,
          0.0005159655579547837,
          0.0004991474658092436,
          0.0005855091504663304,
          0.0007753988864656752,
          0.0006998149590402936
         ],
         "xaxis": "x9",
         "y": [
          0.4947163709900468,
          0.49297218666986886,
          0.4813471719885105,
          0.48582076595330836,
          0.49587634066649217,
          0.5560792513104827,
          0.49097770875755825,
          0.5471641810764196,
          0.4710884659460451,
          0.5192872211135511,
          0.4720872759986644,
          0.4780043560672921,
          0.4783535459108627,
          0.488548144677984,
          0.4749128374145374,
          0.487769105549433,
          0.47458700663798725,
          0.47753635333064803,
          0.47975956101430856,
          0.47947758102598936,
          0.49103530289164443,
          0.4789503351840474,
          0.4701534300838065,
          0.4804629293430363,
          0.4752618935408578,
          0.474945696293687,
          0.481977635714154,
          0.4863866662540127,
          0.48186299640489916,
          0.4922695804451491,
          0.508653296464621,
          0.4794973851669492,
          0.4737243393326588,
          0.46960232107520977,
          0.47120738116290567,
          0.4814090757681261,
          0.4757593588922349,
          0.47896822428703595,
          0.4788739237015786,
          0.4853290016196741,
          0.48325651304304423,
          0.4899098494396619,
          0.476696629183824,
          0.4765966158354703,
          0.4748064759492319,
          0.48392333305005486,
          0.47938930652759854,
          0.4745539856098385,
          0.48092740797674294,
          0.4753333800279938,
          0.5060278962560338,
          0.47373214689969584,
          0.47244882948448763,
          0.47652775516288504,
          0.47999415219853664,
          0.46765089132423154,
          0.4750165791239908,
          0.4879987234342427,
          0.5157825625317525,
          0.48817027384220946,
          0.47435968325415523,
          0.4728887151357227,
          0.47056914603092376,
          0.4739508108943912,
          0.47426974341841915,
          0.4728146041285085,
          0.4931526315687284,
          0.48179250246934996,
          0.47499075944337904,
          0.4792153890867136,
          0.4752772806530471,
          0.47720184036313684,
          0.49111532730738194,
          0.4749740798152371,
          0.4703356771093289,
          0.47245721636041516,
          0.4792768420228019,
          0.47744524798157534,
          0.47992130553746615,
          0.47413360385770825,
          0.4891283724311615,
          0.47146206060207463,
          0.4725066716247543,
          0.47421981432720495,
          0.47509827674326494,
          0.467506767790427,
          0.48101392759986794,
          0.476056847897639,
          0.4864916518815289,
          0.4764027842181404,
          0.4710527345378048,
          0.47533313375982755,
          0.476651268681432,
          0.47011212845426753,
          0.4678993784002907,
          0.47614993484406687,
          0.4699721327650116,
          0.47817908620643507,
          0.47195365450561433,
          0.47098801612099744,
          0.47361158599473674,
          0.4734281162019044,
          0.46773682273024947,
          0.47442986625995054,
          0.47992965659307973,
          0.4803537810227622,
          0.47782849991800813,
          0.4755833048830165,
          0.47442427700593404,
          0.47152652209703544,
          0.47418346018185636,
          0.47059656434887476,
          0.4726290772044729,
          0.4765326919998197,
          0.47697419245679706,
          0.47808491617680593,
          0.4733793731938419,
          0.4726823801968501,
          0.4698592048259145,
          0.47211085906567885,
          0.47244852982364655,
          0.47838932217908525,
          0.48037627474070604,
          0.47918118849053537,
          0.4741612926631936,
          0.4728438033902339,
          0.47374695314225157,
          0.4717925652091289,
          0.4802410386796166,
          0.4696368344828613,
          0.4757084202950518,
          0.47374940389009607,
          0.46740088270443064,
          0.47205506449530016,
          0.4701365183923391,
          0.47411675921598045,
          0.47143572671749556,
          0.46767101671620426,
          0.4773971007552863,
          0.47186851126008583,
          0.4726959032666368,
          0.480404100490545,
          0.4725809782928513,
          0.47610778828381245,
          0.4725246665125689,
          0.46920679239328467,
          0.4747861185140221,
          0.47425826551568157,
          0.4801263660247838,
          0.4754080991120146,
          0.4727588315492456,
          0.476782389620511,
          0.4745475629573795,
          0.4744544017281635,
          0.4733290955868358,
          0.4736699109515882,
          0.47054529547851914,
          0.47366229101686796,
          0.4792159338518216,
          0.46934150880573294,
          0.4769028784945505,
          0.46872593803518087,
          0.47270859089255834,
          0.4728450761737221,
          0.5580999826108497,
          0.46771894252505664,
          0.4804232071647254,
          0.4726844681399382,
          0.469114960247079,
          0.4730066615858699,
          0.4766316778854428,
          0.4777947693777608,
          0.47425675049708216,
          0.47897224965076085,
          0.4765646195693587,
          0.48050106290402317,
          0.47234244081827503,
          0.4711346738732935,
          0.4821882633205762,
          0.471824871131317,
          0.46895306889291594,
          0.4766971441821295,
          0.47818710608691867,
          0.4737086022486089,
          0.4725758218822527
         ],
         "yaxis": "y9"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Slice Plot"
        },
        "width": 2700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.09135802469135802
         ],
         "title": {
          "text": "batch_size"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.11358024691358025,
          0.20493827160493827
         ],
         "title": {
          "text": "div_factor"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.2271604938271605,
          0.31851851851851853
         ],
         "title": {
          "text": "dropout"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.34074074074074073,
          0.43209876543209874
         ],
         "title": {
          "text": "final_div_factor"
         },
         "type": "log"
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0.454320987654321,
          0.5456790123456791
         ],
         "title": {
          "text": "input_layer_size"
         }
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.5679012345679012,
          0.6592592592592592
         ],
         "title": {
          "text": "learning_rate"
         },
         "type": "log"
        },
        "xaxis7": {
         "anchor": "y7",
         "domain": [
          0.6814814814814815,
          0.7728395061728395
         ],
         "title": {
          "text": "n_layers"
         }
        },
        "xaxis8": {
         "anchor": "y8",
         "domain": [
          0.7950617283950617,
          0.8864197530864197
         ],
         "title": {
          "text": "pct_start"
         }
        },
        "xaxis9": {
         "anchor": "y9",
         "domain": [
          0.908641975308642,
          1
         ],
         "title": {
          "text": "weight_decay"
         },
         "type": "log"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Objective Value"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis7": {
         "anchor": "x7",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis8": {
         "anchor": "x8",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis9": {
         "anchor": "x9",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "mlp",
         "type": "scatter",
         "x": [
          0.46740088270443064,
          0.4683170352287379,
          0.4692331877530452,
          0.47014934027735245,
          0.4710654928016597,
          0.471981645325967,
          0.47289779785027425,
          0.47381395037458146,
          0.47473010289888873,
          0.475646255423196,
          0.47656240794750326,
          0.47747856047181053,
          0.4783947129961178,
          0.47931086552042507,
          0.48022701804473233,
          0.4811431705690396,
          0.48205932309334687,
          0.48297547561765414,
          0.4838916281419614,
          0.4848077806662686,
          0.4857239331905759,
          0.48664008571488315,
          0.4875562382391904,
          0.4884723907634977,
          0.48938854328780496,
          0.4903046958121122,
          0.4912208483364195,
          0.49213700086072676,
          0.493053153385034,
          0.4939693059093413,
          0.49488545843364856,
          0.49580161095795583,
          0.49671776348226304,
          0.4976339160065703,
          0.4985500685308776,
          0.49946622105518484,
          0.5003823735794921,
          0.5012985261037994,
          0.5022146786281066,
          0.5031308311524139,
          0.5040469836767212,
          0.5049631362010284,
          0.5058792887253357,
          0.5067954412496429,
          0.5077115937739503,
          0.5086277462982575,
          0.5095438988225648,
          0.510460051346872,
          0.5113762038711793,
          0.5122923563954865,
          0.5132085089197937,
          0.5141246614441011,
          0.5150408139684083,
          0.5159569664927156,
          0.5168731190170228,
          0.5177892715413301,
          0.5187054240656374,
          0.5196215765899447,
          0.5205377291142519,
          0.5214538816385592,
          0.5223700341628664,
          0.5232861866871737,
          0.524202339211481,
          0.5251184917357883,
          0.5260346442600955,
          0.5269507967844027,
          0.52786694930871,
          0.5287831018330172,
          0.5296992543573246,
          0.5306154068816318,
          0.5315315594059391,
          0.5324477119302463,
          0.5333638644545536,
          0.5342800169788608,
          0.5351961695031682,
          0.5361123220274754,
          0.5370284745517826,
          0.5379446270760899,
          0.5388607796003971,
          0.5397769321247045,
          0.5406930846490117,
          0.541609237173319,
          0.5425253896976262,
          0.5434415422219335,
          0.5443576947462407,
          0.5452738472705481,
          0.5461899997948553,
          0.5471061523191625,
          0.5480223048434698,
          0.548938457367777,
          0.5498546098920843,
          0.5507707624163916,
          0.5516869149406989,
          0.5526030674650061,
          0.5535192199893134,
          0.5544353725136206,
          0.555351525037928,
          0.5562676775622352,
          0.5571838300865425,
          0.5580999826108497
         ],
         "y": [
          0.005405405405405406,
          0.03783783783783784,
          0.05945945945945946,
          0.0972972972972973,
          0.13513513513513514,
          0.1891891891891892,
          0.3027027027027027,
          0.3675675675675676,
          0.4540540540540541,
          0.5297297297297298,
          0.572972972972973,
          0.6378378378378379,
          0.6864864864864865,
          0.7297297297297297,
          0.772972972972973,
          0.8216216216216217,
          0.8486486486486486,
          0.8540540540540541,
          0.8594594594594595,
          0.8648648648648649,
          0.8702702702702703,
          0.8864864864864865,
          0.8864864864864865,
          0.9027027027027027,
          0.9135135135135135,
          0.918918918918919,
          0.9351351351351351,
          0.9351351351351351,
          0.9459459459459459,
          0.9513513513513514,
          0.9567567567567568,
          0.9567567567567568,
          0.9621621621621622,
          0.9621621621621622,
          0.9621621621621622,
          0.9621621621621622,
          0.9621621621621622,
          0.9621621621621622,
          0.9621621621621622,
          0.9621621621621622,
          0.9621621621621622,
          0.9621621621621622,
          0.9621621621621622,
          0.9675675675675676,
          0.9675675675675676,
          0.9675675675675676,
          0.972972972972973,
          0.972972972972973,
          0.972972972972973,
          0.972972972972973,
          0.972972972972973,
          0.972972972972973,
          0.972972972972973,
          0.9783783783783784,
          0.9783783783783784,
          0.9783783783783784,
          0.9783783783783784,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9837837837837838,
          0.9891891891891892,
          0.9891891891891892,
          0.9891891891891892,
          0.9891891891891892,
          0.9891891891891892,
          0.9891891891891892,
          0.9891891891891892,
          0.9891891891891892,
          0.9891891891891892,
          0.9945945945945946,
          0.9945945945945946,
          1
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Empirical Distribution Function Plot"
        },
        "xaxis": {
         "title": {
          "text": "Objective Value"
         }
        },
        "yaxis": {
         "range": [
          0,
          1
         ],
         "title": {
          "text": "Cumulative Probability"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_edf(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "dimensions": [
          {
           "label": "Objective Value",
           "range": [
            0.46740088270443064,
            0.5580999826108497
           ],
           "values": [
            0.4947163709900468,
            0.49297218666986886,
            0.4813471719885105,
            0.48582076595330836,
            0.49587634066649217,
            0.5560792513104827,
            0.49097770875755825,
            0.5471641810764196,
            0.4710884659460451,
            0.5192872211135511,
            0.4720872759986644,
            0.4780043560672921,
            0.4783535459108627,
            0.488548144677984,
            0.4749128374145374,
            0.487769105549433,
            0.47458700663798725,
            0.47753635333064803,
            0.47975956101430856,
            0.47947758102598936,
            0.49103530289164443,
            0.4789503351840474,
            0.4701534300838065,
            0.4804629293430363,
            0.4752618935408578,
            0.474945696293687,
            0.481977635714154,
            0.4863866662540127,
            0.48186299640489916,
            0.4922695804451491,
            0.508653296464621,
            0.4794973851669492,
            0.4737243393326588,
            0.46960232107520977,
            0.47120738116290567,
            0.4814090757681261,
            0.4757593588922349,
            0.47896822428703595,
            0.4788739237015786,
            0.4853290016196741,
            0.48325651304304423,
            0.4899098494396619,
            0.476696629183824,
            0.4765966158354703,
            0.4748064759492319,
            0.48392333305005486,
            0.47938930652759854,
            0.4745539856098385,
            0.48092740797674294,
            0.4753333800279938,
            0.5060278962560338,
            0.47373214689969584,
            0.47244882948448763,
            0.47652775516288504,
            0.47999415219853664,
            0.46765089132423154,
            0.4750165791239908,
            0.4879987234342427,
            0.5157825625317525,
            0.48817027384220946,
            0.47435968325415523,
            0.4728887151357227,
            0.47056914603092376,
            0.4739508108943912,
            0.47426974341841915,
            0.4728146041285085,
            0.4931526315687284,
            0.48179250246934996,
            0.47499075944337904,
            0.4792153890867136,
            0.4752772806530471,
            0.47720184036313684,
            0.49111532730738194,
            0.4749740798152371,
            0.4703356771093289,
            0.47245721636041516,
            0.4792768420228019,
            0.47744524798157534,
            0.47992130553746615,
            0.47413360385770825,
            0.4891283724311615,
            0.47146206060207463,
            0.4725066716247543,
            0.47421981432720495,
            0.47509827674326494,
            0.467506767790427,
            0.48101392759986794,
            0.476056847897639,
            0.4864916518815289,
            0.4764027842181404,
            0.4710527345378048,
            0.47533313375982755,
            0.476651268681432,
            0.47011212845426753,
            0.4678993784002907,
            0.47614993484406687,
            0.4699721327650116,
            0.47817908620643507,
            0.47195365450561433,
            0.47098801612099744,
            0.47361158599473674,
            0.4734281162019044,
            0.46773682273024947,
            0.47442986625995054,
            0.47992965659307973,
            0.4803537810227622,
            0.47782849991800813,
            0.4755833048830165,
            0.47442427700593404,
            0.47152652209703544,
            0.47418346018185636,
            0.47059656434887476,
            0.4726290772044729,
            0.4765326919998197,
            0.47697419245679706,
            0.47808491617680593,
            0.4733793731938419,
            0.4726823801968501,
            0.4698592048259145,
            0.47211085906567885,
            0.47244852982364655,
            0.47838932217908525,
            0.48037627474070604,
            0.47918118849053537,
            0.4741612926631936,
            0.4728438033902339,
            0.47374695314225157,
            0.4717925652091289,
            0.4802410386796166,
            0.4696368344828613,
            0.4757084202950518,
            0.47374940389009607,
            0.46740088270443064,
            0.47205506449530016,
            0.4701365183923391,
            0.47411675921598045,
            0.47143572671749556,
            0.46767101671620426,
            0.4773971007552863,
            0.47186851126008583,
            0.4726959032666368,
            0.480404100490545,
            0.4725809782928513,
            0.47610778828381245,
            0.4725246665125689,
            0.46920679239328467,
            0.4747861185140221,
            0.47425826551568157,
            0.4801263660247838,
            0.4754080991120146,
            0.4727588315492456,
            0.476782389620511,
            0.4745475629573795,
            0.4744544017281635,
            0.4733290955868358,
            0.4736699109515882,
            0.47054529547851914,
            0.47366229101686796,
            0.4792159338518216,
            0.46934150880573294,
            0.4769028784945505,
            0.46872593803518087,
            0.47270859089255834,
            0.4728450761737221,
            0.5580999826108497,
            0.46771894252505664,
            0.4804232071647254,
            0.4726844681399382,
            0.469114960247079,
            0.4730066615858699,
            0.4766316778854428,
            0.4777947693777608,
            0.47425675049708216,
            0.47897224965076085,
            0.4765646195693587,
            0.48050106290402317,
            0.47234244081827503,
            0.4711346738732935,
            0.4821882633205762,
            0.471824871131317,
            0.46895306889291594,
            0.4766971441821295,
            0.47818710608691867,
            0.4737086022486089,
            0.4725758218822527
           ]
          },
          {
           "label": "batch_size",
           "range": [
            128,
            512
           ],
           "values": [
            448,
            320,
            384,
            128,
            128,
            384,
            512,
            256,
            320,
            320,
            192,
            192,
            256,
            192,
            256,
            192,
            384,
            512,
            320,
            128,
            448,
            384,
            448,
            448,
            320,
            256,
            448,
            192,
            512,
            384,
            320,
            384,
            448,
            448,
            512,
            512,
            448,
            512,
            448,
            512,
            384,
            448,
            128,
            512,
            512,
            256,
            448,
            384,
            320,
            192,
            512,
            448,
            448,
            384,
            128,
            448,
            256,
            384,
            320,
            192,
            448,
            448,
            448,
            512,
            384,
            448,
            512,
            448,
            384,
            256,
            320,
            448,
            448,
            448,
            512,
            512,
            512,
            512,
            512,
            512,
            448,
            448,
            448,
            384,
            448,
            512,
            512,
            512,
            512,
            320,
            448,
            448,
            448,
            448,
            448,
            448,
            384,
            384,
            448,
            448,
            384,
            448,
            448,
            448,
            448,
            384,
            448,
            448,
            448,
            384,
            448,
            448,
            448,
            448,
            512,
            448,
            448,
            512,
            448,
            384,
            448,
            448,
            448,
            448,
            448,
            512,
            384,
            448,
            448,
            448,
            512,
            448,
            448,
            448,
            448,
            448,
            448,
            448,
            512,
            448,
            448,
            448,
            448,
            448,
            448,
            448,
            384,
            448,
            448,
            512,
            384,
            448,
            448,
            448,
            448,
            448,
            448,
            448,
            448,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            512,
            448,
            448,
            512,
            448,
            448,
            448,
            448,
            448,
            448
           ]
          },
          {
           "label": "div_factor",
           "range": [
            1,
            100
           ],
           "values": [
            47,
            8,
            36,
            13,
            96,
            67,
            38,
            80,
            16,
            68,
            20,
            23,
            2,
            25,
            27,
            17,
            53,
            36,
            1,
            51,
            17,
            56,
            64,
            65,
            78,
            43,
            28,
            75,
            89,
            61,
            44,
            51,
            58,
            60,
            12,
            8,
            73,
            11,
            32,
            45,
            89,
            18,
            20,
            7,
            11,
            63,
            31,
            70,
            39,
            22,
            6,
            57,
            58,
            14,
            69,
            48,
            85,
            100,
            3,
            40,
            25,
            63,
            52,
            48,
            14,
            53,
            48,
            54,
            61,
            33,
            72,
            66,
            59,
            55,
            51,
            42,
            50,
            36,
            11,
            46,
            78,
            59,
            63,
            60,
            16,
            50,
            52,
            49,
            57,
            42,
            55,
            65,
            55,
            63,
            68,
            70,
            75,
            75,
            67,
            82,
            84,
            78,
            83,
            85,
            82,
            90,
            73,
            81,
            64,
            77,
            87,
            51,
            51,
            93,
            46,
            68,
            53,
            62,
            44,
            43,
            48,
            75,
            45,
            71,
            50,
            41,
            37,
            57,
            47,
            80,
            65,
            82,
            74,
            75,
            73,
            72,
            80,
            69,
            77,
            69,
            67,
            74,
            61,
            71,
            66,
            79,
            79,
            76,
            69,
            73,
            80,
            83,
            63,
            44,
            59,
            86,
            67,
            67,
            71,
            69,
            73,
            68,
            69,
            64,
            77,
            71,
            70,
            74,
            79,
            80,
            76,
            71,
            79,
            73,
            68,
            88,
            84,
            65,
            78,
            75,
            62,
            61,
            66,
            63,
            71
           ]
          },
          {
           "label": "dropout",
           "range": [
            0,
            0.3
           ],
           "values": [
            0.3,
            0.05,
            0.2,
            0.1,
            0.3,
            0,
            0.25,
            0.3,
            0.1,
            0.3,
            0.15000000000000002,
            0.15000000000000002,
            0.15000000000000002,
            0.1,
            0.1,
            0.2,
            0.05,
            0.2,
            0.05,
            0,
            0.15000000000000002,
            0.05,
            0.1,
            0.1,
            0.1,
            0.15000000000000002,
            0.2,
            0.1,
            0.15000000000000002,
            0.25,
            0.05,
            0.05,
            0,
            0,
            0,
            0,
            0,
            0.05,
            0.05,
            0,
            0,
            0.1,
            0.1,
            0.2,
            0.15000000000000002,
            0.1,
            0.15000000000000002,
            0.25,
            0.05,
            0,
            0.1,
            0,
            0,
            0,
            0.05,
            0,
            0.05,
            0.2,
            0.15000000000000002,
            0,
            0.1,
            0,
            0,
            0.05,
            0,
            0,
            0.15000000000000002,
            0.05,
            0,
            0.05,
            0.3,
            0,
            0,
            0,
            0,
            0,
            0.1,
            0.05,
            0.15000000000000002,
            0,
            0.05,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0.05,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0.05,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0.05,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0.05,
            0.05,
            0.05,
            0,
            0,
            0.05,
            0,
            0,
            0,
            0,
            0,
            0,
            0.05,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0.1,
            0.05,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0.1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            0.25,
            0,
            0,
            0,
            0,
            0.05,
            0.05,
            0.05,
            0,
            0
           ]
          },
          {
           "label": "final_div_factor",
           "range": [
            0.013179045065928223,
            3.9990103696822428
           ],
           "ticktext": [
            "1.03",
            "10",
            "100",
            "1e+03",
            "9.98e+03"
           ],
           "tickvals": [
            0.013179045065928223,
            1,
            2,
            3,
            3.9990103696822428
           ],
           "values": [
            2.184490811393021,
            3.5022367130725627,
            2.4373908762185077,
            1.0636845939219746,
            0.9984116615395489,
            2.510253515824378,
            0.39043288127955256,
            3.137005114057194,
            2.6671323466954657,
            1.7082183718455033,
            3.811201226102568,
            3.9640794805721424,
            3.069492331880743,
            3.6317288276488777,
            2.919508862580935,
            1.6319630094495485,
            3.9252133742791195,
            2.7978501669395937,
            3.498301785512752,
            0.013179045065928223,
            1.7442590161545435,
            3.8537903425572515,
            3.422924072640967,
            3.2367279937340827,
            2.6915354838324506,
            3.296109534110869,
            2.1517840899437677,
            3.6307702340478594,
            2.520454989908173,
            3.3646930474182755,
            2.8686124290043713,
            3.9907082416622845,
            3.6990033277122114,
            3.69275251738101,
            3.4176908027393313,
            3.4476161403156635,
            2.34856472030515,
            3.0280231173681,
            3.242115509762629,
            2.664903854773596,
            1.1440047332477725,
            3.6482560316573855,
            3.76855882781008,
            3.4414331998609313,
            3.0405623841909737,
            3.551260619065735,
            3.7711574860837813,
            1.9547641705989025,
            3.1807232869519573,
            3.394367251048232,
            3.8297488634568,
            3.6965095180867547,
            3.9895348178914203,
            3.9884926251560335,
            3.5475736883230398,
            3.849049116316583,
            2.990563549157692,
            3.1685289332137163,
            3.5465088546439127,
            3.8231704565343945,
            1.4092456110495308,
            3.8547847586195467,
            3.3195239392054536,
            3.3914678042750164,
            3.2862332785354087,
            3.6111439378490204,
            2.6889588614581266,
            2.905309811811741,
            3.118192818321838,
            2.431223471250318,
            3.3099761766654034,
            3.9091149056698336,
            3.721606879454944,
            3.5105763247534867,
            3.963919981613594,
            0.5460148180512889,
            3.649017244870175,
            3.88622660652211,
            3.45650993602441,
            3.752898054911579,
            2.7621756391538312,
            3.9952119144152425,
            3.856171540704574,
            3.6048468223496295,
            3.748579618448819,
            2.230063159534106,
            2.268979165357699,
            1.907057462455938,
            2.607079753642325,
            3.9395172451367566,
            2.1280194045824743,
            2.103594998577668,
            1.786068190774623,
            2.0959186638507106,
            2.0717549881754844,
            2.047319224993085,
            2.2222118082759277,
            2.161916047926305,
            2.3202067728923184,
            1.8069945407041448,
            1.839157588837668,
            1.5192836267153538,
            2.0006716540469687,
            1.643160113062553,
            2.2249561763525016,
            1.9217814176436,
            2.0679650353183296,
            2.4156177446660436,
            1.9869224946084851,
            2.5149483011626645,
            1.8268781420608293,
            1.6745489063920502,
            1.199151000642377,
            1.7317673516577812,
            1.486111686639901,
            1.6543753010313311,
            1.3303582292380995,
            1.8625002865584164,
            2.0003475831924864,
            0.7377009687369932,
            2.3564517953403774,
            2.197244777614037,
            1.9642001195700454,
            1.5323930184875294,
            2.0293888741954587,
            1.7421907775311294,
            2.2448475237375622,
            1.9112229920271713,
            0.0555393290920324,
            2.0052122768583454,
            2.1282583615098374,
            2.0635977312589775,
            1.5945604302071998,
            1.6784011768230689,
            1.5682248040314213,
            0.9683492472314651,
            1.3546040781977675,
            2.2969491548565006,
            2.310001843504299,
            2.579070393350828,
            1.5549352908042864,
            2.190879394898159,
            2.407825121850431,
            1.9952507699886157,
            2.265025729020361,
            2.112885034186369,
            2.1100316004348567,
            2.0118525228223203,
            1.8924062019811885,
            2.1713932251600387,
            2.335118494995522,
            2.06492670824059,
            1.9468029252340275,
            3.8996541452013056,
            2.490891042303835,
            2.243053542329876,
            3.8076759664927757,
            3.815273550685349,
            3.6780832899339932,
            3.814569991045034,
            1.781441846810261,
            3.799021639016089,
            3.7335995561505824,
            3.9078712504593476,
            3.575093718101658,
            3.9308944102320944,
            2.1502912694994976,
            3.7003772412577822,
            3.7945976014527822,
            3.8106582847634565,
            1.9971602897586755,
            3.6390955820273883,
            3.8669199365781597,
            3.7619748746748005,
            3.9990103696822428,
            2.090346167095223,
            3.515125885607371,
            1.8886990413012992,
            1.4499494278968597,
            1.5786437686637012,
            1.200556844682463,
            1.1819559604788898,
            1.2826107619066647,
            1.105683379707895,
            0.8467454336408112
           ]
          },
          {
           "label": "input_layer_size",
           "range": [
            512,
            1024
           ],
           "values": [
            960,
            640,
            832,
            896,
            704,
            640,
            896,
            640,
            704,
            640,
            512,
            512,
            512,
            768,
            512,
            768,
            1024,
            576,
            704,
            576,
            768,
            1024,
            960,
            896,
            832,
            960,
            576,
            704,
            832,
            960,
            1024,
            1024,
            960,
            960,
            896,
            896,
            832,
            960,
            896,
            960,
            832,
            704,
            896,
            960,
            896,
            640,
            768,
            1024,
            512,
            640,
            576,
            960,
            960,
            896,
            1024,
            960,
            896,
            832,
            768,
            960,
            1024,
            960,
            960,
            960,
            896,
            1024,
            512,
            576,
            704,
            896,
            1024,
            960,
            960,
            960,
            960,
            1024,
            960,
            896,
            832,
            960,
            640,
            960,
            960,
            896,
            1024,
            960,
            960,
            960,
            960,
            1024,
            704,
            704,
            768,
            704,
            704,
            704,
            704,
            704,
            704,
            640,
            640,
            640,
            704,
            768,
            640,
            768,
            704,
            704,
            768,
            640,
            576,
            704,
            704,
            704,
            640,
            704,
            704,
            768,
            640,
            704,
            704,
            640,
            640,
            640,
            576,
            960,
            960,
            704,
            960,
            704,
            704,
            704,
            640,
            704,
            640,
            640,
            640,
            960,
            640,
            768,
            576,
            960,
            960,
            960,
            960,
            960,
            896,
            1024,
            960,
            960,
            640,
            960,
            960,
            960,
            960,
            960,
            640,
            640,
            640,
            640,
            576,
            640,
            640,
            640,
            576,
            704,
            704,
            704,
            640,
            640,
            640,
            640,
            704,
            640,
            704,
            704,
            640,
            640,
            704,
            704,
            768,
            768,
            640,
            704,
            640
           ]
          },
          {
           "label": "learning_rate",
           "range": [
            -3.999555180005388,
            -2.0051978408100313
           ],
           "ticktext": [
            "0.0001",
            "0.001",
            "0.00988"
           ],
           "tickvals": [
            -3.999555180005388,
            -3,
            -2.0051978408100313
           ],
           "values": [
            -3.586924285436019,
            -3.7930196432775802,
            -2.7852394163996395,
            -2.5417598921104614,
            -2.3970465742337943,
            -3.860048071375122,
            -3.633503836231625,
            -3.9152752503434405,
            -2.809140767632573,
            -3.3531415063986163,
            -3.104153776669108,
            -3.0407131189358663,
            -3.1106247038977486,
            -2.1979592248373367,
            -2.8502925508969077,
            -3.2853130265793866,
            -2.6620159033092006,
            -2.0470055006100716,
            -3.2737352524299603,
            -2.8970633860516,
            -2.39796075448227,
            -2.6635177353233237,
            -2.6548846783022997,
            -3.1033440245693575,
            -2.5172934194455223,
            -2.942191059734566,
            -2.736016695691751,
            -3.4124165540563407,
            -3.171616037103479,
            -2.3035658745126546,
            -3.480716469682212,
            -2.6207682194452415,
            -2.7531755856893483,
            -2.964916903767728,
            -2.9394795860995555,
            -2.952062890359557,
            -2.814139288586235,
            -2.509456816717349,
            -3.0055285667574894,
            -3.6954939473601898,
            -3.2371240737955427,
            -3.0677438309087286,
            -2.865601597607356,
            -3.164363196251097,
            -2.7413961978090775,
            -2.9773422433310555,
            -2.6268933574707525,
            -2.460730825142878,
            -2.854251360141683,
            -3.038035639388193,
            -3.5049618169596726,
            -2.7571947603514366,
            -2.674610350094043,
            -2.673735397283428,
            -2.5693079385418263,
            -2.9117572807520045,
            -2.919630776846135,
            -3.2004900784666277,
            -3.999555180005388,
            -3.315925320605908,
            -3.1309232728767684,
            -2.8220011212102634,
            -2.693966604191711,
            -2.89657098690125,
            -3.005823904316213,
            -2.8040976653518093,
            -3.08731619378003,
            -2.3117507514056985,
            -2.6973622654860594,
            -2.576170270421025,
            -2.948274198076972,
            -2.7105014407410404,
            -2.4701445512168063,
            -2.629050616267939,
            -2.787239602677685,
            -2.8876996870213447,
            -2.796017043960535,
            -3.013833649278444,
            -2.831445042330924,
            -2.9587258511823413,
            -3.073761209475566,
            -2.7767147574574835,
            -2.7451594318205887,
            -2.9108605527341354,
            -2.7746946389755984,
            -2.606979498984197,
            -2.5670719747168467,
            -2.3947318000064666,
            -2.6255437246603295,
            -2.8448556644430116,
            -2.5101531619642667,
            -2.4397708720423648,
            -2.5250953729757435,
            -2.7095857776120904,
            -2.708958399224996,
            -2.601879918117154,
            -2.696722527416591,
            -2.7172458143950284,
            -2.6730368188585163,
            -2.326814697119921,
            -2.2221508225187563,
            -2.332836236571313,
            -2.232943457120928,
            -2.146581380816829,
            -2.0051978408100313,
            -2.187910317022103,
            -2.10321340608892,
            -2.250391274041465,
            -2.372136733521226,
            -2.6492152745461914,
            -2.468290598412729,
            -2.5409073921823704,
            -2.584707181835846,
            -2.6997715096192865,
            -2.5347854557932994,
            -2.872213863982508,
            -2.7266850507531517,
            -2.785775127593023,
            -2.6564566254637576,
            -2.6665372114511583,
            -2.6124608314794084,
            -2.7522554761379108,
            -2.2786396690537996,
            -2.693900661700718,
            -2.6440473659345916,
            -2.550545721001796,
            -2.3554042103791133,
            -2.80739414988833,
            -2.4310245470858955,
            -2.593999659983418,
            -2.494919148408022,
            -2.595989521392321,
            -2.74708919278055,
            -2.747335577010888,
            -2.706445184853643,
            -2.8435036400888745,
            -2.716720343418416,
            -2.6531833169324823,
            -2.6524091115844497,
            -2.770925626312317,
            -2.8702695760217303,
            -2.67415195416213,
            -2.7096138860115953,
            -2.6094371810680874,
            -2.7751489302228562,
            -2.8135154121506756,
            -2.9210135354986804,
            -2.8384522453417316,
            -3.031003097119045,
            -2.9653777824320198,
            -2.8147567225177816,
            -2.72535809865317,
            -2.6401199779323155,
            -2.6880220953737513,
            -2.570768111165197,
            -2.746611190268838,
            -2.800433119579815,
            -2.8947480751077497,
            -2.810864914052054,
            -2.789552764806281,
            -2.6369703864215333,
            -2.7886107921561147,
            -2.8593678497432187,
            -2.769524469052698,
            -3.7880711222570893,
            -2.72542737738232,
            -2.679517092643997,
            -2.7316264970331954,
            -2.983392064432454,
            -2.9744531605215347,
            -2.940354384373996,
            -3.0070601139841604,
            -2.903058377768344,
            -2.608086844646792,
            -2.6991598775155468,
            -2.7465294196491166,
            -2.6587073128231262,
            -2.8430813726345514,
            -3.123228628205846,
            -2.5892913276763156,
            -2.713180251472763,
            -2.71495460467155,
            -3.064971240862738,
            -2.7713702826217195,
            -2.648169182111688
           ]
          },
          {
           "label": "n_layers",
           "range": [
            2,
            4
           ],
           "values": [
            4,
            2,
            4,
            2,
            2,
            3,
            4,
            3,
            2,
            2,
            3,
            3,
            3,
            2,
            3,
            2,
            4,
            3,
            3,
            2,
            3,
            4,
            4,
            4,
            4,
            3,
            3,
            2,
            4,
            4,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            2,
            4,
            3,
            2,
            4,
            3,
            2,
            4,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            3,
            4,
            3,
            2,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            2,
            3,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            2,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4,
            4
           ]
          },
          {
           "label": "pct_start",
           "range": [
            0.05,
            0.2
           ],
           "values": [
            0.1,
            0.05,
            0.1,
            0.2,
            0.05,
            0.15000000000000002,
            0.05,
            0.2,
            0.05,
            0.2,
            0.1,
            0.1,
            0.15000000000000002,
            0.05,
            0.1,
            0.15000000000000002,
            0.05,
            0.1,
            0.05,
            0.1,
            0.15000000000000002,
            0.05,
            0.05,
            0.05,
            0.1,
            0.05,
            0.1,
            0.05,
            0.05,
            0.1,
            0.1,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.1,
            0.05,
            0.1,
            0.05,
            0.2,
            0.05,
            0.15000000000000002,
            0.1,
            0.05,
            0.15000000000000002,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.1,
            0.05,
            0.05,
            0.2,
            0.1,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.1,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.1,
            0.05,
            0.15000000000000002,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.2,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.15000000000000002,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05,
            0.05
           ]
          },
          {
           "label": "weight_decay",
           "range": [
            -3.993876025717284,
            -2.023556177011077
           ],
           "ticktext": [
            "0.000101",
            "0.001",
            "0.00947"
           ],
           "tickvals": [
            -3.993876025717284,
            -3,
            -2.023556177011077
           ],
           "values": [
            -3.0850124570467248,
            -2.7849970287587342,
            -3.813330727854817,
            -2.553143369346541,
            -2.9721058560943665,
            -3.140087308199032,
            -2.1508573718237476,
            -3.2981110215865455,
            -3.743539864883725,
            -3.9866641127120515,
            -3.5474217245392015,
            -3.553324146284505,
            -3.5316008403978536,
            -3.4988544818989613,
            -3.7768520319183967,
            -3.737484460107776,
            -3.2763731374775813,
            -3.9318210079620353,
            -3.4686213829688275,
            -2.767861831262266,
            -2.093537624164667,
            -3.3248453274409906,
            -3.65607225333795,
            -3.658947119230801,
            -3.6645736328605456,
            -3.871490018724559,
            -3.3790022719759714,
            -3.6629092806151067,
            -3.1889457101999064,
            -3.0229447430449623,
            -3.98229213041097,
            -3.237209496214022,
            -3.429650651522985,
            -3.4229227402321194,
            -3.5969241263565745,
            -3.8448509550390373,
            -2.81801150504192,
            -3.638787302483834,
            -3.7585059352603207,
            -2.4614883745358416,
            -3.875096744917416,
            -3.602771846118332,
            -3.387095022820266,
            -3.0809705214575946,
            -3.54282193529858,
            -3.735787889729194,
            -3.482291225303336,
            -3.5751677295760733,
            -3.720057566512781,
            -3.8245154949407794,
            -3.3436302456097717,
            -3.439626723954979,
            -3.400295965555172,
            -3.1574135937029113,
            -3.5194866287905615,
            -3.251734174118437,
            -3.284456228213114,
            -3.597368068874083,
            -3.2132208472540755,
            -3.0847585755689044,
            -2.960952573707504,
            -3.39829649477833,
            -3.4905566048605916,
            -3.682747421941126,
            -3.4893857853234675,
            -3.8014500362913792,
            -3.9189703501676196,
            -3.324576673985653,
            -3.609920303929222,
            -3.5451942753352075,
            -3.6886865691214092,
            -3.4458835397825713,
            -2.278255571327327,
            -3.2470188800836763,
            -3.3674056548030955,
            -3.3354700002012043,
            -3.507791299360297,
            -3.6329177304905986,
            -3.7653749322894106,
            -2.8879373850669237,
            -3.5616887413313245,
            -3.3807077367870244,
            -3.4580137122520176,
            -3.2938624155011613,
            -3.3705572219493485,
            -3.7175347139557746,
            -3.1329563442367823,
            -3.707920555982568,
            -2.61288263689692,
            -3.8588472582852225,
            -3.640201287277831,
            -3.6410889566719447,
            -3.579552916520547,
            -3.7614374937876724,
            -3.792067427826909,
            -3.9096910207631286,
            -3.9894750811509887,
            -3.9931645563008913,
            -3.804112606124766,
            -3.9472501929625956,
            -3.9675799505587364,
            -3.8983719392686806,
            -3.9519826060697034,
            -3.961473462357896,
            -3.834864781292749,
            -3.9349923055094322,
            -3.87550131379736,
            -3.761809388548446,
            -3.7887712148422246,
            -3.8294003619210257,
            -3.717591797548464,
            -3.941174987431262,
            -3.9617779101362385,
            -3.88851247110635,
            -3.9479368131488233,
            -3.993876025717284,
            -3.847865026872832,
            -3.790380730842076,
            -3.733709491298875,
            -3.6672287132620554,
            -3.7441833003751763,
            -3.896311445214324,
            -3.688763090843973,
            -3.9315901876171595,
            -3.4272803183814653,
            -3.8184093025049184,
            -3.745125816329305,
            -3.855694934117853,
            -3.249679237926695,
            -3.5216786873907053,
            -3.524425966502135,
            -3.6165558602114976,
            -3.476371032897809,
            -3.435982777805295,
            -3.5470513756083912,
            -3.5048608595525175,
            -3.4821318508229906,
            -3.572490771052376,
            -3.5640786090612404,
            -3.587999552676788,
            -3.3481191692258836,
            -3.527295213677737,
            -3.4053752110296474,
            -3.6625285257521685,
            -3.555416939007777,
            -3.4754416579835543,
            -3.4745381824798853,
            -3.7082856414151846,
            -3.627642673526905,
            -3.441498585729024,
            -3.3266162833937676,
            -3.4887975182706588,
            -3.5897850194204706,
            -3.3972615966457145,
            -3.521926633630493,
            -3.3621975555861647,
            -3.461667014292271,
            -3.4644065282493823,
            -3.6721253650250345,
            -3.281083459544453,
            -3.2965570126196546,
            -3.432495986081298,
            -3.542919106023021,
            -3.1501388646061153,
            -3.409228387384888,
            -3.184443981363348,
            -3.097776756822254,
            -3.2173521846784072,
            -3.2725270040156116,
            -3.258406403461848,
            -3.3146417314339947,
            -2.996308344746351,
            -3.264015244892719,
            -3.1962282716666066,
            -3.7136644465900503,
            -3.189860941982415,
            -3.7803897548948475,
            -3.645024276891651,
            -2.023556177011077,
            -3.6028879020897664,
            -3.287379287693359,
            -3.3017711294749623,
            -3.232466313288491,
            -3.110474827009696,
            -3.155016778401814
           ]
          }
         ],
         "labelangle": 30,
         "labelside": "bottom",
         "line": {
          "color": [
           0.4947163709900468,
           0.49297218666986886,
           0.4813471719885105,
           0.48582076595330836,
           0.49587634066649217,
           0.5560792513104827,
           0.49097770875755825,
           0.5471641810764196,
           0.4710884659460451,
           0.5192872211135511,
           0.4720872759986644,
           0.4780043560672921,
           0.4783535459108627,
           0.488548144677984,
           0.4749128374145374,
           0.487769105549433,
           0.47458700663798725,
           0.47753635333064803,
           0.47975956101430856,
           0.47947758102598936,
           0.49103530289164443,
           0.4789503351840474,
           0.4701534300838065,
           0.4804629293430363,
           0.4752618935408578,
           0.474945696293687,
           0.481977635714154,
           0.4863866662540127,
           0.48186299640489916,
           0.4922695804451491,
           0.508653296464621,
           0.4794973851669492,
           0.4737243393326588,
           0.46960232107520977,
           0.47120738116290567,
           0.4814090757681261,
           0.4757593588922349,
           0.47896822428703595,
           0.4788739237015786,
           0.4853290016196741,
           0.48325651304304423,
           0.4899098494396619,
           0.476696629183824,
           0.4765966158354703,
           0.4748064759492319,
           0.48392333305005486,
           0.47938930652759854,
           0.4745539856098385,
           0.48092740797674294,
           0.4753333800279938,
           0.5060278962560338,
           0.47373214689969584,
           0.47244882948448763,
           0.47652775516288504,
           0.47999415219853664,
           0.46765089132423154,
           0.4750165791239908,
           0.4879987234342427,
           0.5157825625317525,
           0.48817027384220946,
           0.47435968325415523,
           0.4728887151357227,
           0.47056914603092376,
           0.4739508108943912,
           0.47426974341841915,
           0.4728146041285085,
           0.4931526315687284,
           0.48179250246934996,
           0.47499075944337904,
           0.4792153890867136,
           0.4752772806530471,
           0.47720184036313684,
           0.49111532730738194,
           0.4749740798152371,
           0.4703356771093289,
           0.47245721636041516,
           0.4792768420228019,
           0.47744524798157534,
           0.47992130553746615,
           0.47413360385770825,
           0.4891283724311615,
           0.47146206060207463,
           0.4725066716247543,
           0.47421981432720495,
           0.47509827674326494,
           0.467506767790427,
           0.48101392759986794,
           0.476056847897639,
           0.4864916518815289,
           0.4764027842181404,
           0.4710527345378048,
           0.47533313375982755,
           0.476651268681432,
           0.47011212845426753,
           0.4678993784002907,
           0.47614993484406687,
           0.4699721327650116,
           0.47817908620643507,
           0.47195365450561433,
           0.47098801612099744,
           0.47361158599473674,
           0.4734281162019044,
           0.46773682273024947,
           0.47442986625995054,
           0.47992965659307973,
           0.4803537810227622,
           0.47782849991800813,
           0.4755833048830165,
           0.47442427700593404,
           0.47152652209703544,
           0.47418346018185636,
           0.47059656434887476,
           0.4726290772044729,
           0.4765326919998197,
           0.47697419245679706,
           0.47808491617680593,
           0.4733793731938419,
           0.4726823801968501,
           0.4698592048259145,
           0.47211085906567885,
           0.47244852982364655,
           0.47838932217908525,
           0.48037627474070604,
           0.47918118849053537,
           0.4741612926631936,
           0.4728438033902339,
           0.47374695314225157,
           0.4717925652091289,
           0.4802410386796166,
           0.4696368344828613,
           0.4757084202950518,
           0.47374940389009607,
           0.46740088270443064,
           0.47205506449530016,
           0.4701365183923391,
           0.47411675921598045,
           0.47143572671749556,
           0.46767101671620426,
           0.4773971007552863,
           0.47186851126008583,
           0.4726959032666368,
           0.480404100490545,
           0.4725809782928513,
           0.47610778828381245,
           0.4725246665125689,
           0.46920679239328467,
           0.4747861185140221,
           0.47425826551568157,
           0.4801263660247838,
           0.4754080991120146,
           0.4727588315492456,
           0.476782389620511,
           0.4745475629573795,
           0.4744544017281635,
           0.4733290955868358,
           0.4736699109515882,
           0.47054529547851914,
           0.47366229101686796,
           0.4792159338518216,
           0.46934150880573294,
           0.4769028784945505,
           0.46872593803518087,
           0.47270859089255834,
           0.4728450761737221,
           0.5580999826108497,
           0.46771894252505664,
           0.4804232071647254,
           0.4726844681399382,
           0.469114960247079,
           0.4730066615858699,
           0.4766316778854428,
           0.4777947693777608,
           0.47425675049708216,
           0.47897224965076085,
           0.4765646195693587,
           0.48050106290402317,
           0.47234244081827503,
           0.4711346738732935,
           0.4821882633205762,
           0.471824871131317,
           0.46895306889291594,
           0.4766971441821295,
           0.47818710608691867,
           0.4737086022486089,
           0.4725758218822527
          ],
          "colorbar": {
           "title": {
            "text": "Objective Value"
           }
          },
          "colorscale": [
           [
            0,
            "rgb(247,251,255)"
           ],
           [
            0.125,
            "rgb(222,235,247)"
           ],
           [
            0.25,
            "rgb(198,219,239)"
           ],
           [
            0.375,
            "rgb(158,202,225)"
           ],
           [
            0.5,
            "rgb(107,174,214)"
           ],
           [
            0.625,
            "rgb(66,146,198)"
           ],
           [
            0.75,
            "rgb(33,113,181)"
           ],
           [
            0.875,
            "rgb(8,81,156)"
           ],
           [
            1,
            "rgb(8,48,107)"
           ]
          ],
          "reversescale": true,
          "showscale": true
         },
         "type": "parcoords"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Parallel Coordinate Plot"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 448,\n",
       " 'dropout': 0.0,\n",
       " 'input_layer_size': 640,\n",
       " 'n_layers': 4,\n",
       " 'learning_rate': 0.0017902381479678216,\n",
       " 'weight_decay': 0.0003339096474946611,\n",
       " 'pct_start': 0.05,\n",
       " 'div_factor': 74.0,\n",
       " 'final_div_factor': 39.31519465021811}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = dict(study.best_params)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcts-strength-variants-kSTIVMm8-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
